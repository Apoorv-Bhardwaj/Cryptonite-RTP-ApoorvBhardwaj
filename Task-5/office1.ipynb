{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:03.086150Z",
     "iopub.status.busy": "2026-01-30T09:46:03.085884Z",
     "iopub.status.idle": "2026-01-30T09:46:04.803600Z",
     "shell.execute_reply": "2026-01-30T09:46:04.802729Z",
     "shell.execute_reply.started": "2026-01-30T09:46:03.086107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 2.0.2\n",
      "torch 2.8.0+cu126\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os                                        \n",
    "import math                                       \n",
    "import random                                     # random choices for sampling\n",
    "import time                                       # measure elapsed time\n",
    "import numpy as np                               \n",
    "import matplotlib.pyplot as plt                  \n",
    "import torch                                      # main PyTorch package\n",
    "import torch.nn as nn                            \n",
    "from torch.utils.data import Dataset, DataLoader  # dataset and dataloader utilities\n",
    "\n",
    "print(\"numpy\", np.__version__)                     # show numpy version\n",
    "print(\"torch\", torch.__version__)                  # show torch version\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:04.805213Z",
     "iopub.status.busy": "2026-01-30T09:46:04.804838Z",
     "iopub.status.idle": "2026-01-30T09:46:04.828452Z",
     "shell.execute_reply": "2026-01-30T09:46:04.827842Z",
     "shell.execute_reply.started": "2026-01-30T09:46:04.805190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characters: 3427466\n",
      "Michael: All right Jim. Your quarterlies look very good. How are things at the library?\n",
      "Jim: Oh, I told you. I couldn't close it. So...\n",
      "Michael: So you've come to the master for guidance? Is this what you're saying, grasshopper?\n",
      "Jim: Actually, you called me in here, but yeah.\n",
      "Michael: All right. Well, let me show you how it's done.\n",
      "Michael:  Yes, I'd like to speak to your office manager, please. Yes, hello. This is Michael Scott. I am the Regional Manager of Dunder Mifflin Paper Products. Just wanted to talk to you manager-a-manger.  All right. Done deal. Thank you very much, sir. You're a gentleman and a scholar. Oh, I'm sorry. OK. I'm sorry. My mistake.  That was a woman I was talking to, so... She had a very low voice. Probably a smoker, so...  So that's the way it's done.\n",
      "Michael: I've\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/input/office-script-clean/office_script_clean.txt\" \n",
    "\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()                          \n",
    "\n",
    "\n",
    "raw_text = raw_text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\") \n",
    "\n",
    "\n",
    "print(\"Loaded characters:\", len(raw_text)) \n",
    "\n",
    "\n",
    "print(raw_text[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:04.829411Z",
     "iopub.status.busy": "2026-01-30T09:46:04.829222Z",
     "iopub.status.idle": "2026-01-30T09:46:05.173744Z",
     "shell.execute_reply": "2026-01-30T09:46:05.172955Z",
     "shell.execute_reply.started": "2026-01-30T09:46:04.829394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 72\n",
      "total characters: 3427466\n",
      "context length (suggested): 128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = sorted(list(set(raw_text))\n",
    "\n",
    "stoi = {ch:i for i,ch in enumerate(vocab)}   \n",
    "itos = {i:ch for i,ch in enumerate(vocab)}        \n",
    "\n",
    "\n",
    "data_ids = np.array([stoi[ch] for ch in raw_text], dtype=np.int64)\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)                      \n",
    "total_chars = len(raw_text)                      \n",
    "context_length = 128                            \n",
    "\n",
    "\n",
    "print(\"vocab size:\", vocab_size)                \n",
    "print(\"total characters:\", total_chars)         \n",
    "print(\"context length (suggested):\", context_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:05.175909Z",
     "iopub.status.busy": "2026-01-30T09:46:05.175623Z",
     "iopub.status.idle": "2026-01-30T09:46:05.183555Z",
     "shell.execute_reply": "2026-01-30T09:46:05.182914Z",
     "shell.execute_reply.started": "2026-01-30T09:46:05.175886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches per epoch: 48196\n",
      "Val batches per epoch: 5353\n"
     ]
    }
   ],
   "source": [
    "# 90/10 train/validation split index\n",
    "split_at = int(0.9 * len(data_ids))              \n",
    "\n",
    "# split encoded ids into train and validation arrays\n",
    "train_ids = data_ids[:split_at]                 \n",
    "val_ids = data_ids[split_at:]                   \n",
    "\n",
    "# sliding windows of characters\n",
    "class CharDataset(Dataset):                        \n",
    "    def __init__(self, arr, context_len):            # constructor with array and window size\n",
    "        self.arr = arr                               # store array of ids\n",
    "        self.context_len = context_len               # store context length\n",
    "    def __len__(self):                               # required: number of samples\n",
    "        return max(0, len(self.arr) - self.context_len)  # number of windows\n",
    "    def __getitem__(self, idx):                      # required: get one sample by index\n",
    "        x = self.arr[idx: idx + self.context_len]   # input window of length context_len\n",
    "        y = self.arr[idx + 1: idx + 1 + self.context_len]  # target is next characters\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)  # return tensors\n",
    "\n",
    "# instantiate datasets for train and validation\n",
    "train_dataset = CharDataset(train_ids, context_length) \n",
    "val_dataset = CharDataset(val_ids, context_length)    \n",
    "\n",
    "# dataloader parameters\n",
    "batch_size = 64                                   \n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=4,       \n",
    "    pin_memory=True      \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train batches per epoch:\", len(train_loader))   # number of training batches\n",
    "print(\"Val batches per epoch:\", len(val_loader))       # number of validation batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:05.184656Z",
     "iopub.status.busy": "2026-01-30T09:46:05.184386Z",
     "iopub.status.idle": "2026-01-30T09:46:06.355822Z",
     "shell.execute_reply": "2026-01-30T09:46:06.355057Z",
     "shell.execute_reply.started": "2026-01-30T09:46:05.184626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 72\n",
      "Parameter count: 422984\n",
      "Train batches per epoch: 48196\n",
      "Val batches per epoch: 5353\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_size = 128                     # embedding vector size for each character\n",
    "\n",
    "checkpoint_path = \"lstm_modules_fast.pt\"  # where checkpoints will be saved #lstm_modules_full\n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "context_length = 64\n",
    "num_epochs = 15\n",
    "learning_rate = 0.001\n",
    "\n",
    "embed = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size).to(device)  # char -> vector\n",
    "\n",
    "lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=n_layers, batch_first=True).to(device)  # recurrent core\n",
    "\n",
    "fc = nn.Linear(in_features=hidden_size, out_features=vocab_size).to(device)  # project LSTM outputs to vocab logits\n",
    "\n",
    "\n",
    "params = list(embed.parameters()) + list(lstm.parameters()) + list(fc.parameters())  # gather all trainable params\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)  # Adam over all params\n",
    "criterion = nn.CrossEntropyLoss()                        # loss: cross-entropy over vocab logits\n",
    "\n",
    "\n",
    "print(\"Vocab size:\", vocab_size)                          \n",
    "print(\"Parameter count:\", sum(p.numel() for p in params)) \n",
    "print(\"Train batches per epoch:\", len(train_loader))      \n",
    "print(\"Val batches per epoch:\", len(val_loader))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:06.357067Z",
     "iopub.status.busy": "2026-01-30T09:46:06.356722Z",
     "iopub.status.idle": "2026-01-30T09:46:06.363612Z",
     "shell.execute_reply": "2026-01-30T09:46:06.362829Z",
     "shell.execute_reply.started": "2026-01-30T09:46:06.357041Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_modules(embed, lstm, fc, dataloader):\n",
    "    #Compute average negative log-likelihood (NLL) and perplexity on dataloader.\n",
    "\n",
    "    total_loss = 0.0  # loss * token_count\n",
    "    total_tokens = 0          \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for xb, yb in dataloader:    # mini-batches\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            emb = embed(xb)          # (B, T, E)\n",
    "            out, _ = lstm(emb)       # (B, T, H)\n",
    "            logits = fc(out)         # (B, T, V) logits \n",
    "            \n",
    "            B, T, V = logits.shape   # batch, time, vocab sizes\n",
    "            logits_flat = logits.view(B*T, V)     # flatten to (B*T, V) for loss\n",
    "            targets_flat = yb.view(B*T)          # flatten targets to (B*T)\n",
    "\n",
    "            loss = criterion(logits_flat, targets_flat)  # cross-entropy averaged over B*T\n",
    "            total_loss += loss.item() * (B*T)            # weight by token count\n",
    "            total_tokens += (B*T)                       # increase token counter\n",
    "\n",
    "    avg_nll = total_loss / total_tokens        # average negative log-likelihood per token\n",
    "    ppl = math.exp(avg_nll)                    # perplexity = exp(avg NLL)\n",
    "    return avg_nll, ppl                        # return both values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:06.364930Z",
     "iopub.status.busy": "2026-01-30T09:46:06.364639Z",
     "iopub.status.idle": "2026-01-30T09:46:06.380390Z",
     "shell.execute_reply": "2026-01-30T09:46:06.379755Z",
     "shell.execute_reply.started": "2026-01-30T09:46:06.364898Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_modules_with_history(embed, lstm, fc, train_loader, val_loader, num_epochs, save_path):\n",
    "    \"\"\"\n",
    "    Train modules and print batch-level progress with ETA.\n",
    "    Returns histories: train_losses, val_losses, train_ppls, val_ppls.\n",
    "    \"\"\"\n",
    "    embed.to(device); lstm.to(device); fc.to(device)       \n",
    "\n",
    "    train_losses = []                                      # avg train loss per epoch\n",
    "    val_losses = []                                        # avg val loss per epoch\n",
    "    train_ppls = []                                        # train perplexity per epoch\n",
    "    val_ppls = []                                          # val perplexity per epoch\n",
    "\n",
    "    total_batches = len(train_loader)                      # batches per epoch\n",
    "\n",
    "    for epoch in range(num_epochs):                        # epoch loop\n",
    "        embed.train(); lstm.train(); fc.train()            # training mode\n",
    "        running_loss = 0.0                                 # loss accumulator\n",
    "        running_tokens = 0                                 # token counter\n",
    "        epoch_start = time.time()                          # epoch timer start\n",
    "\n",
    "        for batch_idx, (xb, yb) in enumerate(train_loader, start=1):  \n",
    "            xb = xb.to(device); yb = yb.to(device)         # move to device\n",
    "            optimizer.zero_grad()                           # reset gradients\n",
    "\n",
    "            emb_out = embed(xb)                             # embeddings\n",
    "            lstm_out, _ = lstm(emb_out)                     # LSTM forward\n",
    "            logits = fc(lstm_out)                           # project to vocab\n",
    "\n",
    "            B, T, V = logits.shape                          # shapes\n",
    "            logits_flat = logits.view(B*T, V)               \n",
    "            targets_flat = yb.view(B*T)                     \n",
    "\n",
    "            loss = criterion(logits_flat, targets_flat)     # compute loss\n",
    "            loss.backward()                                 # backprop\n",
    "            torch.nn.utils.clip_grad_norm_(params, 1.0)     # gradient clipping\n",
    "            optimizer.step()                                # optimizer step\n",
    "\n",
    "            running_loss += loss.item() * (B*T)             # accumulate weighted loss\n",
    "            running_tokens += (B*T)                         # accumulate tokens\n",
    "\n",
    "            # ---- progress reporting ----\n",
    "            if batch_idx % 200 == 0 or batch_idx == total_batches:\n",
    "                elapsed = time.time() - epoch_start        \n",
    "                progress = batch_idx / total_batches        # fraction of epoch done\n",
    "                eta = elapsed / progress - elapsed          # estimated remaining time\n",
    "                avg_loss = running_loss / running_tokens    # running average loss\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                    f\"Batch {batch_idx}/{total_batches} \"\n",
    "                    f\"({progress*100:5.1f}%) | \"\n",
    "                    f\"loss {avg_loss:.4f} | \"\n",
    "                    f\"elapsed {elapsed/60:.1f}m | \"\n",
    "                    f\"ETA {eta/60:.1f}m\"\n",
    "                )\n",
    "\n",
    "\n",
    "        train_loss, train_ppl = evaluate_modules(embed, lstm, fc, train_loader)\n",
    "        val_loss, val_ppl = evaluate_modules(embed, lstm, fc, val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_ppls.append(train_ppl)\n",
    "        val_ppls.append(val_ppl)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1} DONE | \"\n",
    "            f\"train_loss {train_loss:.4f} ppl {train_ppl:.3f} | \"\n",
    "            f\"val_loss {val_loss:.4f} ppl {val_ppl:.3f}\"\n",
    "        )\n",
    "\n",
    "        # save checkpoint after each epoch\n",
    "        torch.save({\n",
    "            'embed_state': embed.state_dict(),\n",
    "            'lstm_state': lstm.state_dict(),\n",
    "            'fc_state': fc.state_dict(),\n",
    "            'stoi': stoi,\n",
    "            'itos': itos,\n",
    "            'epoch': epoch + 1,\n",
    "            'val_ppl': val_ppl\n",
    "        }, save_path)\n",
    "\n",
    "    return train_losses, val_losses, train_ppls, val_ppls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:06.381780Z",
     "iopub.status.busy": "2026-01-30T09:46:06.381447Z",
     "iopub.status.idle": "2026-01-30T09:46:06.397830Z",
     "shell.execute_reply": "2026-01-30T09:46:06.397070Z",
     "shell.execute_reply.started": "2026-01-30T09:46:06.381758Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_script(seed_text, temperature, num_tokens_to_generate):\n",
    "    \"\"\"\n",
    "    Generate characters using saved LSTM modules if checkpoint exists.\n",
    "    If no checkpoint found, fall back to bigram sampling built from training text.\n",
    "    Signature required by the task: generate_script(seed_text, temperature, num_tokens_to_generate)\n",
    "    \"\"\"\n",
    "    ckpt = checkpoint_path  # uses the same checkpoint path defined earlier\n",
    "\n",
    "    if os.path.exists(ckpt):                           \n",
    "        ck = torch.load(ckpt, map_location=device)     # load checkpoint to CPU/GPU as needed\n",
    "        embed.load_state_dict(ck['embed_state'])       # restore embedding weights\n",
    "        lstm.load_state_dict(ck['lstm_state'])         # restore LSTM weights\n",
    "        fc.load_state_dict(ck['fc_state'])             # restore final linear weights\n",
    "        embed.to(device); lstm.to(device); fc.to(device) \n",
    "\n",
    "        if len(seed_text) == 0:                         # if seed is empty, start with newline\n",
    "            seed_text = \"\\n\"\n",
    "\n",
    "        # map seed chars to ids using global stoi (unknown -> 0)\n",
    "        input_ids = [stoi.get(ch, 0) for ch in seed_text]\n",
    "        inp = torch.tensor([input_ids], dtype=torch.long).to(device)  # shape (1, L)\n",
    "        out_text = seed_text                              # initialize output string with seed\n",
    "\n",
    "        with torch.no_grad():                             # disable gradients during sampling\n",
    "            emb_seed = embed(inp)                         # embed the seed -> (1, L, E)\n",
    "            out_seed, hidden = lstm(emb_seed)             # run entire seed to prime hidden state\n",
    "            last_id = input_ids[-1]                       # start sampling conditioned on last seed id\n",
    "\n",
    "            for _ in range(num_tokens_to_generate):       # generate requested number of characters\n",
    "                step_inp = torch.tensor([[last_id]], dtype=torch.long).to(device)  # (1,1) tensor\n",
    "                step_emb = embed(step_inp)                # embedding for the last token -> (1,1,E)\n",
    "                #logits_step, hidden = lstm(step_emb, hidden)  # one-step forward using current hidden\n",
    "                #logits_np = logits_step[0, -1, :].cpu().numpy()  # extract logits for vocabulary (V,)\n",
    "                lstm_out, hidden = lstm(step_emb, hidden)\n",
    "                logits_step = fc(lstm_out)                      #  project to vocab\n",
    "                logits_np = logits_step[0, -1, :].cpu().numpy() # (vocab_size,)\n",
    "\n",
    "                if temperature <= 0.0:\n",
    "                    temperature = 1e-8\n",
    "\n",
    "                logits_scaled = logits_np / temperature    # scale logits by 1/temperature\n",
    "                exps = np.exp(logits_scaled - np.max(logits_scaled))  # subtract max for stability\n",
    "                probs = exps / exps.sum()                 # normalized sampling probabilities\n",
    "\n",
    "                next_id = np.random.choice(len(probs), p=probs)  # sample next char id\n",
    "                next_char = itos[next_id]                   # convert id back to character\n",
    "                out_text += next_char                       # append to generated output\n",
    "                last_id = next_id                           # update last_id for next step\n",
    "\n",
    "        return out_text                                   # return generated text from LSTM\n",
    "\n",
    "    else:\n",
    "        if 'bigram' not in globals():                    # if bigram not available, build it\n",
    "            # build bigram from training portion of raw_text\n",
    "            train_text = raw_text[:int(0.9 * len(raw_text))]    # same 90/10 split as before\n",
    "            chars = sorted(list(set(train_text)))               # bigram vocab\n",
    "            stoi_big = {ch:i for i,ch in enumerate(chars)}      # char->id for bigram\n",
    "            itos_big = {i:ch for i,ch in enumerate(chars)}      # id->char for bigram\n",
    "            V = len(chars)                                      # bigram vocab size\n",
    "            counts = np.zeros((V, V), dtype=np.float64)        # bigram counts\n",
    "            unigram = np.zeros(V, dtype=np.float64)            # unigram counts\n",
    "\n",
    "            for a, b in zip(train_text, train_text[1:]):       # count consecutive pairs\n",
    "                ai = stoi_big[a]; bi = stoi_big[b]\n",
    "                counts[ai, bi] += 1.0\n",
    "                unigram[ai] += 1.0\n",
    "            unigram[stoi_big[train_text[-1]]] += 1.0           # last char count\n",
    "            alpha = 1e-3\n",
    "            bigram_probs = (counts + alpha) / (counts.sum(axis=1, keepdims=True) + alpha * V)  # row-normalize\n",
    "            unigram_probs = (unigram + alpha) / (unigram.sum() + alpha * V)\n",
    "\n",
    "            # store globally for reuse during this session\n",
    "            bigram = {'chars': chars, 'stoi': stoi_big, 'itos': itos_big, 'bigram_probs': bigram_probs, 'unigram_probs': unigram_probs}\n",
    "\n",
    "        # perform sampling from the bigram model with temperature\n",
    "        if len(seed_text) == 0:\n",
    "            seed_text = \"\\n\"\n",
    "        out_text = seed_text                                  # initialize with the seed\n",
    "        last_char = seed_text[-1]                             # condition on last char of seed\n",
    "\n",
    "        for _ in range(num_tokens_to_generate):               # generate requested chars\n",
    "            if last_char in bigram['stoi']:                   # get conditional distribution\n",
    "                probs = bigram['bigram_probs'][bigram['stoi'][last_char]].copy()\n",
    "            else:\n",
    "                probs = bigram['unigram_probs'].copy()       # fallback to unigram after unknown char\n",
    "\n",
    "            if temperature <= 0.0:                            # guard temperature\n",
    "                temperature = 1e-8\n",
    "\n",
    "            logits = np.log(probs + 1e-12) / temperature      # apply temperature in log space\n",
    "            exps = np.exp(logits - np.max(logits))            # numerical stability subtraction\n",
    "            probs_t = exps / exps.sum()                       # normalized probabilities\n",
    "\n",
    "            next_i = np.random.choice(np.arange(len(probs_t)), p=probs_t)  # sample char index\n",
    "            next_c = bigram['itos'][next_i]                   # convert index to char\n",
    "            out_text += next_c                                # append generated char\n",
    "            last_char = next_c                                # update last_char for next step\n",
    "\n",
    "        return out_text                                      # return bigram-generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T09:46:06.399030Z",
     "iopub.status.busy": "2026-01-30T09:46:06.398768Z",
     "iopub.status.idle": "2026-01-30T11:01:53.427185Z",
     "shell.execute_reply": "2026-01-30T11:01:53.426368Z",
     "shell.execute_reply.started": "2026-01-30T09:46:06.399001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 | Batch 200/48196 (  0.4%) | loss 2.2907 | elapsed 0.0m | ETA 11.4m\n",
      "Epoch 1/6 | Batch 400/48196 (  0.8%) | loss 1.9898 | elapsed 0.1m | ETA 10.0m\n",
      "Epoch 1/6 | Batch 600/48196 (  1.2%) | loss 1.8440 | elapsed 0.1m | ETA 9.6m\n",
      "Epoch 1/6 | Batch 800/48196 (  1.7%) | loss 1.7534 | elapsed 0.2m | ETA 9.3m\n",
      "Epoch 1/6 | Batch 1000/48196 (  2.1%) | loss 1.6897 | elapsed 0.2m | ETA 9.2m\n",
      "Epoch 1/6 | Batch 1200/48196 (  2.5%) | loss 1.6420 | elapsed 0.2m | ETA 9.0m\n",
      "Epoch 1/6 | Batch 1400/48196 (  2.9%) | loss 1.6032 | elapsed 0.3m | ETA 9.0m\n",
      "Epoch 1/6 | Batch 1600/48196 (  3.3%) | loss 1.5715 | elapsed 0.3m | ETA 8.9m\n",
      "Epoch 1/6 | Batch 1800/48196 (  3.7%) | loss 1.5451 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 1/6 | Batch 2000/48196 (  4.1%) | loss 1.5221 | elapsed 0.4m | ETA 8.8m\n",
      "Epoch 1/6 | Batch 2200/48196 (  4.6%) | loss 1.5023 | elapsed 0.4m | ETA 8.7m\n",
      "Epoch 1/6 | Batch 2400/48196 (  5.0%) | loss 1.4848 | elapsed 0.5m | ETA 8.7m\n",
      "Epoch 1/6 | Batch 2600/48196 (  5.4%) | loss 1.4692 | elapsed 0.5m | ETA 8.7m\n",
      "Epoch 1/6 | Batch 2800/48196 (  5.8%) | loss 1.4550 | elapsed 0.5m | ETA 8.6m\n",
      "Epoch 1/6 | Batch 3000/48196 (  6.2%) | loss 1.4422 | elapsed 0.6m | ETA 8.6m\n",
      "Epoch 1/6 | Batch 3200/48196 (  6.6%) | loss 1.4307 | elapsed 0.6m | ETA 8.5m\n",
      "Epoch 1/6 | Batch 3400/48196 (  7.1%) | loss 1.4198 | elapsed 0.6m | ETA 8.5m\n",
      "Epoch 1/6 | Batch 3600/48196 (  7.5%) | loss 1.4099 | elapsed 0.7m | ETA 8.5m\n",
      "Epoch 1/6 | Batch 3800/48196 (  7.9%) | loss 1.4007 | elapsed 0.7m | ETA 8.4m\n",
      "Epoch 1/6 | Batch 4000/48196 (  8.3%) | loss 1.3923 | elapsed 0.8m | ETA 8.4m\n",
      "Epoch 1/6 | Batch 4200/48196 (  8.7%) | loss 1.3843 | elapsed 0.8m | ETA 8.3m\n",
      "Epoch 1/6 | Batch 4400/48196 (  9.1%) | loss 1.3768 | elapsed 0.8m | ETA 8.3m\n",
      "Epoch 1/6 | Batch 4600/48196 (  9.5%) | loss 1.3699 | elapsed 0.9m | ETA 8.2m\n",
      "Epoch 1/6 | Batch 4800/48196 ( 10.0%) | loss 1.3633 | elapsed 0.9m | ETA 8.2m\n",
      "Epoch 1/6 | Batch 5000/48196 ( 10.4%) | loss 1.3570 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 1/6 | Batch 5200/48196 ( 10.8%) | loss 1.3511 | elapsed 1.0m | ETA 8.1m\n",
      "Epoch 1/6 | Batch 5400/48196 ( 11.2%) | loss 1.3455 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 1/6 | Batch 5600/48196 ( 11.6%) | loss 1.3402 | elapsed 1.1m | ETA 8.0m\n",
      "Epoch 1/6 | Batch 5800/48196 ( 12.0%) | loss 1.3353 | elapsed 1.1m | ETA 8.0m\n",
      "Epoch 1/6 | Batch 6000/48196 ( 12.4%) | loss 1.3305 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 1/6 | Batch 6200/48196 ( 12.9%) | loss 1.3259 | elapsed 1.2m | ETA 7.9m\n",
      "Epoch 1/6 | Batch 6400/48196 ( 13.3%) | loss 1.3215 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 1/6 | Batch 6600/48196 ( 13.7%) | loss 1.3173 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 1/6 | Batch 6800/48196 ( 14.1%) | loss 1.3132 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 1/6 | Batch 7000/48196 ( 14.5%) | loss 1.3094 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 1/6 | Batch 7200/48196 ( 14.9%) | loss 1.3056 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 1/6 | Batch 7400/48196 ( 15.4%) | loss 1.3018 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 1/6 | Batch 7600/48196 ( 15.8%) | loss 1.2983 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 1/6 | Batch 7800/48196 ( 16.2%) | loss 1.2950 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 1/6 | Batch 8000/48196 ( 16.6%) | loss 1.2917 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 1/6 | Batch 8200/48196 ( 17.0%) | loss 1.2885 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 1/6 | Batch 8400/48196 ( 17.4%) | loss 1.2855 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 1/6 | Batch 8600/48196 ( 17.8%) | loss 1.2825 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 1/6 | Batch 8800/48196 ( 18.3%) | loss 1.2798 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 1/6 | Batch 9000/48196 ( 18.7%) | loss 1.2769 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 1/6 | Batch 9200/48196 ( 19.1%) | loss 1.2743 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 1/6 | Batch 9400/48196 ( 19.5%) | loss 1.2716 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 1/6 | Batch 9600/48196 ( 19.9%) | loss 1.2691 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 1/6 | Batch 9800/48196 ( 20.3%) | loss 1.2667 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 1/6 | Batch 10000/48196 ( 20.7%) | loss 1.2644 | elapsed 1.9m | ETA 7.1m\n",
      "Epoch 1/6 | Batch 10200/48196 ( 21.2%) | loss 1.2620 | elapsed 1.9m | ETA 7.1m\n",
      "Epoch 1/6 | Batch 10400/48196 ( 21.6%) | loss 1.2597 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 1/6 | Batch 10600/48196 ( 22.0%) | loss 1.2575 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 1/6 | Batch 10800/48196 ( 22.4%) | loss 1.2553 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 1/6 | Batch 11000/48196 ( 22.8%) | loss 1.2533 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 1/6 | Batch 11200/48196 ( 23.2%) | loss 1.2512 | elapsed 2.1m | ETA 6.9m\n",
      "Epoch 1/6 | Batch 11400/48196 ( 23.7%) | loss 1.2493 | elapsed 2.1m | ETA 6.9m\n",
      "Epoch 1/6 | Batch 11600/48196 ( 24.1%) | loss 1.2473 | elapsed 2.2m | ETA 6.8m\n",
      "Epoch 1/6 | Batch 11800/48196 ( 24.5%) | loss 1.2454 | elapsed 2.2m | ETA 6.8m\n",
      "Epoch 1/6 | Batch 12000/48196 ( 24.9%) | loss 1.2436 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 1/6 | Batch 12200/48196 ( 25.3%) | loss 1.2418 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 1/6 | Batch 12400/48196 ( 25.7%) | loss 1.2400 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 1/6 | Batch 12600/48196 ( 26.1%) | loss 1.2382 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 1/6 | Batch 12800/48196 ( 26.6%) | loss 1.2365 | elapsed 2.4m | ETA 6.6m\n",
      "Epoch 1/6 | Batch 13000/48196 ( 27.0%) | loss 1.2349 | elapsed 2.4m | ETA 6.6m\n",
      "Epoch 1/6 | Batch 13200/48196 ( 27.4%) | loss 1.2332 | elapsed 2.5m | ETA 6.5m\n",
      "Epoch 1/6 | Batch 13400/48196 ( 27.8%) | loss 1.2317 | elapsed 2.5m | ETA 6.5m\n",
      "Epoch 1/6 | Batch 13600/48196 ( 28.2%) | loss 1.2302 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 1/6 | Batch 13800/48196 ( 28.6%) | loss 1.2286 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 1/6 | Batch 14000/48196 ( 29.0%) | loss 1.2271 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 1/6 | Batch 14200/48196 ( 29.5%) | loss 1.2256 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 1/6 | Batch 14400/48196 ( 29.9%) | loss 1.2242 | elapsed 2.7m | ETA 6.3m\n",
      "Epoch 1/6 | Batch 14600/48196 ( 30.3%) | loss 1.2228 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 1/6 | Batch 14800/48196 ( 30.7%) | loss 1.2214 | elapsed 2.8m | ETA 6.2m\n",
      "Epoch 1/6 | Batch 15000/48196 ( 31.1%) | loss 1.2201 | elapsed 2.8m | ETA 6.2m\n",
      "Epoch 1/6 | Batch 15200/48196 ( 31.5%) | loss 1.2187 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 1/6 | Batch 15400/48196 ( 32.0%) | loss 1.2174 | elapsed 2.9m | ETA 6.1m\n",
      "Epoch 1/6 | Batch 15600/48196 ( 32.4%) | loss 1.2162 | elapsed 2.9m | ETA 6.1m\n",
      "Epoch 1/6 | Batch 15800/48196 ( 32.8%) | loss 1.2149 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 1/6 | Batch 16000/48196 ( 33.2%) | loss 1.2137 | elapsed 3.0m | ETA 6.0m\n",
      "Epoch 1/6 | Batch 16200/48196 ( 33.6%) | loss 1.2125 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 1/6 | Batch 16400/48196 ( 34.0%) | loss 1.2113 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 1/6 | Batch 16600/48196 ( 34.4%) | loss 1.2101 | elapsed 3.1m | ETA 5.9m\n",
      "Epoch 1/6 | Batch 16800/48196 ( 34.9%) | loss 1.2090 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 1/6 | Batch 17000/48196 ( 35.3%) | loss 1.2078 | elapsed 3.2m | ETA 5.8m\n",
      "Epoch 1/6 | Batch 17200/48196 ( 35.7%) | loss 1.2067 | elapsed 3.2m | ETA 5.8m\n",
      "Epoch 1/6 | Batch 17400/48196 ( 36.1%) | loss 1.2055 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 1/6 | Batch 17600/48196 ( 36.5%) | loss 1.2044 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 1/6 | Batch 17800/48196 ( 36.9%) | loss 1.2034 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 1/6 | Batch 18000/48196 ( 37.3%) | loss 1.2023 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 1/6 | Batch 18200/48196 ( 37.8%) | loss 1.2013 | elapsed 3.4m | ETA 5.6m\n",
      "Epoch 1/6 | Batch 18400/48196 ( 38.2%) | loss 1.2003 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 1/6 | Batch 18600/48196 ( 38.6%) | loss 1.1993 | elapsed 3.5m | ETA 5.5m\n",
      "Epoch 1/6 | Batch 18800/48196 ( 39.0%) | loss 1.1983 | elapsed 3.5m | ETA 5.5m\n",
      "Epoch 1/6 | Batch 19000/48196 ( 39.4%) | loss 1.1972 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 1/6 | Batch 19200/48196 ( 39.8%) | loss 1.1963 | elapsed 3.6m | ETA 5.4m\n",
      "Epoch 1/6 | Batch 19400/48196 ( 40.3%) | loss 1.1953 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 1/6 | Batch 19600/48196 ( 40.7%) | loss 1.1944 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 1/6 | Batch 19800/48196 ( 41.1%) | loss 1.1935 | elapsed 3.7m | ETA 5.3m\n",
      "Epoch 1/6 | Batch 20000/48196 ( 41.5%) | loss 1.1925 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 1/6 | Batch 20200/48196 ( 41.9%) | loss 1.1916 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 1/6 | Batch 20400/48196 ( 42.3%) | loss 1.1907 | elapsed 3.8m | ETA 5.2m\n",
      "Epoch 1/6 | Batch 20600/48196 ( 42.7%) | loss 1.1898 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 1/6 | Batch 20800/48196 ( 43.2%) | loss 1.1890 | elapsed 3.9m | ETA 5.1m\n",
      "Epoch 1/6 | Batch 21000/48196 ( 43.6%) | loss 1.1881 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 1/6 | Batch 21200/48196 ( 44.0%) | loss 1.1872 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 1/6 | Batch 21400/48196 ( 44.4%) | loss 1.1864 | elapsed 4.0m | ETA 5.0m\n",
      "Epoch 1/6 | Batch 21600/48196 ( 44.8%) | loss 1.1856 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 1/6 | Batch 21800/48196 ( 45.2%) | loss 1.1848 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 1/6 | Batch 22000/48196 ( 45.6%) | loss 1.1840 | elapsed 4.1m | ETA 4.9m\n",
      "Epoch 1/6 | Batch 22200/48196 ( 46.1%) | loss 1.1832 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 1/6 | Batch 22400/48196 ( 46.5%) | loss 1.1824 | elapsed 4.2m | ETA 4.8m\n",
      "Epoch 1/6 | Batch 22600/48196 ( 46.9%) | loss 1.1816 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 1/6 | Batch 22800/48196 ( 47.3%) | loss 1.1808 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 1/6 | Batch 23000/48196 ( 47.7%) | loss 1.1801 | elapsed 4.3m | ETA 4.7m\n",
      "Epoch 1/6 | Batch 23200/48196 ( 48.1%) | loss 1.1793 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 1/6 | Batch 23400/48196 ( 48.6%) | loss 1.1786 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 1/6 | Batch 23600/48196 ( 49.0%) | loss 1.1779 | elapsed 4.4m | ETA 4.6m\n",
      "Epoch 1/6 | Batch 23800/48196 ( 49.4%) | loss 1.1771 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 1/6 | Batch 24000/48196 ( 49.8%) | loss 1.1764 | elapsed 4.5m | ETA 4.5m\n",
      "Epoch 1/6 | Batch 24200/48196 ( 50.2%) | loss 1.1757 | elapsed 4.5m | ETA 4.5m\n",
      "Epoch 1/6 | Batch 24400/48196 ( 50.6%) | loss 1.1750 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 1/6 | Batch 24600/48196 ( 51.0%) | loss 1.1743 | elapsed 4.6m | ETA 4.4m\n",
      "Epoch 1/6 | Batch 24800/48196 ( 51.5%) | loss 1.1737 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 1/6 | Batch 25000/48196 ( 51.9%) | loss 1.1730 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 1/6 | Batch 25200/48196 ( 52.3%) | loss 1.1723 | elapsed 4.7m | ETA 4.3m\n",
      "Epoch 1/6 | Batch 25400/48196 ( 52.7%) | loss 1.1717 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 1/6 | Batch 25600/48196 ( 53.1%) | loss 1.1710 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 1/6 | Batch 25800/48196 ( 53.5%) | loss 1.1703 | elapsed 4.8m | ETA 4.2m\n",
      "Epoch 1/6 | Batch 26000/48196 ( 53.9%) | loss 1.1697 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 1/6 | Batch 26200/48196 ( 54.4%) | loss 1.1690 | elapsed 4.9m | ETA 4.1m\n",
      "Epoch 1/6 | Batch 26400/48196 ( 54.8%) | loss 1.1684 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 1/6 | Batch 26600/48196 ( 55.2%) | loss 1.1678 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 1/6 | Batch 26800/48196 ( 55.6%) | loss 1.1672 | elapsed 5.0m | ETA 4.0m\n",
      "Epoch 1/6 | Batch 27000/48196 ( 56.0%) | loss 1.1666 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 1/6 | Batch 27200/48196 ( 56.4%) | loss 1.1660 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 1/6 | Batch 27400/48196 ( 56.9%) | loss 1.1654 | elapsed 5.1m | ETA 3.9m\n",
      "Epoch 1/6 | Batch 27600/48196 ( 57.3%) | loss 1.1648 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 1/6 | Batch 27800/48196 ( 57.7%) | loss 1.1642 | elapsed 5.2m | ETA 3.8m\n",
      "Epoch 1/6 | Batch 28000/48196 ( 58.1%) | loss 1.1636 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 1/6 | Batch 28200/48196 ( 58.5%) | loss 1.1631 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 1/6 | Batch 28400/48196 ( 58.9%) | loss 1.1625 | elapsed 5.3m | ETA 3.7m\n",
      "Epoch 1/6 | Batch 28600/48196 ( 59.3%) | loss 1.1619 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 1/6 | Batch 28800/48196 ( 59.8%) | loss 1.1614 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 1/6 | Batch 29000/48196 ( 60.2%) | loss 1.1608 | elapsed 5.4m | ETA 3.6m\n",
      "Epoch 1/6 | Batch 29200/48196 ( 60.6%) | loss 1.1602 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 1/6 | Batch 29400/48196 ( 61.0%) | loss 1.1597 | elapsed 5.5m | ETA 3.5m\n",
      "Epoch 1/6 | Batch 29600/48196 ( 61.4%) | loss 1.1592 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 1/6 | Batch 29800/48196 ( 61.8%) | loss 1.1586 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 1/6 | Batch 30000/48196 ( 62.2%) | loss 1.1581 | elapsed 5.6m | ETA 3.4m\n",
      "Epoch 1/6 | Batch 30200/48196 ( 62.7%) | loss 1.1576 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 1/6 | Batch 30400/48196 ( 63.1%) | loss 1.1571 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 1/6 | Batch 30600/48196 ( 63.5%) | loss 1.1566 | elapsed 5.7m | ETA 3.3m\n",
      "Epoch 1/6 | Batch 30800/48196 ( 63.9%) | loss 1.1561 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 1/6 | Batch 31000/48196 ( 64.3%) | loss 1.1556 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 1/6 | Batch 31200/48196 ( 64.7%) | loss 1.1551 | elapsed 5.8m | ETA 3.2m\n",
      "Epoch 1/6 | Batch 31400/48196 ( 65.2%) | loss 1.1546 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 1/6 | Batch 31600/48196 ( 65.6%) | loss 1.1541 | elapsed 5.9m | ETA 3.1m\n",
      "Epoch 1/6 | Batch 31800/48196 ( 66.0%) | loss 1.1536 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 1/6 | Batch 32000/48196 ( 66.4%) | loss 1.1531 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 1/6 | Batch 32200/48196 ( 66.8%) | loss 1.1526 | elapsed 6.0m | ETA 3.0m\n",
      "Epoch 1/6 | Batch 32400/48196 ( 67.2%) | loss 1.1521 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 1/6 | Batch 32600/48196 ( 67.6%) | loss 1.1517 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 1/6 | Batch 32800/48196 ( 68.1%) | loss 1.1512 | elapsed 6.1m | ETA 2.9m\n",
      "Epoch 1/6 | Batch 33000/48196 ( 68.5%) | loss 1.1507 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 1/6 | Batch 33200/48196 ( 68.9%) | loss 1.1503 | elapsed 6.2m | ETA 2.8m\n",
      "Epoch 1/6 | Batch 33400/48196 ( 69.3%) | loss 1.1498 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 1/6 | Batch 33600/48196 ( 69.7%) | loss 1.1493 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 1/6 | Batch 33800/48196 ( 70.1%) | loss 1.1489 | elapsed 6.3m | ETA 2.7m\n",
      "Epoch 1/6 | Batch 34000/48196 ( 70.5%) | loss 1.1484 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 1/6 | Batch 34200/48196 ( 71.0%) | loss 1.1480 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 1/6 | Batch 34400/48196 ( 71.4%) | loss 1.1475 | elapsed 6.4m | ETA 2.6m\n",
      "Epoch 1/6 | Batch 34600/48196 ( 71.8%) | loss 1.1471 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 1/6 | Batch 34800/48196 ( 72.2%) | loss 1.1467 | elapsed 6.5m | ETA 2.5m\n",
      "Epoch 1/6 | Batch 35000/48196 ( 72.6%) | loss 1.1463 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 1/6 | Batch 35200/48196 ( 73.0%) | loss 1.1458 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 1/6 | Batch 35400/48196 ( 73.5%) | loss 1.1454 | elapsed 6.6m | ETA 2.4m\n",
      "Epoch 1/6 | Batch 35600/48196 ( 73.9%) | loss 1.1450 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 1/6 | Batch 35800/48196 ( 74.3%) | loss 1.1445 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 1/6 | Batch 36000/48196 ( 74.7%) | loss 1.1441 | elapsed 6.7m | ETA 2.3m\n",
      "Epoch 1/6 | Batch 36200/48196 ( 75.1%) | loss 1.1437 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 1/6 | Batch 36400/48196 ( 75.5%) | loss 1.1433 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 1/6 | Batch 36600/48196 ( 75.9%) | loss 1.1429 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 1/6 | Batch 36800/48196 ( 76.4%) | loss 1.1425 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 1/6 | Batch 37000/48196 ( 76.8%) | loss 1.1421 | elapsed 6.9m | ETA 2.1m\n",
      "Epoch 1/6 | Batch 37200/48196 ( 77.2%) | loss 1.1417 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 1/6 | Batch 37400/48196 ( 77.6%) | loss 1.1413 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 1/6 | Batch 37600/48196 ( 78.0%) | loss 1.1409 | elapsed 7.0m | ETA 2.0m\n",
      "Epoch 1/6 | Batch 37800/48196 ( 78.4%) | loss 1.1405 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 1/6 | Batch 38000/48196 ( 78.8%) | loss 1.1401 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 1/6 | Batch 38200/48196 ( 79.3%) | loss 1.1398 | elapsed 7.1m | ETA 1.9m\n",
      "Epoch 1/6 | Batch 38400/48196 ( 79.7%) | loss 1.1394 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 1/6 | Batch 38600/48196 ( 80.1%) | loss 1.1390 | elapsed 7.2m | ETA 1.8m\n",
      "Epoch 1/6 | Batch 38800/48196 ( 80.5%) | loss 1.1386 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 1/6 | Batch 39000/48196 ( 80.9%) | loss 1.1383 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 1/6 | Batch 39200/48196 ( 81.3%) | loss 1.1379 | elapsed 7.3m | ETA 1.7m\n",
      "Epoch 1/6 | Batch 39400/48196 ( 81.7%) | loss 1.1375 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 1/6 | Batch 39600/48196 ( 82.2%) | loss 1.1372 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 1/6 | Batch 39800/48196 ( 82.6%) | loss 1.1368 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 1/6 | Batch 40000/48196 ( 83.0%) | loss 1.1365 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 1/6 | Batch 40200/48196 ( 83.4%) | loss 1.1361 | elapsed 7.5m | ETA 1.5m\n",
      "Epoch 1/6 | Batch 40400/48196 ( 83.8%) | loss 1.1357 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 1/6 | Batch 40600/48196 ( 84.2%) | loss 1.1354 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 1/6 | Batch 40800/48196 ( 84.7%) | loss 1.1351 | elapsed 7.6m | ETA 1.4m\n",
      "Epoch 1/6 | Batch 41000/48196 ( 85.1%) | loss 1.1347 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 1/6 | Batch 41200/48196 ( 85.5%) | loss 1.1344 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 1/6 | Batch 41400/48196 ( 85.9%) | loss 1.1340 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 1/6 | Batch 41600/48196 ( 86.3%) | loss 1.1337 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 1/6 | Batch 41800/48196 ( 86.7%) | loss 1.1334 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 1/6 | Batch 42000/48196 ( 87.1%) | loss 1.1330 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 1/6 | Batch 42200/48196 ( 87.6%) | loss 1.1327 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 1/6 | Batch 42400/48196 ( 88.0%) | loss 1.1324 | elapsed 7.9m | ETA 1.1m\n",
      "Epoch 1/6 | Batch 42600/48196 ( 88.4%) | loss 1.1320 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 1/6 | Batch 42800/48196 ( 88.8%) | loss 1.1317 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 1/6 | Batch 43000/48196 ( 89.2%) | loss 1.1314 | elapsed 8.0m | ETA 1.0m\n",
      "Epoch 1/6 | Batch 43200/48196 ( 89.6%) | loss 1.1311 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 1/6 | Batch 43400/48196 ( 90.0%) | loss 1.1308 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 1/6 | Batch 43600/48196 ( 90.5%) | loss 1.1304 | elapsed 8.1m | ETA 0.9m\n",
      "Epoch 1/6 | Batch 43800/48196 ( 90.9%) | loss 1.1301 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 1/6 | Batch 44000/48196 ( 91.3%) | loss 1.1298 | elapsed 8.2m | ETA 0.8m\n",
      "Epoch 1/6 | Batch 44200/48196 ( 91.7%) | loss 1.1295 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 1/6 | Batch 44400/48196 ( 92.1%) | loss 1.1292 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 1/6 | Batch 44600/48196 ( 92.5%) | loss 1.1289 | elapsed 8.3m | ETA 0.7m\n",
      "Epoch 1/6 | Batch 44800/48196 ( 93.0%) | loss 1.1286 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 1/6 | Batch 45000/48196 ( 93.4%) | loss 1.1283 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 1/6 | Batch 45200/48196 ( 93.8%) | loss 1.1280 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 1/6 | Batch 45400/48196 ( 94.2%) | loss 1.1277 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 1/6 | Batch 45600/48196 ( 94.6%) | loss 1.1274 | elapsed 8.5m | ETA 0.5m\n",
      "Epoch 1/6 | Batch 45800/48196 ( 95.0%) | loss 1.1271 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 1/6 | Batch 46000/48196 ( 95.4%) | loss 1.1268 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 1/6 | Batch 46200/48196 ( 95.9%) | loss 1.1265 | elapsed 8.6m | ETA 0.4m\n",
      "Epoch 1/6 | Batch 46400/48196 ( 96.3%) | loss 1.1262 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 1/6 | Batch 46600/48196 ( 96.7%) | loss 1.1259 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 1/6 | Batch 46800/48196 ( 97.1%) | loss 1.1256 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 1/6 | Batch 47000/48196 ( 97.5%) | loss 1.1253 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 1/6 | Batch 47200/48196 ( 97.9%) | loss 1.1251 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 1/6 | Batch 47400/48196 ( 98.3%) | loss 1.1248 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 1/6 | Batch 47600/48196 ( 98.8%) | loss 1.1245 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 1/6 | Batch 47800/48196 ( 99.2%) | loss 1.1242 | elapsed 8.9m | ETA 0.1m\n",
      "Epoch 1/6 | Batch 48000/48196 ( 99.6%) | loss 1.1239 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 1/6 | Batch 48196/48196 (100.0%) | loss 1.1237 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 1 DONE | train_loss 1.0579 ppl 2.880 | val_loss 1.3051 ppl 3.688\n",
      "Epoch 2/6 | Batch 200/48196 (  0.4%) | loss 1.0565 | elapsed 0.0m | ETA 10.0m\n",
      "Epoch 2/6 | Batch 400/48196 (  0.8%) | loss 1.0556 | elapsed 0.1m | ETA 9.4m\n",
      "Epoch 2/6 | Batch 600/48196 (  1.2%) | loss 1.0552 | elapsed 0.1m | ETA 9.2m\n",
      "Epoch 2/6 | Batch 800/48196 (  1.7%) | loss 1.0551 | elapsed 0.2m | ETA 9.1m\n",
      "Epoch 2/6 | Batch 1000/48196 (  2.1%) | loss 1.0550 | elapsed 0.2m | ETA 9.0m\n",
      "Epoch 2/6 | Batch 1200/48196 (  2.5%) | loss 1.0554 | elapsed 0.2m | ETA 8.9m\n",
      "Epoch 2/6 | Batch 1400/48196 (  2.9%) | loss 1.0557 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 2/6 | Batch 1600/48196 (  3.3%) | loss 1.0558 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 2/6 | Batch 1800/48196 (  3.7%) | loss 1.0558 | elapsed 0.3m | ETA 8.7m\n",
      "Epoch 2/6 | Batch 2000/48196 (  4.1%) | loss 1.0556 | elapsed 0.4m | ETA 8.7m\n",
      "Epoch 2/6 | Batch 2200/48196 (  4.6%) | loss 1.0558 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 2/6 | Batch 2400/48196 (  5.0%) | loss 1.0559 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 2/6 | Batch 2600/48196 (  5.4%) | loss 1.0556 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 2/6 | Batch 2800/48196 (  5.8%) | loss 1.0555 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 2/6 | Batch 3000/48196 (  6.2%) | loss 1.0555 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 2/6 | Batch 3200/48196 (  6.6%) | loss 1.0555 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 2/6 | Batch 3400/48196 (  7.1%) | loss 1.0555 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 2/6 | Batch 3600/48196 (  7.5%) | loss 1.0555 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 2/6 | Batch 3800/48196 (  7.9%) | loss 1.0554 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 2/6 | Batch 4000/48196 (  8.3%) | loss 1.0554 | elapsed 0.7m | ETA 8.2m\n",
      "Epoch 2/6 | Batch 4200/48196 (  8.7%) | loss 1.0553 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 2/6 | Batch 4400/48196 (  9.1%) | loss 1.0554 | elapsed 0.8m | ETA 8.1m\n",
      "Epoch 2/6 | Batch 4600/48196 (  9.5%) | loss 1.0554 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 2/6 | Batch 4800/48196 ( 10.0%) | loss 1.0553 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 2/6 | Batch 5000/48196 ( 10.4%) | loss 1.0553 | elapsed 0.9m | ETA 8.0m\n",
      "Epoch 2/6 | Batch 5200/48196 ( 10.8%) | loss 1.0551 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 2/6 | Batch 5400/48196 ( 11.2%) | loss 1.0551 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 2/6 | Batch 5600/48196 ( 11.6%) | loss 1.0551 | elapsed 1.0m | ETA 7.9m\n",
      "Epoch 2/6 | Batch 5800/48196 ( 12.0%) | loss 1.0550 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 2/6 | Batch 6000/48196 ( 12.4%) | loss 1.0550 | elapsed 1.1m | ETA 7.8m\n",
      "Epoch 2/6 | Batch 6200/48196 ( 12.9%) | loss 1.0549 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 2/6 | Batch 6400/48196 ( 13.3%) | loss 1.0549 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 2/6 | Batch 6600/48196 ( 13.7%) | loss 1.0548 | elapsed 1.2m | ETA 7.7m\n",
      "Epoch 2/6 | Batch 6800/48196 ( 14.1%) | loss 1.0548 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 2/6 | Batch 7000/48196 ( 14.5%) | loss 1.0547 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 2/6 | Batch 7200/48196 ( 14.9%) | loss 1.0547 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 2/6 | Batch 7400/48196 ( 15.4%) | loss 1.0546 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 2/6 | Batch 7600/48196 ( 15.8%) | loss 1.0545 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 2/6 | Batch 7800/48196 ( 16.2%) | loss 1.0543 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 2/6 | Batch 8000/48196 ( 16.6%) | loss 1.0543 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 2/6 | Batch 8200/48196 ( 17.0%) | loss 1.0542 | elapsed 1.5m | ETA 7.4m\n",
      "Epoch 2/6 | Batch 8400/48196 ( 17.4%) | loss 1.0542 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 2/6 | Batch 8600/48196 ( 17.8%) | loss 1.0540 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 2/6 | Batch 8800/48196 ( 18.3%) | loss 1.0539 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 2/6 | Batch 9000/48196 ( 18.7%) | loss 1.0538 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 2/6 | Batch 9200/48196 ( 19.1%) | loss 1.0537 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 2/6 | Batch 9400/48196 ( 19.5%) | loss 1.0537 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 2/6 | Batch 9600/48196 ( 19.9%) | loss 1.0536 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 2/6 | Batch 9800/48196 ( 20.3%) | loss 1.0535 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 2/6 | Batch 10000/48196 ( 20.7%) | loss 1.0534 | elapsed 1.9m | ETA 7.1m\n",
      "Epoch 2/6 | Batch 10200/48196 ( 21.2%) | loss 1.0533 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 2/6 | Batch 10400/48196 ( 21.6%) | loss 1.0532 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 2/6 | Batch 10600/48196 ( 22.0%) | loss 1.0532 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 2/6 | Batch 10800/48196 ( 22.4%) | loss 1.0531 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 2/6 | Batch 11000/48196 ( 22.8%) | loss 1.0531 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 2/6 | Batch 11200/48196 ( 23.2%) | loss 1.0530 | elapsed 2.1m | ETA 6.9m\n",
      "Epoch 2/6 | Batch 11400/48196 ( 23.7%) | loss 1.0529 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 2/6 | Batch 11600/48196 ( 24.1%) | loss 1.0529 | elapsed 2.2m | ETA 6.8m\n",
      "Epoch 2/6 | Batch 11800/48196 ( 24.5%) | loss 1.0528 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 2/6 | Batch 12000/48196 ( 24.9%) | loss 1.0527 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 2/6 | Batch 12200/48196 ( 25.3%) | loss 1.0527 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 2/6 | Batch 12400/48196 ( 25.7%) | loss 1.0527 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 2/6 | Batch 12600/48196 ( 26.1%) | loss 1.0526 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 2/6 | Batch 12800/48196 ( 26.6%) | loss 1.0526 | elapsed 2.4m | ETA 6.6m\n",
      "Epoch 2/6 | Batch 13000/48196 ( 27.0%) | loss 1.0525 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 2/6 | Batch 13200/48196 ( 27.4%) | loss 1.0525 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 2/6 | Batch 13400/48196 ( 27.8%) | loss 1.0524 | elapsed 2.5m | ETA 6.5m\n",
      "Epoch 2/6 | Batch 13600/48196 ( 28.2%) | loss 1.0524 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 2/6 | Batch 13800/48196 ( 28.6%) | loss 1.0523 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 2/6 | Batch 14000/48196 ( 29.0%) | loss 1.0522 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 2/6 | Batch 14200/48196 ( 29.5%) | loss 1.0522 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 2/6 | Batch 14400/48196 ( 29.9%) | loss 1.0521 | elapsed 2.7m | ETA 6.3m\n",
      "Epoch 2/6 | Batch 14600/48196 ( 30.3%) | loss 1.0521 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 2/6 | Batch 14800/48196 ( 30.7%) | loss 1.0520 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 2/6 | Batch 15000/48196 ( 31.1%) | loss 1.0519 | elapsed 2.8m | ETA 6.2m\n",
      "Epoch 2/6 | Batch 15200/48196 ( 31.5%) | loss 1.0519 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 2/6 | Batch 15400/48196 ( 32.0%) | loss 1.0518 | elapsed 2.9m | ETA 6.1m\n",
      "Epoch 2/6 | Batch 15600/48196 ( 32.4%) | loss 1.0518 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 2/6 | Batch 15800/48196 ( 32.8%) | loss 1.0518 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 2/6 | Batch 16000/48196 ( 33.2%) | loss 1.0517 | elapsed 3.0m | ETA 6.0m\n",
      "Epoch 2/6 | Batch 16200/48196 ( 33.6%) | loss 1.0517 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 2/6 | Batch 16400/48196 ( 34.0%) | loss 1.0516 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 2/6 | Batch 16600/48196 ( 34.4%) | loss 1.0516 | elapsed 3.1m | ETA 5.9m\n",
      "Epoch 2/6 | Batch 16800/48196 ( 34.9%) | loss 1.0515 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 2/6 | Batch 17000/48196 ( 35.3%) | loss 1.0514 | elapsed 3.2m | ETA 5.8m\n",
      "Epoch 2/6 | Batch 17200/48196 ( 35.7%) | loss 1.0514 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 2/6 | Batch 17400/48196 ( 36.1%) | loss 1.0513 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 2/6 | Batch 17600/48196 ( 36.5%) | loss 1.0512 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 2/6 | Batch 17800/48196 ( 36.9%) | loss 1.0512 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 2/6 | Batch 18000/48196 ( 37.3%) | loss 1.0511 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 2/6 | Batch 18200/48196 ( 37.8%) | loss 1.0511 | elapsed 3.4m | ETA 5.6m\n",
      "Epoch 2/6 | Batch 18400/48196 ( 38.2%) | loss 1.0510 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 2/6 | Batch 18600/48196 ( 38.6%) | loss 1.0510 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 2/6 | Batch 18800/48196 ( 39.0%) | loss 1.0510 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 2/6 | Batch 19000/48196 ( 39.4%) | loss 1.0510 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 2/6 | Batch 19200/48196 ( 39.8%) | loss 1.0509 | elapsed 3.6m | ETA 5.4m\n",
      "Epoch 2/6 | Batch 19400/48196 ( 40.3%) | loss 1.0508 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 2/6 | Batch 19600/48196 ( 40.7%) | loss 1.0508 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 2/6 | Batch 19800/48196 ( 41.1%) | loss 1.0507 | elapsed 3.7m | ETA 5.3m\n",
      "Epoch 2/6 | Batch 20000/48196 ( 41.5%) | loss 1.0507 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 2/6 | Batch 20200/48196 ( 41.9%) | loss 1.0506 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 2/6 | Batch 20400/48196 ( 42.3%) | loss 1.0506 | elapsed 3.8m | ETA 5.2m\n",
      "Epoch 2/6 | Batch 20600/48196 ( 42.7%) | loss 1.0505 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 2/6 | Batch 20800/48196 ( 43.2%) | loss 1.0505 | elapsed 3.9m | ETA 5.1m\n",
      "Epoch 2/6 | Batch 21000/48196 ( 43.6%) | loss 1.0504 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 2/6 | Batch 21200/48196 ( 44.0%) | loss 1.0504 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 2/6 | Batch 21400/48196 ( 44.4%) | loss 1.0503 | elapsed 4.0m | ETA 5.0m\n",
      "Epoch 2/6 | Batch 21600/48196 ( 44.8%) | loss 1.0503 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 2/6 | Batch 21800/48196 ( 45.2%) | loss 1.0503 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 2/6 | Batch 22000/48196 ( 45.6%) | loss 1.0502 | elapsed 4.1m | ETA 4.9m\n",
      "Epoch 2/6 | Batch 22200/48196 ( 46.1%) | loss 1.0502 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 2/6 | Batch 22400/48196 ( 46.5%) | loss 1.0501 | elapsed 4.2m | ETA 4.8m\n",
      "Epoch 2/6 | Batch 22600/48196 ( 46.9%) | loss 1.0501 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 2/6 | Batch 22800/48196 ( 47.3%) | loss 1.0500 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 2/6 | Batch 23000/48196 ( 47.7%) | loss 1.0500 | elapsed 4.3m | ETA 4.7m\n",
      "Epoch 2/6 | Batch 23200/48196 ( 48.1%) | loss 1.0500 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 2/6 | Batch 23400/48196 ( 48.6%) | loss 1.0499 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 2/6 | Batch 23600/48196 ( 49.0%) | loss 1.0499 | elapsed 4.4m | ETA 4.6m\n",
      "Epoch 2/6 | Batch 23800/48196 ( 49.4%) | loss 1.0498 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 2/6 | Batch 24000/48196 ( 49.8%) | loss 1.0498 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 2/6 | Batch 24200/48196 ( 50.2%) | loss 1.0497 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 2/6 | Batch 24400/48196 ( 50.6%) | loss 1.0497 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 2/6 | Batch 24600/48196 ( 51.0%) | loss 1.0497 | elapsed 4.6m | ETA 4.4m\n",
      "Epoch 2/6 | Batch 24800/48196 ( 51.5%) | loss 1.0496 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 2/6 | Batch 25000/48196 ( 51.9%) | loss 1.0496 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 2/6 | Batch 25200/48196 ( 52.3%) | loss 1.0495 | elapsed 4.7m | ETA 4.3m\n",
      "Epoch 2/6 | Batch 25400/48196 ( 52.7%) | loss 1.0495 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 2/6 | Batch 25600/48196 ( 53.1%) | loss 1.0494 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 2/6 | Batch 25800/48196 ( 53.5%) | loss 1.0494 | elapsed 4.8m | ETA 4.2m\n",
      "Epoch 2/6 | Batch 26000/48196 ( 53.9%) | loss 1.0493 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 2/6 | Batch 26200/48196 ( 54.4%) | loss 1.0493 | elapsed 4.9m | ETA 4.1m\n",
      "Epoch 2/6 | Batch 26400/48196 ( 54.8%) | loss 1.0492 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 2/6 | Batch 26600/48196 ( 55.2%) | loss 1.0492 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 2/6 | Batch 26800/48196 ( 55.6%) | loss 1.0491 | elapsed 5.0m | ETA 4.0m\n",
      "Epoch 2/6 | Batch 27000/48196 ( 56.0%) | loss 1.0491 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 2/6 | Batch 27200/48196 ( 56.4%) | loss 1.0490 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 2/6 | Batch 27400/48196 ( 56.9%) | loss 1.0490 | elapsed 5.1m | ETA 3.9m\n",
      "Epoch 2/6 | Batch 27600/48196 ( 57.3%) | loss 1.0489 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 2/6 | Batch 27800/48196 ( 57.7%) | loss 1.0489 | elapsed 5.2m | ETA 3.8m\n",
      "Epoch 2/6 | Batch 28000/48196 ( 58.1%) | loss 1.0489 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 2/6 | Batch 28200/48196 ( 58.5%) | loss 1.0488 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 2/6 | Batch 28400/48196 ( 58.9%) | loss 1.0488 | elapsed 5.3m | ETA 3.7m\n",
      "Epoch 2/6 | Batch 28600/48196 ( 59.3%) | loss 1.0487 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 2/6 | Batch 28800/48196 ( 59.8%) | loss 1.0487 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 2/6 | Batch 29000/48196 ( 60.2%) | loss 1.0487 | elapsed 5.4m | ETA 3.6m\n",
      "Epoch 2/6 | Batch 29200/48196 ( 60.6%) | loss 1.0486 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 2/6 | Batch 29400/48196 ( 61.0%) | loss 1.0486 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 2/6 | Batch 29600/48196 ( 61.4%) | loss 1.0485 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 2/6 | Batch 29800/48196 ( 61.8%) | loss 1.0485 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 2/6 | Batch 30000/48196 ( 62.2%) | loss 1.0485 | elapsed 5.6m | ETA 3.4m\n",
      "Epoch 2/6 | Batch 30200/48196 ( 62.7%) | loss 1.0484 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 2/6 | Batch 30400/48196 ( 63.1%) | loss 1.0484 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 2/6 | Batch 30600/48196 ( 63.5%) | loss 1.0483 | elapsed 5.7m | ETA 3.3m\n",
      "Epoch 2/6 | Batch 30800/48196 ( 63.9%) | loss 1.0483 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 2/6 | Batch 31000/48196 ( 64.3%) | loss 1.0482 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 2/6 | Batch 31200/48196 ( 64.7%) | loss 1.0482 | elapsed 5.8m | ETA 3.2m\n",
      "Epoch 2/6 | Batch 31400/48196 ( 65.2%) | loss 1.0481 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 2/6 | Batch 31600/48196 ( 65.6%) | loss 1.0481 | elapsed 5.9m | ETA 3.1m\n",
      "Epoch 2/6 | Batch 31800/48196 ( 66.0%) | loss 1.0481 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 2/6 | Batch 32000/48196 ( 66.4%) | loss 1.0480 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 2/6 | Batch 32200/48196 ( 66.8%) | loss 1.0480 | elapsed 6.0m | ETA 3.0m\n",
      "Epoch 2/6 | Batch 32400/48196 ( 67.2%) | loss 1.0480 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 2/6 | Batch 32600/48196 ( 67.6%) | loss 1.0479 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 2/6 | Batch 32800/48196 ( 68.1%) | loss 1.0479 | elapsed 6.1m | ETA 2.9m\n",
      "Epoch 2/6 | Batch 33000/48196 ( 68.5%) | loss 1.0478 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 2/6 | Batch 33200/48196 ( 68.9%) | loss 1.0478 | elapsed 6.2m | ETA 2.8m\n",
      "Epoch 2/6 | Batch 33400/48196 ( 69.3%) | loss 1.0478 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 2/6 | Batch 33600/48196 ( 69.7%) | loss 1.0477 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 2/6 | Batch 33800/48196 ( 70.1%) | loss 1.0477 | elapsed 6.3m | ETA 2.7m\n",
      "Epoch 2/6 | Batch 34000/48196 ( 70.5%) | loss 1.0476 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 2/6 | Batch 34200/48196 ( 71.0%) | loss 1.0476 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 2/6 | Batch 34400/48196 ( 71.4%) | loss 1.0476 | elapsed 6.4m | ETA 2.6m\n",
      "Epoch 2/6 | Batch 34600/48196 ( 71.8%) | loss 1.0475 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 2/6 | Batch 34800/48196 ( 72.2%) | loss 1.0475 | elapsed 6.5m | ETA 2.5m\n",
      "Epoch 2/6 | Batch 35000/48196 ( 72.6%) | loss 1.0475 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 2/6 | Batch 35200/48196 ( 73.0%) | loss 1.0474 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 2/6 | Batch 35400/48196 ( 73.5%) | loss 1.0474 | elapsed 6.6m | ETA 2.4m\n",
      "Epoch 2/6 | Batch 35600/48196 ( 73.9%) | loss 1.0473 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 2/6 | Batch 35800/48196 ( 74.3%) | loss 1.0473 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 2/6 | Batch 36000/48196 ( 74.7%) | loss 1.0473 | elapsed 6.7m | ETA 2.3m\n",
      "Epoch 2/6 | Batch 36200/48196 ( 75.1%) | loss 1.0472 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 2/6 | Batch 36400/48196 ( 75.5%) | loss 1.0472 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 2/6 | Batch 36600/48196 ( 75.9%) | loss 1.0471 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 2/6 | Batch 36800/48196 ( 76.4%) | loss 1.0471 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 2/6 | Batch 37000/48196 ( 76.8%) | loss 1.0471 | elapsed 6.9m | ETA 2.1m\n",
      "Epoch 2/6 | Batch 37200/48196 ( 77.2%) | loss 1.0470 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 2/6 | Batch 37400/48196 ( 77.6%) | loss 1.0470 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 2/6 | Batch 37600/48196 ( 78.0%) | loss 1.0470 | elapsed 7.0m | ETA 2.0m\n",
      "Epoch 2/6 | Batch 37800/48196 ( 78.4%) | loss 1.0469 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 2/6 | Batch 38000/48196 ( 78.8%) | loss 1.0469 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 2/6 | Batch 38200/48196 ( 79.3%) | loss 1.0469 | elapsed 7.1m | ETA 1.9m\n",
      "Epoch 2/6 | Batch 38400/48196 ( 79.7%) | loss 1.0468 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 2/6 | Batch 38600/48196 ( 80.1%) | loss 1.0468 | elapsed 7.2m | ETA 1.8m\n",
      "Epoch 2/6 | Batch 38800/48196 ( 80.5%) | loss 1.0467 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 2/6 | Batch 39000/48196 ( 80.9%) | loss 1.0467 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 2/6 | Batch 39200/48196 ( 81.3%) | loss 1.0467 | elapsed 7.3m | ETA 1.7m\n",
      "Epoch 2/6 | Batch 39400/48196 ( 81.7%) | loss 1.0466 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 2/6 | Batch 39600/48196 ( 82.2%) | loss 1.0466 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 2/6 | Batch 39800/48196 ( 82.6%) | loss 1.0465 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 2/6 | Batch 40000/48196 ( 83.0%) | loss 1.0465 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 2/6 | Batch 40200/48196 ( 83.4%) | loss 1.0465 | elapsed 7.5m | ETA 1.5m\n",
      "Epoch 2/6 | Batch 40400/48196 ( 83.8%) | loss 1.0464 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 2/6 | Batch 40600/48196 ( 84.2%) | loss 1.0464 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 2/6 | Batch 40800/48196 ( 84.7%) | loss 1.0464 | elapsed 7.6m | ETA 1.4m\n",
      "Epoch 2/6 | Batch 41000/48196 ( 85.1%) | loss 1.0463 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 2/6 | Batch 41200/48196 ( 85.5%) | loss 1.0463 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 2/6 | Batch 41400/48196 ( 85.9%) | loss 1.0463 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 2/6 | Batch 41600/48196 ( 86.3%) | loss 1.0462 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 2/6 | Batch 41800/48196 ( 86.7%) | loss 1.0462 | elapsed 7.8m | ETA 1.2m\n",
      "Epoch 2/6 | Batch 42000/48196 ( 87.1%) | loss 1.0462 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 2/6 | Batch 42200/48196 ( 87.6%) | loss 1.0461 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 2/6 | Batch 42400/48196 ( 88.0%) | loss 1.0461 | elapsed 7.9m | ETA 1.1m\n",
      "Epoch 2/6 | Batch 42600/48196 ( 88.4%) | loss 1.0461 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 2/6 | Batch 42800/48196 ( 88.8%) | loss 1.0460 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 2/6 | Batch 43000/48196 ( 89.2%) | loss 1.0460 | elapsed 8.0m | ETA 1.0m\n",
      "Epoch 2/6 | Batch 43200/48196 ( 89.6%) | loss 1.0460 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 2/6 | Batch 43400/48196 ( 90.0%) | loss 1.0460 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 2/6 | Batch 43600/48196 ( 90.5%) | loss 1.0459 | elapsed 8.1m | ETA 0.9m\n",
      "Epoch 2/6 | Batch 43800/48196 ( 90.9%) | loss 1.0459 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 2/6 | Batch 44000/48196 ( 91.3%) | loss 1.0459 | elapsed 8.2m | ETA 0.8m\n",
      "Epoch 2/6 | Batch 44200/48196 ( 91.7%) | loss 1.0458 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 2/6 | Batch 44400/48196 ( 92.1%) | loss 1.0458 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 2/6 | Batch 44600/48196 ( 92.5%) | loss 1.0458 | elapsed 8.3m | ETA 0.7m\n",
      "Epoch 2/6 | Batch 44800/48196 ( 93.0%) | loss 1.0457 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 2/6 | Batch 45000/48196 ( 93.4%) | loss 1.0457 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 2/6 | Batch 45200/48196 ( 93.8%) | loss 1.0457 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 2/6 | Batch 45400/48196 ( 94.2%) | loss 1.0456 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 2/6 | Batch 45600/48196 ( 94.6%) | loss 1.0456 | elapsed 8.5m | ETA 0.5m\n",
      "Epoch 2/6 | Batch 45800/48196 ( 95.0%) | loss 1.0456 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 2/6 | Batch 46000/48196 ( 95.4%) | loss 1.0455 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 2/6 | Batch 46200/48196 ( 95.9%) | loss 1.0455 | elapsed 8.6m | ETA 0.4m\n",
      "Epoch 2/6 | Batch 46400/48196 ( 96.3%) | loss 1.0455 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 2/6 | Batch 46600/48196 ( 96.7%) | loss 1.0454 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 2/6 | Batch 46800/48196 ( 97.1%) | loss 1.0454 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 2/6 | Batch 47000/48196 ( 97.5%) | loss 1.0453 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 2/6 | Batch 47200/48196 ( 97.9%) | loss 1.0453 | elapsed 8.8m | ETA 0.2m\n",
      "Epoch 2/6 | Batch 47400/48196 ( 98.3%) | loss 1.0453 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 2/6 | Batch 47600/48196 ( 98.8%) | loss 1.0452 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 2/6 | Batch 47800/48196 ( 99.2%) | loss 1.0452 | elapsed 8.9m | ETA 0.1m\n",
      "Epoch 2/6 | Batch 48000/48196 ( 99.6%) | loss 1.0452 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 2/6 | Batch 48196/48196 (100.0%) | loss 1.0452 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 2 DONE | train_loss 1.0364 ppl 2.819 | val_loss 1.3245 ppl 3.760\n",
      "Epoch 3/6 | Batch 200/48196 (  0.4%) | loss 1.0337 | elapsed 0.0m | ETA 10.1m\n",
      "Epoch 3/6 | Batch 400/48196 (  0.8%) | loss 1.0355 | elapsed 0.1m | ETA 9.5m\n",
      "Epoch 3/6 | Batch 600/48196 (  1.2%) | loss 1.0359 | elapsed 0.1m | ETA 9.2m\n",
      "Epoch 3/6 | Batch 800/48196 (  1.7%) | loss 1.0360 | elapsed 0.2m | ETA 9.1m\n",
      "Epoch 3/6 | Batch 1000/48196 (  2.1%) | loss 1.0361 | elapsed 0.2m | ETA 9.0m\n",
      "Epoch 3/6 | Batch 1200/48196 (  2.5%) | loss 1.0361 | elapsed 0.2m | ETA 8.9m\n",
      "Epoch 3/6 | Batch 1400/48196 (  2.9%) | loss 1.0365 | elapsed 0.3m | ETA 8.9m\n",
      "Epoch 3/6 | Batch 1600/48196 (  3.3%) | loss 1.0364 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 3/6 | Batch 1800/48196 (  3.7%) | loss 1.0365 | elapsed 0.3m | ETA 8.7m\n",
      "Epoch 3/6 | Batch 2000/48196 (  4.1%) | loss 1.0367 | elapsed 0.4m | ETA 8.7m\n",
      "Epoch 3/6 | Batch 2200/48196 (  4.6%) | loss 1.0368 | elapsed 0.4m | ETA 8.7m\n",
      "Epoch 3/6 | Batch 2400/48196 (  5.0%) | loss 1.0368 | elapsed 0.5m | ETA 8.6m\n",
      "Epoch 3/6 | Batch 2600/48196 (  5.4%) | loss 1.0368 | elapsed 0.5m | ETA 8.6m\n",
      "Epoch 3/6 | Batch 2800/48196 (  5.8%) | loss 1.0367 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 3/6 | Batch 3000/48196 (  6.2%) | loss 1.0367 | elapsed 0.6m | ETA 8.5m\n",
      "Epoch 3/6 | Batch 3200/48196 (  6.6%) | loss 1.0367 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 3/6 | Batch 3400/48196 (  7.1%) | loss 1.0365 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 3/6 | Batch 3600/48196 (  7.5%) | loss 1.0365 | elapsed 0.7m | ETA 8.4m\n",
      "Epoch 3/6 | Batch 3800/48196 (  7.9%) | loss 1.0364 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 3/6 | Batch 4000/48196 (  8.3%) | loss 1.0365 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 3/6 | Batch 4200/48196 (  8.7%) | loss 1.0365 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 3/6 | Batch 4400/48196 (  9.1%) | loss 1.0365 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 3/6 | Batch 4600/48196 (  9.5%) | loss 1.0364 | elapsed 0.9m | ETA 8.2m\n",
      "Epoch 3/6 | Batch 4800/48196 ( 10.0%) | loss 1.0363 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 3/6 | Batch 5000/48196 ( 10.4%) | loss 1.0364 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 3/6 | Batch 5200/48196 ( 10.8%) | loss 1.0363 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 3/6 | Batch 5400/48196 ( 11.2%) | loss 1.0363 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 3/6 | Batch 5600/48196 ( 11.6%) | loss 1.0363 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 3/6 | Batch 5800/48196 ( 12.0%) | loss 1.0362 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 3/6 | Batch 6000/48196 ( 12.4%) | loss 1.0362 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 3/6 | Batch 6200/48196 ( 12.9%) | loss 1.0362 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 3/6 | Batch 6400/48196 ( 13.3%) | loss 1.0362 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 3/6 | Batch 6600/48196 ( 13.7%) | loss 1.0363 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 3/6 | Batch 6800/48196 ( 14.1%) | loss 1.0362 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 3/6 | Batch 7000/48196 ( 14.5%) | loss 1.0361 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 3/6 | Batch 7200/48196 ( 14.9%) | loss 1.0361 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 3/6 | Batch 7400/48196 ( 15.4%) | loss 1.0361 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 3/6 | Batch 7600/48196 ( 15.8%) | loss 1.0362 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 3/6 | Batch 7800/48196 ( 16.2%) | loss 1.0362 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 3/6 | Batch 8000/48196 ( 16.6%) | loss 1.0362 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 3/6 | Batch 8200/48196 ( 17.0%) | loss 1.0362 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 3/6 | Batch 8400/48196 ( 17.4%) | loss 1.0362 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 3/6 | Batch 8600/48196 ( 17.8%) | loss 1.0361 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 3/6 | Batch 8800/48196 ( 18.3%) | loss 1.0361 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 3/6 | Batch 9000/48196 ( 18.7%) | loss 1.0361 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 3/6 | Batch 9200/48196 ( 19.1%) | loss 1.0361 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 3/6 | Batch 9400/48196 ( 19.5%) | loss 1.0361 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 3/6 | Batch 9600/48196 ( 19.9%) | loss 1.0360 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 3/6 | Batch 9800/48196 ( 20.3%) | loss 1.0360 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 3/6 | Batch 10000/48196 ( 20.7%) | loss 1.0360 | elapsed 1.9m | ETA 7.1m\n",
      "Epoch 3/6 | Batch 10200/48196 ( 21.2%) | loss 1.0360 | elapsed 1.9m | ETA 7.1m\n",
      "Epoch 3/6 | Batch 10400/48196 ( 21.6%) | loss 1.0360 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 3/6 | Batch 10600/48196 ( 22.0%) | loss 1.0360 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 3/6 | Batch 10800/48196 ( 22.4%) | loss 1.0360 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 3/6 | Batch 11000/48196 ( 22.8%) | loss 1.0360 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 3/6 | Batch 11200/48196 ( 23.2%) | loss 1.0360 | elapsed 2.1m | ETA 6.9m\n",
      "Epoch 3/6 | Batch 11400/48196 ( 23.7%) | loss 1.0360 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 3/6 | Batch 11600/48196 ( 24.1%) | loss 1.0360 | elapsed 2.2m | ETA 6.8m\n",
      "Epoch 3/6 | Batch 11800/48196 ( 24.5%) | loss 1.0360 | elapsed 2.2m | ETA 6.8m\n",
      "Epoch 3/6 | Batch 12000/48196 ( 24.9%) | loss 1.0359 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 3/6 | Batch 12200/48196 ( 25.3%) | loss 1.0358 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 3/6 | Batch 12400/48196 ( 25.7%) | loss 1.0358 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 3/6 | Batch 12600/48196 ( 26.1%) | loss 1.0359 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 3/6 | Batch 12800/48196 ( 26.6%) | loss 1.0358 | elapsed 2.4m | ETA 6.6m\n",
      "Epoch 3/6 | Batch 13000/48196 ( 27.0%) | loss 1.0358 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 3/6 | Batch 13200/48196 ( 27.4%) | loss 1.0358 | elapsed 2.5m | ETA 6.5m\n",
      "Epoch 3/6 | Batch 13400/48196 ( 27.8%) | loss 1.0358 | elapsed 2.5m | ETA 6.5m\n",
      "Epoch 3/6 | Batch 13600/48196 ( 28.2%) | loss 1.0358 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 3/6 | Batch 13800/48196 ( 28.6%) | loss 1.0358 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 3/6 | Batch 14000/48196 ( 29.0%) | loss 1.0357 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 3/6 | Batch 14200/48196 ( 29.5%) | loss 1.0357 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 3/6 | Batch 14400/48196 ( 29.9%) | loss 1.0357 | elapsed 2.7m | ETA 6.3m\n",
      "Epoch 3/6 | Batch 14600/48196 ( 30.3%) | loss 1.0357 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 3/6 | Batch 14800/48196 ( 30.7%) | loss 1.0357 | elapsed 2.8m | ETA 6.2m\n",
      "Epoch 3/6 | Batch 15000/48196 ( 31.1%) | loss 1.0357 | elapsed 2.8m | ETA 6.2m\n",
      "Epoch 3/6 | Batch 15200/48196 ( 31.5%) | loss 1.0357 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 3/6 | Batch 15400/48196 ( 32.0%) | loss 1.0357 | elapsed 2.9m | ETA 6.1m\n",
      "Epoch 3/6 | Batch 15600/48196 ( 32.4%) | loss 1.0357 | elapsed 2.9m | ETA 6.1m\n",
      "Epoch 3/6 | Batch 15800/48196 ( 32.8%) | loss 1.0356 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 3/6 | Batch 16000/48196 ( 33.2%) | loss 1.0356 | elapsed 3.0m | ETA 6.0m\n",
      "Epoch 3/6 | Batch 16200/48196 ( 33.6%) | loss 1.0355 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 3/6 | Batch 16400/48196 ( 34.0%) | loss 1.0355 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 3/6 | Batch 16600/48196 ( 34.4%) | loss 1.0355 | elapsed 3.1m | ETA 5.9m\n",
      "Epoch 3/6 | Batch 16800/48196 ( 34.9%) | loss 1.0355 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 3/6 | Batch 17000/48196 ( 35.3%) | loss 1.0354 | elapsed 3.2m | ETA 5.8m\n",
      "Epoch 3/6 | Batch 17200/48196 ( 35.7%) | loss 1.0354 | elapsed 3.2m | ETA 5.8m\n",
      "Epoch 3/6 | Batch 17400/48196 ( 36.1%) | loss 1.0354 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 3/6 | Batch 17600/48196 ( 36.5%) | loss 1.0354 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 3/6 | Batch 17800/48196 ( 36.9%) | loss 1.0353 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 3/6 | Batch 18000/48196 ( 37.3%) | loss 1.0353 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 3/6 | Batch 18200/48196 ( 37.8%) | loss 1.0353 | elapsed 3.4m | ETA 5.6m\n",
      "Epoch 3/6 | Batch 18400/48196 ( 38.2%) | loss 1.0353 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 3/6 | Batch 18600/48196 ( 38.6%) | loss 1.0353 | elapsed 3.5m | ETA 5.5m\n",
      "Epoch 3/6 | Batch 18800/48196 ( 39.0%) | loss 1.0353 | elapsed 3.5m | ETA 5.5m\n",
      "Epoch 3/6 | Batch 19000/48196 ( 39.4%) | loss 1.0352 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 3/6 | Batch 19200/48196 ( 39.8%) | loss 1.0352 | elapsed 3.6m | ETA 5.4m\n",
      "Epoch 3/6 | Batch 19400/48196 ( 40.3%) | loss 1.0352 | elapsed 3.6m | ETA 5.4m\n",
      "Epoch 3/6 | Batch 19600/48196 ( 40.7%) | loss 1.0352 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 3/6 | Batch 19800/48196 ( 41.1%) | loss 1.0352 | elapsed 3.7m | ETA 5.3m\n",
      "Epoch 3/6 | Batch 20000/48196 ( 41.5%) | loss 1.0352 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 3/6 | Batch 20200/48196 ( 41.9%) | loss 1.0352 | elapsed 3.8m | ETA 5.2m\n",
      "Epoch 3/6 | Batch 20400/48196 ( 42.3%) | loss 1.0351 | elapsed 3.8m | ETA 5.2m\n",
      "Epoch 3/6 | Batch 20600/48196 ( 42.7%) | loss 1.0351 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 3/6 | Batch 20800/48196 ( 43.2%) | loss 1.0351 | elapsed 3.9m | ETA 5.1m\n",
      "Epoch 3/6 | Batch 21000/48196 ( 43.6%) | loss 1.0351 | elapsed 3.9m | ETA 5.1m\n",
      "Epoch 3/6 | Batch 21200/48196 ( 44.0%) | loss 1.0351 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 3/6 | Batch 21400/48196 ( 44.4%) | loss 1.0351 | elapsed 4.0m | ETA 5.0m\n",
      "Epoch 3/6 | Batch 21600/48196 ( 44.8%) | loss 1.0351 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 3/6 | Batch 21800/48196 ( 45.2%) | loss 1.0350 | elapsed 4.1m | ETA 4.9m\n",
      "Epoch 3/6 | Batch 22000/48196 ( 45.6%) | loss 1.0350 | elapsed 4.1m | ETA 4.9m\n",
      "Epoch 3/6 | Batch 22200/48196 ( 46.1%) | loss 1.0350 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 3/6 | Batch 22400/48196 ( 46.5%) | loss 1.0350 | elapsed 4.2m | ETA 4.8m\n",
      "Epoch 3/6 | Batch 22600/48196 ( 46.9%) | loss 1.0350 | elapsed 4.2m | ETA 4.8m\n",
      "Epoch 3/6 | Batch 22800/48196 ( 47.3%) | loss 1.0350 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 3/6 | Batch 23000/48196 ( 47.7%) | loss 1.0350 | elapsed 4.3m | ETA 4.7m\n",
      "Epoch 3/6 | Batch 23200/48196 ( 48.1%) | loss 1.0349 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 3/6 | Batch 23400/48196 ( 48.6%) | loss 1.0349 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 3/6 | Batch 23600/48196 ( 49.0%) | loss 1.0349 | elapsed 4.4m | ETA 4.6m\n",
      "Epoch 3/6 | Batch 23800/48196 ( 49.4%) | loss 1.0349 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 3/6 | Batch 24000/48196 ( 49.8%) | loss 1.0349 | elapsed 4.5m | ETA 4.5m\n",
      "Epoch 3/6 | Batch 24200/48196 ( 50.2%) | loss 1.0349 | elapsed 4.5m | ETA 4.5m\n",
      "Epoch 3/6 | Batch 24400/48196 ( 50.6%) | loss 1.0348 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 3/6 | Batch 24600/48196 ( 51.0%) | loss 1.0348 | elapsed 4.6m | ETA 4.4m\n",
      "Epoch 3/6 | Batch 24800/48196 ( 51.5%) | loss 1.0348 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 3/6 | Batch 25000/48196 ( 51.9%) | loss 1.0348 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 3/6 | Batch 25200/48196 ( 52.3%) | loss 1.0347 | elapsed 4.7m | ETA 4.3m\n",
      "Epoch 3/6 | Batch 25400/48196 ( 52.7%) | loss 1.0347 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 3/6 | Batch 25600/48196 ( 53.1%) | loss 1.0347 | elapsed 4.8m | ETA 4.2m\n",
      "Epoch 3/6 | Batch 25800/48196 ( 53.5%) | loss 1.0347 | elapsed 4.8m | ETA 4.2m\n",
      "Epoch 3/6 | Batch 26000/48196 ( 53.9%) | loss 1.0347 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 3/6 | Batch 26200/48196 ( 54.4%) | loss 1.0347 | elapsed 4.9m | ETA 4.1m\n",
      "Epoch 3/6 | Batch 26400/48196 ( 54.8%) | loss 1.0347 | elapsed 4.9m | ETA 4.1m\n",
      "Epoch 3/6 | Batch 26600/48196 ( 55.2%) | loss 1.0346 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 3/6 | Batch 26800/48196 ( 55.6%) | loss 1.0346 | elapsed 5.0m | ETA 4.0m\n",
      "Epoch 3/6 | Batch 27000/48196 ( 56.0%) | loss 1.0346 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 3/6 | Batch 27200/48196 ( 56.4%) | loss 1.0346 | elapsed 5.1m | ETA 3.9m\n",
      "Epoch 3/6 | Batch 27400/48196 ( 56.9%) | loss 1.0346 | elapsed 5.1m | ETA 3.9m\n",
      "Epoch 3/6 | Batch 27600/48196 ( 57.3%) | loss 1.0346 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 3/6 | Batch 27800/48196 ( 57.7%) | loss 1.0346 | elapsed 5.2m | ETA 3.8m\n",
      "Epoch 3/6 | Batch 28000/48196 ( 58.1%) | loss 1.0346 | elapsed 5.2m | ETA 3.8m\n",
      "Epoch 3/6 | Batch 28200/48196 ( 58.5%) | loss 1.0345 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 3/6 | Batch 28400/48196 ( 58.9%) | loss 1.0345 | elapsed 5.3m | ETA 3.7m\n",
      "Epoch 3/6 | Batch 28600/48196 ( 59.3%) | loss 1.0345 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 3/6 | Batch 28800/48196 ( 59.8%) | loss 1.0345 | elapsed 5.4m | ETA 3.6m\n",
      "Epoch 3/6 | Batch 29000/48196 ( 60.2%) | loss 1.0345 | elapsed 5.4m | ETA 3.6m\n",
      "Epoch 3/6 | Batch 29200/48196 ( 60.6%) | loss 1.0345 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 3/6 | Batch 29400/48196 ( 61.0%) | loss 1.0345 | elapsed 5.5m | ETA 3.5m\n",
      "Epoch 3/6 | Batch 29600/48196 ( 61.4%) | loss 1.0345 | elapsed 5.5m | ETA 3.5m\n",
      "Epoch 3/6 | Batch 29800/48196 ( 61.8%) | loss 1.0345 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 3/6 | Batch 30000/48196 ( 62.2%) | loss 1.0345 | elapsed 5.6m | ETA 3.4m\n",
      "Epoch 3/6 | Batch 30200/48196 ( 62.7%) | loss 1.0344 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 3/6 | Batch 30400/48196 ( 63.1%) | loss 1.0344 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 3/6 | Batch 30600/48196 ( 63.5%) | loss 1.0344 | elapsed 5.7m | ETA 3.3m\n",
      "Epoch 3/6 | Batch 30800/48196 ( 63.9%) | loss 1.0344 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 3/6 | Batch 31000/48196 ( 64.3%) | loss 1.0344 | elapsed 5.8m | ETA 3.2m\n",
      "Epoch 3/6 | Batch 31200/48196 ( 64.7%) | loss 1.0344 | elapsed 5.8m | ETA 3.2m\n",
      "Epoch 3/6 | Batch 31400/48196 ( 65.2%) | loss 1.0344 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 3/6 | Batch 31600/48196 ( 65.6%) | loss 1.0344 | elapsed 5.9m | ETA 3.1m\n",
      "Epoch 3/6 | Batch 31800/48196 ( 66.0%) | loss 1.0343 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 3/6 | Batch 32000/48196 ( 66.4%) | loss 1.0343 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 3/6 | Batch 32200/48196 ( 66.8%) | loss 1.0343 | elapsed 6.0m | ETA 3.0m\n",
      "Epoch 3/6 | Batch 32400/48196 ( 67.2%) | loss 1.0343 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 3/6 | Batch 32600/48196 ( 67.6%) | loss 1.0343 | elapsed 6.1m | ETA 2.9m\n",
      "Epoch 3/6 | Batch 32800/48196 ( 68.1%) | loss 1.0343 | elapsed 6.1m | ETA 2.9m\n",
      "Epoch 3/6 | Batch 33000/48196 ( 68.5%) | loss 1.0343 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 3/6 | Batch 33200/48196 ( 68.9%) | loss 1.0343 | elapsed 6.2m | ETA 2.8m\n",
      "Epoch 3/6 | Batch 33400/48196 ( 69.3%) | loss 1.0343 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 3/6 | Batch 33600/48196 ( 69.7%) | loss 1.0343 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 3/6 | Batch 33800/48196 ( 70.1%) | loss 1.0342 | elapsed 6.3m | ETA 2.7m\n",
      "Epoch 3/6 | Batch 34000/48196 ( 70.5%) | loss 1.0342 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 3/6 | Batch 34200/48196 ( 71.0%) | loss 1.0342 | elapsed 6.4m | ETA 2.6m\n",
      "Epoch 3/6 | Batch 34400/48196 ( 71.4%) | loss 1.0342 | elapsed 6.4m | ETA 2.6m\n",
      "Epoch 3/6 | Batch 34600/48196 ( 71.8%) | loss 1.0342 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 3/6 | Batch 34800/48196 ( 72.2%) | loss 1.0342 | elapsed 6.5m | ETA 2.5m\n",
      "Epoch 3/6 | Batch 35000/48196 ( 72.6%) | loss 1.0342 | elapsed 6.5m | ETA 2.5m\n",
      "Epoch 3/6 | Batch 35200/48196 ( 73.0%) | loss 1.0342 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 3/6 | Batch 35400/48196 ( 73.5%) | loss 1.0342 | elapsed 6.6m | ETA 2.4m\n",
      "Epoch 3/6 | Batch 35600/48196 ( 73.9%) | loss 1.0342 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 3/6 | Batch 35800/48196 ( 74.3%) | loss 1.0341 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 3/6 | Batch 36000/48196 ( 74.7%) | loss 1.0341 | elapsed 6.7m | ETA 2.3m\n",
      "Epoch 3/6 | Batch 36200/48196 ( 75.1%) | loss 1.0341 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 3/6 | Batch 36400/48196 ( 75.5%) | loss 1.0341 | elapsed 6.8m | ETA 2.2m\n",
      "Epoch 3/6 | Batch 36600/48196 ( 75.9%) | loss 1.0341 | elapsed 6.8m | ETA 2.2m\n",
      "Epoch 3/6 | Batch 36800/48196 ( 76.4%) | loss 1.0341 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 3/6 | Batch 37000/48196 ( 76.8%) | loss 1.0341 | elapsed 6.9m | ETA 2.1m\n",
      "Epoch 3/6 | Batch 37200/48196 ( 77.2%) | loss 1.0341 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 3/6 | Batch 37400/48196 ( 77.6%) | loss 1.0341 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 3/6 | Batch 37600/48196 ( 78.0%) | loss 1.0341 | elapsed 7.0m | ETA 2.0m\n",
      "Epoch 3/6 | Batch 37800/48196 ( 78.4%) | loss 1.0341 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 3/6 | Batch 38000/48196 ( 78.8%) | loss 1.0340 | elapsed 7.1m | ETA 1.9m\n",
      "Epoch 3/6 | Batch 38200/48196 ( 79.3%) | loss 1.0340 | elapsed 7.1m | ETA 1.9m\n",
      "Epoch 3/6 | Batch 38400/48196 ( 79.7%) | loss 1.0340 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 3/6 | Batch 38600/48196 ( 80.1%) | loss 1.0340 | elapsed 7.2m | ETA 1.8m\n",
      "Epoch 3/6 | Batch 38800/48196 ( 80.5%) | loss 1.0340 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 3/6 | Batch 39000/48196 ( 80.9%) | loss 1.0340 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 3/6 | Batch 39200/48196 ( 81.3%) | loss 1.0340 | elapsed 7.3m | ETA 1.7m\n",
      "Epoch 3/6 | Batch 39400/48196 ( 81.7%) | loss 1.0340 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 3/6 | Batch 39600/48196 ( 82.2%) | loss 1.0339 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 3/6 | Batch 39800/48196 ( 82.6%) | loss 1.0339 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 3/6 | Batch 40000/48196 ( 83.0%) | loss 1.0339 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 3/6 | Batch 40200/48196 ( 83.4%) | loss 1.0339 | elapsed 7.5m | ETA 1.5m\n",
      "Epoch 3/6 | Batch 40400/48196 ( 83.8%) | loss 1.0339 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 3/6 | Batch 40600/48196 ( 84.2%) | loss 1.0339 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 3/6 | Batch 40800/48196 ( 84.7%) | loss 1.0339 | elapsed 7.6m | ETA 1.4m\n",
      "Epoch 3/6 | Batch 41000/48196 ( 85.1%) | loss 1.0339 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 3/6 | Batch 41200/48196 ( 85.5%) | loss 1.0339 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 3/6 | Batch 41400/48196 ( 85.9%) | loss 1.0339 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 3/6 | Batch 41600/48196 ( 86.3%) | loss 1.0338 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 3/6 | Batch 41800/48196 ( 86.7%) | loss 1.0338 | elapsed 7.8m | ETA 1.2m\n",
      "Epoch 3/6 | Batch 42000/48196 ( 87.1%) | loss 1.0338 | elapsed 7.8m | ETA 1.2m\n",
      "Epoch 3/6 | Batch 42200/48196 ( 87.6%) | loss 1.0338 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 3/6 | Batch 42400/48196 ( 88.0%) | loss 1.0338 | elapsed 7.9m | ETA 1.1m\n",
      "Epoch 3/6 | Batch 42600/48196 ( 88.4%) | loss 1.0338 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 3/6 | Batch 42800/48196 ( 88.8%) | loss 1.0338 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 3/6 | Batch 43000/48196 ( 89.2%) | loss 1.0338 | elapsed 8.0m | ETA 1.0m\n",
      "Epoch 3/6 | Batch 43200/48196 ( 89.6%) | loss 1.0337 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 3/6 | Batch 43400/48196 ( 90.0%) | loss 1.0337 | elapsed 8.1m | ETA 0.9m\n",
      "Epoch 3/6 | Batch 43600/48196 ( 90.5%) | loss 1.0337 | elapsed 8.1m | ETA 0.9m\n",
      "Epoch 3/6 | Batch 43800/48196 ( 90.9%) | loss 1.0337 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 3/6 | Batch 44000/48196 ( 91.3%) | loss 1.0337 | elapsed 8.2m | ETA 0.8m\n",
      "Epoch 3/6 | Batch 44200/48196 ( 91.7%) | loss 1.0337 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 3/6 | Batch 44400/48196 ( 92.1%) | loss 1.0337 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 3/6 | Batch 44600/48196 ( 92.5%) | loss 1.0337 | elapsed 8.3m | ETA 0.7m\n",
      "Epoch 3/6 | Batch 44800/48196 ( 93.0%) | loss 1.0336 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 3/6 | Batch 45000/48196 ( 93.4%) | loss 1.0336 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 3/6 | Batch 45200/48196 ( 93.8%) | loss 1.0336 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 3/6 | Batch 45400/48196 ( 94.2%) | loss 1.0336 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 3/6 | Batch 45600/48196 ( 94.6%) | loss 1.0336 | elapsed 8.5m | ETA 0.5m\n",
      "Epoch 3/6 | Batch 45800/48196 ( 95.0%) | loss 1.0336 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 3/6 | Batch 46000/48196 ( 95.4%) | loss 1.0336 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 3/6 | Batch 46200/48196 ( 95.9%) | loss 1.0336 | elapsed 8.6m | ETA 0.4m\n",
      "Epoch 3/6 | Batch 46400/48196 ( 96.3%) | loss 1.0336 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 3/6 | Batch 46600/48196 ( 96.7%) | loss 1.0335 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 3/6 | Batch 46800/48196 ( 97.1%) | loss 1.0335 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 3/6 | Batch 47000/48196 ( 97.5%) | loss 1.0335 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 3/6 | Batch 47200/48196 ( 97.9%) | loss 1.0335 | elapsed 8.8m | ETA 0.2m\n",
      "Epoch 3/6 | Batch 47400/48196 ( 98.3%) | loss 1.0335 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 3/6 | Batch 47600/48196 ( 98.8%) | loss 1.0335 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 3/6 | Batch 47800/48196 ( 99.2%) | loss 1.0335 | elapsed 8.9m | ETA 0.1m\n",
      "Epoch 3/6 | Batch 48000/48196 ( 99.6%) | loss 1.0335 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 3/6 | Batch 48196/48196 (100.0%) | loss 1.0334 | elapsed 9.0m | ETA 0.0m\n",
      "Epoch 3 DONE | train_loss 1.0293 ppl 2.799 | val_loss 1.3330 ppl 3.792\n",
      "Epoch 4/6 | Batch 200/48196 (  0.4%) | loss 1.0310 | elapsed 0.0m | ETA 10.1m\n",
      "Epoch 4/6 | Batch 400/48196 (  0.8%) | loss 1.0301 | elapsed 0.1m | ETA 9.4m\n",
      "Epoch 4/6 | Batch 600/48196 (  1.2%) | loss 1.0296 | elapsed 0.1m | ETA 9.2m\n",
      "Epoch 4/6 | Batch 800/48196 (  1.7%) | loss 1.0302 | elapsed 0.2m | ETA 9.1m\n",
      "Epoch 4/6 | Batch 1000/48196 (  2.1%) | loss 1.0301 | elapsed 0.2m | ETA 9.0m\n",
      "Epoch 4/6 | Batch 1200/48196 (  2.5%) | loss 1.0301 | elapsed 0.2m | ETA 8.9m\n",
      "Epoch 4/6 | Batch 1400/48196 (  2.9%) | loss 1.0299 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 4/6 | Batch 1600/48196 (  3.3%) | loss 1.0295 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 4/6 | Batch 1800/48196 (  3.7%) | loss 1.0294 | elapsed 0.3m | ETA 8.7m\n",
      "Epoch 4/6 | Batch 2000/48196 (  4.1%) | loss 1.0295 | elapsed 0.4m | ETA 8.7m\n",
      "Epoch 4/6 | Batch 2200/48196 (  4.6%) | loss 1.0295 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 4/6 | Batch 2400/48196 (  5.0%) | loss 1.0295 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 4/6 | Batch 2600/48196 (  5.4%) | loss 1.0296 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 4/6 | Batch 2800/48196 (  5.8%) | loss 1.0299 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 4/6 | Batch 3000/48196 (  6.2%) | loss 1.0300 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 4/6 | Batch 3200/48196 (  6.6%) | loss 1.0301 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 4/6 | Batch 3400/48196 (  7.1%) | loss 1.0301 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 4/6 | Batch 3600/48196 (  7.5%) | loss 1.0302 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 4/6 | Batch 3800/48196 (  7.9%) | loss 1.0302 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 4/6 | Batch 4000/48196 (  8.3%) | loss 1.0302 | elapsed 0.7m | ETA 8.2m\n",
      "Epoch 4/6 | Batch 4200/48196 (  8.7%) | loss 1.0301 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 4/6 | Batch 4400/48196 (  9.1%) | loss 1.0301 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 4/6 | Batch 4600/48196 (  9.5%) | loss 1.0301 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 4/6 | Batch 4800/48196 ( 10.0%) | loss 1.0300 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 4/6 | Batch 5000/48196 ( 10.4%) | loss 1.0300 | elapsed 0.9m | ETA 8.0m\n",
      "Epoch 4/6 | Batch 5200/48196 ( 10.8%) | loss 1.0301 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 4/6 | Batch 5400/48196 ( 11.2%) | loss 1.0301 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 4/6 | Batch 5600/48196 ( 11.6%) | loss 1.0301 | elapsed 1.0m | ETA 7.9m\n",
      "Epoch 4/6 | Batch 5800/48196 ( 12.0%) | loss 1.0301 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 4/6 | Batch 6000/48196 ( 12.4%) | loss 1.0302 | elapsed 1.1m | ETA 7.8m\n",
      "Epoch 4/6 | Batch 6200/48196 ( 12.9%) | loss 1.0301 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 4/6 | Batch 6400/48196 ( 13.3%) | loss 1.0302 | elapsed 1.2m | ETA 7.8m\n",
      "Epoch 4/6 | Batch 6600/48196 ( 13.7%) | loss 1.0301 | elapsed 1.2m | ETA 7.7m\n",
      "Epoch 4/6 | Batch 6800/48196 ( 14.1%) | loss 1.0301 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 4/6 | Batch 7000/48196 ( 14.5%) | loss 1.0301 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 4/6 | Batch 7200/48196 ( 14.9%) | loss 1.0301 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 4/6 | Batch 7400/48196 ( 15.4%) | loss 1.0300 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 4/6 | Batch 7600/48196 ( 15.8%) | loss 1.0300 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 4/6 | Batch 7800/48196 ( 16.2%) | loss 1.0300 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 4/6 | Batch 8000/48196 ( 16.6%) | loss 1.0299 | elapsed 1.5m | ETA 7.5m\n",
      "Epoch 4/6 | Batch 8200/48196 ( 17.0%) | loss 1.0300 | elapsed 1.5m | ETA 7.4m\n",
      "Epoch 4/6 | Batch 8400/48196 ( 17.4%) | loss 1.0299 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 4/6 | Batch 8600/48196 ( 17.8%) | loss 1.0300 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 4/6 | Batch 8800/48196 ( 18.3%) | loss 1.0300 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 4/6 | Batch 9000/48196 ( 18.7%) | loss 1.0300 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 4/6 | Batch 9200/48196 ( 19.1%) | loss 1.0300 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 4/6 | Batch 9400/48196 ( 19.5%) | loss 1.0300 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 4/6 | Batch 9600/48196 ( 19.9%) | loss 1.0300 | elapsed 1.8m | ETA 7.2m\n",
      "Epoch 4/6 | Batch 9800/48196 ( 20.3%) | loss 1.0300 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 4/6 | Batch 10000/48196 ( 20.7%) | loss 1.0299 | elapsed 1.9m | ETA 7.1m\n",
      "Epoch 4/6 | Batch 10200/48196 ( 21.2%) | loss 1.0299 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 4/6 | Batch 10400/48196 ( 21.6%) | loss 1.0299 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 4/6 | Batch 10600/48196 ( 22.0%) | loss 1.0300 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 4/6 | Batch 10800/48196 ( 22.4%) | loss 1.0300 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 4/6 | Batch 11000/48196 ( 22.8%) | loss 1.0300 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 4/6 | Batch 11200/48196 ( 23.2%) | loss 1.0300 | elapsed 2.1m | ETA 6.9m\n",
      "Epoch 4/6 | Batch 11400/48196 ( 23.7%) | loss 1.0299 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 4/6 | Batch 11600/48196 ( 24.1%) | loss 1.0299 | elapsed 2.2m | ETA 6.8m\n",
      "Epoch 4/6 | Batch 11800/48196 ( 24.5%) | loss 1.0298 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 4/6 | Batch 12000/48196 ( 24.9%) | loss 1.0298 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 4/6 | Batch 12200/48196 ( 25.3%) | loss 1.0298 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 4/6 | Batch 12400/48196 ( 25.7%) | loss 1.0298 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 4/6 | Batch 12600/48196 ( 26.1%) | loss 1.0299 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 4/6 | Batch 12800/48196 ( 26.6%) | loss 1.0299 | elapsed 2.4m | ETA 6.6m\n",
      "Epoch 4/6 | Batch 13000/48196 ( 27.0%) | loss 1.0298 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 4/6 | Batch 13200/48196 ( 27.4%) | loss 1.0299 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 4/6 | Batch 13400/48196 ( 27.8%) | loss 1.0299 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 4/6 | Batch 13600/48196 ( 28.2%) | loss 1.0298 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 4/6 | Batch 13800/48196 ( 28.6%) | loss 1.0298 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 4/6 | Batch 14000/48196 ( 29.0%) | loss 1.0299 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 4/6 | Batch 14200/48196 ( 29.5%) | loss 1.0298 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 4/6 | Batch 14400/48196 ( 29.9%) | loss 1.0298 | elapsed 2.7m | ETA 6.3m\n",
      "Epoch 4/6 | Batch 14600/48196 ( 30.3%) | loss 1.0298 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 4/6 | Batch 14800/48196 ( 30.7%) | loss 1.0298 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 4/6 | Batch 15000/48196 ( 31.1%) | loss 1.0298 | elapsed 2.8m | ETA 6.2m\n",
      "Epoch 4/6 | Batch 15200/48196 ( 31.5%) | loss 1.0298 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 4/6 | Batch 15400/48196 ( 32.0%) | loss 1.0298 | elapsed 2.9m | ETA 6.1m\n",
      "Epoch 4/6 | Batch 15600/48196 ( 32.4%) | loss 1.0298 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 4/6 | Batch 15800/48196 ( 32.8%) | loss 1.0298 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 4/6 | Batch 16000/48196 ( 33.2%) | loss 1.0297 | elapsed 3.0m | ETA 6.0m\n",
      "Epoch 4/6 | Batch 16200/48196 ( 33.6%) | loss 1.0297 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 4/6 | Batch 16400/48196 ( 34.0%) | loss 1.0297 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 4/6 | Batch 16600/48196 ( 34.4%) | loss 1.0297 | elapsed 3.1m | ETA 5.9m\n",
      "Epoch 4/6 | Batch 16800/48196 ( 34.9%) | loss 1.0296 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 4/6 | Batch 17000/48196 ( 35.3%) | loss 1.0296 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 4/6 | Batch 17200/48196 ( 35.7%) | loss 1.0296 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 4/6 | Batch 17400/48196 ( 36.1%) | loss 1.0296 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 4/6 | Batch 17600/48196 ( 36.5%) | loss 1.0296 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 4/6 | Batch 17800/48196 ( 36.9%) | loss 1.0296 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 4/6 | Batch 18000/48196 ( 37.3%) | loss 1.0296 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 4/6 | Batch 18200/48196 ( 37.8%) | loss 1.0295 | elapsed 3.4m | ETA 5.6m\n",
      "Epoch 4/6 | Batch 18400/48196 ( 38.2%) | loss 1.0295 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 4/6 | Batch 18600/48196 ( 38.6%) | loss 1.0295 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 4/6 | Batch 18800/48196 ( 39.0%) | loss 1.0295 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 4/6 | Batch 19000/48196 ( 39.4%) | loss 1.0295 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 4/6 | Batch 19200/48196 ( 39.8%) | loss 1.0295 | elapsed 3.6m | ETA 5.4m\n",
      "Epoch 4/6 | Batch 19400/48196 ( 40.3%) | loss 1.0295 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 4/6 | Batch 19600/48196 ( 40.7%) | loss 1.0295 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 4/6 | Batch 19800/48196 ( 41.1%) | loss 1.0295 | elapsed 3.7m | ETA 5.3m\n",
      "Epoch 4/6 | Batch 20000/48196 ( 41.5%) | loss 1.0295 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 4/6 | Batch 20200/48196 ( 41.9%) | loss 1.0295 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 4/6 | Batch 20400/48196 ( 42.3%) | loss 1.0295 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 4/6 | Batch 20600/48196 ( 42.7%) | loss 1.0295 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 4/6 | Batch 20800/48196 ( 43.2%) | loss 1.0295 | elapsed 3.9m | ETA 5.1m\n",
      "Epoch 4/6 | Batch 21000/48196 ( 43.6%) | loss 1.0295 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 4/6 | Batch 21200/48196 ( 44.0%) | loss 1.0294 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 4/6 | Batch 21400/48196 ( 44.4%) | loss 1.0294 | elapsed 4.0m | ETA 5.0m\n",
      "Epoch 4/6 | Batch 21600/48196 ( 44.8%) | loss 1.0294 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 4/6 | Batch 21800/48196 ( 45.2%) | loss 1.0294 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 4/6 | Batch 22000/48196 ( 45.6%) | loss 1.0294 | elapsed 4.1m | ETA 4.9m\n",
      "Epoch 4/6 | Batch 22200/48196 ( 46.1%) | loss 1.0294 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 4/6 | Batch 22400/48196 ( 46.5%) | loss 1.0294 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 4/6 | Batch 22600/48196 ( 46.9%) | loss 1.0294 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 4/6 | Batch 22800/48196 ( 47.3%) | loss 1.0294 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 4/6 | Batch 23000/48196 ( 47.7%) | loss 1.0294 | elapsed 4.3m | ETA 4.7m\n",
      "Epoch 4/6 | Batch 23200/48196 ( 48.1%) | loss 1.0294 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 4/6 | Batch 23400/48196 ( 48.6%) | loss 1.0294 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 4/6 | Batch 23600/48196 ( 49.0%) | loss 1.0293 | elapsed 4.4m | ETA 4.6m\n",
      "Epoch 4/6 | Batch 23800/48196 ( 49.4%) | loss 1.0293 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 4/6 | Batch 24000/48196 ( 49.8%) | loss 1.0293 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 4/6 | Batch 24200/48196 ( 50.2%) | loss 1.0293 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 4/6 | Batch 24400/48196 ( 50.6%) | loss 1.0293 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 4/6 | Batch 24600/48196 ( 51.0%) | loss 1.0293 | elapsed 4.6m | ETA 4.4m\n",
      "Epoch 4/6 | Batch 24800/48196 ( 51.5%) | loss 1.0293 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 4/6 | Batch 25000/48196 ( 51.9%) | loss 1.0293 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 4/6 | Batch 25200/48196 ( 52.3%) | loss 1.0293 | elapsed 4.7m | ETA 4.3m\n",
      "Epoch 4/6 | Batch 25400/48196 ( 52.7%) | loss 1.0293 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 4/6 | Batch 25600/48196 ( 53.1%) | loss 1.0293 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 4/6 | Batch 25800/48196 ( 53.5%) | loss 1.0292 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 4/6 | Batch 26000/48196 ( 53.9%) | loss 1.0292 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 4/6 | Batch 26200/48196 ( 54.4%) | loss 1.0292 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 4/6 | Batch 26400/48196 ( 54.8%) | loss 1.0292 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 4/6 | Batch 26600/48196 ( 55.2%) | loss 1.0292 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 4/6 | Batch 26800/48196 ( 55.6%) | loss 1.0292 | elapsed 5.0m | ETA 4.0m\n",
      "Epoch 4/6 | Batch 27000/48196 ( 56.0%) | loss 1.0292 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 4/6 | Batch 27200/48196 ( 56.4%) | loss 1.0292 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 4/6 | Batch 27400/48196 ( 56.9%) | loss 1.0292 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 4/6 | Batch 27600/48196 ( 57.3%) | loss 1.0292 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 4/6 | Batch 27800/48196 ( 57.7%) | loss 1.0292 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 4/6 | Batch 28000/48196 ( 58.1%) | loss 1.0292 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 4/6 | Batch 28200/48196 ( 58.5%) | loss 1.0291 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 4/6 | Batch 28400/48196 ( 58.9%) | loss 1.0292 | elapsed 5.3m | ETA 3.7m\n",
      "Epoch 4/6 | Batch 28600/48196 ( 59.3%) | loss 1.0292 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 4/6 | Batch 28800/48196 ( 59.8%) | loss 1.0292 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 4/6 | Batch 29000/48196 ( 60.2%) | loss 1.0291 | elapsed 5.4m | ETA 3.6m\n",
      "Epoch 4/6 | Batch 29200/48196 ( 60.6%) | loss 1.0291 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 4/6 | Batch 29400/48196 ( 61.0%) | loss 1.0291 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 4/6 | Batch 29600/48196 ( 61.4%) | loss 1.0291 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 4/6 | Batch 29800/48196 ( 61.8%) | loss 1.0291 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 4/6 | Batch 30000/48196 ( 62.2%) | loss 1.0291 | elapsed 5.6m | ETA 3.4m\n",
      "Epoch 4/6 | Batch 30200/48196 ( 62.7%) | loss 1.0291 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 4/6 | Batch 30400/48196 ( 63.1%) | loss 1.0291 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 4/6 | Batch 30600/48196 ( 63.5%) | loss 1.0291 | elapsed 5.7m | ETA 3.3m\n",
      "Epoch 4/6 | Batch 30800/48196 ( 63.9%) | loss 1.0291 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 4/6 | Batch 31000/48196 ( 64.3%) | loss 1.0291 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 4/6 | Batch 31200/48196 ( 64.7%) | loss 1.0291 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 4/6 | Batch 31400/48196 ( 65.2%) | loss 1.0291 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 4/6 | Batch 31600/48196 ( 65.6%) | loss 1.0291 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 4/6 | Batch 31800/48196 ( 66.0%) | loss 1.0291 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 4/6 | Batch 32000/48196 ( 66.4%) | loss 1.0291 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 4/6 | Batch 32200/48196 ( 66.8%) | loss 1.0291 | elapsed 6.0m | ETA 3.0m\n",
      "Epoch 4/6 | Batch 32400/48196 ( 67.2%) | loss 1.0290 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 4/6 | Batch 32600/48196 ( 67.6%) | loss 1.0290 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 4/6 | Batch 32800/48196 ( 68.1%) | loss 1.0290 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 4/6 | Batch 33000/48196 ( 68.5%) | loss 1.0290 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 4/6 | Batch 33200/48196 ( 68.9%) | loss 1.0290 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 4/6 | Batch 33400/48196 ( 69.3%) | loss 1.0290 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 4/6 | Batch 33600/48196 ( 69.7%) | loss 1.0290 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 4/6 | Batch 33800/48196 ( 70.1%) | loss 1.0290 | elapsed 6.3m | ETA 2.7m\n",
      "Epoch 4/6 | Batch 34000/48196 ( 70.5%) | loss 1.0290 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 4/6 | Batch 34200/48196 ( 71.0%) | loss 1.0290 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 4/6 | Batch 34400/48196 ( 71.4%) | loss 1.0290 | elapsed 6.4m | ETA 2.6m\n",
      "Epoch 4/6 | Batch 34600/48196 ( 71.8%) | loss 1.0290 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 4/6 | Batch 34800/48196 ( 72.2%) | loss 1.0290 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 4/6 | Batch 35000/48196 ( 72.6%) | loss 1.0290 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 4/6 | Batch 35200/48196 ( 73.0%) | loss 1.0290 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 4/6 | Batch 35400/48196 ( 73.5%) | loss 1.0290 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 4/6 | Batch 35600/48196 ( 73.9%) | loss 1.0290 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 4/6 | Batch 35800/48196 ( 74.3%) | loss 1.0290 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 4/6 | Batch 36000/48196 ( 74.7%) | loss 1.0289 | elapsed 6.7m | ETA 2.3m\n",
      "Epoch 4/6 | Batch 36200/48196 ( 75.1%) | loss 1.0289 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 4/6 | Batch 36400/48196 ( 75.5%) | loss 1.0289 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 4/6 | Batch 36600/48196 ( 75.9%) | loss 1.0289 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 4/6 | Batch 36800/48196 ( 76.4%) | loss 1.0289 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 4/6 | Batch 37000/48196 ( 76.8%) | loss 1.0289 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 4/6 | Batch 37200/48196 ( 77.2%) | loss 1.0289 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 4/6 | Batch 37400/48196 ( 77.6%) | loss 1.0289 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 4/6 | Batch 37600/48196 ( 78.0%) | loss 1.0289 | elapsed 7.0m | ETA 2.0m\n",
      "Epoch 4/6 | Batch 37800/48196 ( 78.4%) | loss 1.0288 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 4/6 | Batch 38000/48196 ( 78.8%) | loss 1.0288 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 4/6 | Batch 38200/48196 ( 79.3%) | loss 1.0288 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 4/6 | Batch 38400/48196 ( 79.7%) | loss 1.0288 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 4/6 | Batch 38600/48196 ( 80.1%) | loss 1.0288 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 4/6 | Batch 38800/48196 ( 80.5%) | loss 1.0288 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 4/6 | Batch 39000/48196 ( 80.9%) | loss 1.0288 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 4/6 | Batch 39200/48196 ( 81.3%) | loss 1.0288 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 4/6 | Batch 39400/48196 ( 81.7%) | loss 1.0288 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 4/6 | Batch 39600/48196 ( 82.2%) | loss 1.0288 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 4/6 | Batch 39800/48196 ( 82.6%) | loss 1.0288 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 4/6 | Batch 40000/48196 ( 83.0%) | loss 1.0288 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 4/6 | Batch 40200/48196 ( 83.4%) | loss 1.0288 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 4/6 | Batch 40400/48196 ( 83.8%) | loss 1.0288 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 4/6 | Batch 40600/48196 ( 84.2%) | loss 1.0288 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 4/6 | Batch 40800/48196 ( 84.7%) | loss 1.0288 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 4/6 | Batch 41000/48196 ( 85.1%) | loss 1.0288 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 4/6 | Batch 41200/48196 ( 85.5%) | loss 1.0288 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 4/6 | Batch 41400/48196 ( 85.9%) | loss 1.0288 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 4/6 | Batch 41600/48196 ( 86.3%) | loss 1.0288 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 4/6 | Batch 41800/48196 ( 86.7%) | loss 1.0287 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 4/6 | Batch 42000/48196 ( 87.1%) | loss 1.0287 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 4/6 | Batch 42200/48196 ( 87.6%) | loss 1.0287 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 4/6 | Batch 42400/48196 ( 88.0%) | loss 1.0287 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 4/6 | Batch 42600/48196 ( 88.4%) | loss 1.0287 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 4/6 | Batch 42800/48196 ( 88.8%) | loss 1.0287 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 4/6 | Batch 43000/48196 ( 89.2%) | loss 1.0287 | elapsed 8.0m | ETA 1.0m\n",
      "Epoch 4/6 | Batch 43200/48196 ( 89.6%) | loss 1.0287 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 4/6 | Batch 43400/48196 ( 90.0%) | loss 1.0287 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 4/6 | Batch 43600/48196 ( 90.5%) | loss 1.0287 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 4/6 | Batch 43800/48196 ( 90.9%) | loss 1.0287 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 4/6 | Batch 44000/48196 ( 91.3%) | loss 1.0287 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 4/6 | Batch 44200/48196 ( 91.7%) | loss 1.0287 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 4/6 | Batch 44400/48196 ( 92.1%) | loss 1.0287 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 4/6 | Batch 44600/48196 ( 92.5%) | loss 1.0287 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 4/6 | Batch 44800/48196 ( 93.0%) | loss 1.0286 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 4/6 | Batch 45000/48196 ( 93.4%) | loss 1.0286 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 4/6 | Batch 45200/48196 ( 93.8%) | loss 1.0287 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 4/6 | Batch 45400/48196 ( 94.2%) | loss 1.0286 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 4/6 | Batch 45600/48196 ( 94.6%) | loss 1.0286 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 4/6 | Batch 45800/48196 ( 95.0%) | loss 1.0286 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 4/6 | Batch 46000/48196 ( 95.4%) | loss 1.0286 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 4/6 | Batch 46200/48196 ( 95.9%) | loss 1.0286 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 4/6 | Batch 46400/48196 ( 96.3%) | loss 1.0286 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 4/6 | Batch 46600/48196 ( 96.7%) | loss 1.0286 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 4/6 | Batch 46800/48196 ( 97.1%) | loss 1.0286 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 4/6 | Batch 47000/48196 ( 97.5%) | loss 1.0286 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 4/6 | Batch 47200/48196 ( 97.9%) | loss 1.0286 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 4/6 | Batch 47400/48196 ( 98.3%) | loss 1.0286 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 4/6 | Batch 47600/48196 ( 98.8%) | loss 1.0286 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 4/6 | Batch 47800/48196 ( 99.2%) | loss 1.0286 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 4/6 | Batch 48000/48196 ( 99.6%) | loss 1.0286 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 4/6 | Batch 48196/48196 (100.0%) | loss 1.0286 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 4 DONE | train_loss 1.0265 ppl 2.791 | val_loss 1.3382 ppl 3.812\n",
      "Epoch 5/6 | Batch 200/48196 (  0.4%) | loss 1.0256 | elapsed 0.0m | ETA 10.1m\n",
      "Epoch 5/6 | Batch 400/48196 (  0.8%) | loss 1.0261 | elapsed 0.1m | ETA 9.5m\n",
      "Epoch 5/6 | Batch 600/48196 (  1.2%) | loss 1.0254 | elapsed 0.1m | ETA 9.2m\n",
      "Epoch 5/6 | Batch 800/48196 (  1.7%) | loss 1.0254 | elapsed 0.2m | ETA 9.1m\n",
      "Epoch 5/6 | Batch 1000/48196 (  2.1%) | loss 1.0257 | elapsed 0.2m | ETA 9.0m\n",
      "Epoch 5/6 | Batch 1200/48196 (  2.5%) | loss 1.0261 | elapsed 0.2m | ETA 8.9m\n",
      "Epoch 5/6 | Batch 1400/48196 (  2.9%) | loss 1.0260 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 5/6 | Batch 1600/48196 (  3.3%) | loss 1.0262 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 5/6 | Batch 1800/48196 (  3.7%) | loss 1.0261 | elapsed 0.3m | ETA 8.7m\n",
      "Epoch 5/6 | Batch 2000/48196 (  4.1%) | loss 1.0261 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 5/6 | Batch 2200/48196 (  4.6%) | loss 1.0264 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 5/6 | Batch 2400/48196 (  5.0%) | loss 1.0265 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 5/6 | Batch 2600/48196 (  5.4%) | loss 1.0264 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 5/6 | Batch 2800/48196 (  5.8%) | loss 1.0265 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 5/6 | Batch 3000/48196 (  6.2%) | loss 1.0265 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 5/6 | Batch 3200/48196 (  6.6%) | loss 1.0264 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 5/6 | Batch 3400/48196 (  7.1%) | loss 1.0264 | elapsed 0.6m | ETA 8.3m\n",
      "Epoch 5/6 | Batch 3600/48196 (  7.5%) | loss 1.0263 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 5/6 | Batch 3800/48196 (  7.9%) | loss 1.0263 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 5/6 | Batch 4000/48196 (  8.3%) | loss 1.0263 | elapsed 0.7m | ETA 8.2m\n",
      "Epoch 5/6 | Batch 4200/48196 (  8.7%) | loss 1.0262 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 5/6 | Batch 4400/48196 (  9.1%) | loss 1.0263 | elapsed 0.8m | ETA 8.1m\n",
      "Epoch 5/6 | Batch 4600/48196 (  9.5%) | loss 1.0263 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 5/6 | Batch 4800/48196 ( 10.0%) | loss 1.0263 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 5/6 | Batch 5000/48196 ( 10.4%) | loss 1.0263 | elapsed 0.9m | ETA 8.0m\n",
      "Epoch 5/6 | Batch 5200/48196 ( 10.8%) | loss 1.0265 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 5/6 | Batch 5400/48196 ( 11.2%) | loss 1.0266 | elapsed 1.0m | ETA 7.9m\n",
      "Epoch 5/6 | Batch 5600/48196 ( 11.6%) | loss 1.0265 | elapsed 1.0m | ETA 7.9m\n",
      "Epoch 5/6 | Batch 5800/48196 ( 12.0%) | loss 1.0265 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 5/6 | Batch 6000/48196 ( 12.4%) | loss 1.0264 | elapsed 1.1m | ETA 7.8m\n",
      "Epoch 5/6 | Batch 6200/48196 ( 12.9%) | loss 1.0264 | elapsed 1.1m | ETA 7.8m\n",
      "Epoch 5/6 | Batch 6400/48196 ( 13.3%) | loss 1.0264 | elapsed 1.2m | ETA 7.7m\n",
      "Epoch 5/6 | Batch 6600/48196 ( 13.7%) | loss 1.0264 | elapsed 1.2m | ETA 7.7m\n",
      "Epoch 5/6 | Batch 6800/48196 ( 14.1%) | loss 1.0264 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 5/6 | Batch 7000/48196 ( 14.5%) | loss 1.0264 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 5/6 | Batch 7200/48196 ( 14.9%) | loss 1.0263 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 5/6 | Batch 7400/48196 ( 15.4%) | loss 1.0264 | elapsed 1.4m | ETA 7.6m\n",
      "Epoch 5/6 | Batch 7600/48196 ( 15.8%) | loss 1.0264 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 5/6 | Batch 7800/48196 ( 16.2%) | loss 1.0265 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 5/6 | Batch 8000/48196 ( 16.6%) | loss 1.0264 | elapsed 1.5m | ETA 7.4m\n",
      "Epoch 5/6 | Batch 8200/48196 ( 17.0%) | loss 1.0265 | elapsed 1.5m | ETA 7.4m\n",
      "Epoch 5/6 | Batch 8400/48196 ( 17.4%) | loss 1.0265 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 5/6 | Batch 8600/48196 ( 17.8%) | loss 1.0265 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 5/6 | Batch 8800/48196 ( 18.3%) | loss 1.0265 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 5/6 | Batch 9000/48196 ( 18.7%) | loss 1.0265 | elapsed 1.7m | ETA 7.3m\n",
      "Epoch 5/6 | Batch 9200/48196 ( 19.1%) | loss 1.0265 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 5/6 | Batch 9400/48196 ( 19.5%) | loss 1.0265 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 5/6 | Batch 9600/48196 ( 19.9%) | loss 1.0266 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 5/6 | Batch 9800/48196 ( 20.3%) | loss 1.0266 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 5/6 | Batch 10000/48196 ( 20.7%) | loss 1.0266 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 5/6 | Batch 10200/48196 ( 21.2%) | loss 1.0266 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 5/6 | Batch 10400/48196 ( 21.6%) | loss 1.0266 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 5/6 | Batch 10600/48196 ( 22.0%) | loss 1.0266 | elapsed 2.0m | ETA 7.0m\n",
      "Epoch 5/6 | Batch 10800/48196 ( 22.4%) | loss 1.0266 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 5/6 | Batch 11000/48196 ( 22.8%) | loss 1.0266 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 5/6 | Batch 11200/48196 ( 23.2%) | loss 1.0266 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 5/6 | Batch 11400/48196 ( 23.7%) | loss 1.0266 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 5/6 | Batch 11600/48196 ( 24.1%) | loss 1.0266 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 5/6 | Batch 11800/48196 ( 24.5%) | loss 1.0266 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 5/6 | Batch 12000/48196 ( 24.9%) | loss 1.0266 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 5/6 | Batch 12200/48196 ( 25.3%) | loss 1.0266 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 5/6 | Batch 12400/48196 ( 25.7%) | loss 1.0265 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 5/6 | Batch 12600/48196 ( 26.1%) | loss 1.0265 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 5/6 | Batch 12800/48196 ( 26.6%) | loss 1.0265 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 5/6 | Batch 13000/48196 ( 27.0%) | loss 1.0265 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 5/6 | Batch 13200/48196 ( 27.4%) | loss 1.0265 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 5/6 | Batch 13400/48196 ( 27.8%) | loss 1.0265 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 5/6 | Batch 13600/48196 ( 28.2%) | loss 1.0265 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 5/6 | Batch 13800/48196 ( 28.6%) | loss 1.0265 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 5/6 | Batch 14000/48196 ( 29.0%) | loss 1.0265 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 5/6 | Batch 14200/48196 ( 29.5%) | loss 1.0265 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 5/6 | Batch 14400/48196 ( 29.9%) | loss 1.0265 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 5/6 | Batch 14600/48196 ( 30.3%) | loss 1.0264 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 5/6 | Batch 14800/48196 ( 30.7%) | loss 1.0264 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 5/6 | Batch 15000/48196 ( 31.1%) | loss 1.0264 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 5/6 | Batch 15200/48196 ( 31.5%) | loss 1.0264 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 5/6 | Batch 15400/48196 ( 32.0%) | loss 1.0263 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 5/6 | Batch 15600/48196 ( 32.4%) | loss 1.0263 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 5/6 | Batch 15800/48196 ( 32.8%) | loss 1.0263 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 5/6 | Batch 16000/48196 ( 33.2%) | loss 1.0264 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 5/6 | Batch 16200/48196 ( 33.6%) | loss 1.0263 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 5/6 | Batch 16400/48196 ( 34.0%) | loss 1.0263 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 5/6 | Batch 16600/48196 ( 34.4%) | loss 1.0263 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 5/6 | Batch 16800/48196 ( 34.9%) | loss 1.0263 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 5/6 | Batch 17000/48196 ( 35.3%) | loss 1.0263 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 5/6 | Batch 17200/48196 ( 35.7%) | loss 1.0264 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 5/6 | Batch 17400/48196 ( 36.1%) | loss 1.0263 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 5/6 | Batch 17600/48196 ( 36.5%) | loss 1.0263 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 5/6 | Batch 17800/48196 ( 36.9%) | loss 1.0264 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 5/6 | Batch 18000/48196 ( 37.3%) | loss 1.0264 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 5/6 | Batch 18200/48196 ( 37.8%) | loss 1.0263 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 5/6 | Batch 18400/48196 ( 38.2%) | loss 1.0264 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 5/6 | Batch 18600/48196 ( 38.6%) | loss 1.0264 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 5/6 | Batch 18800/48196 ( 39.0%) | loss 1.0264 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 5/6 | Batch 19000/48196 ( 39.4%) | loss 1.0264 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 5/6 | Batch 19200/48196 ( 39.8%) | loss 1.0264 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 5/6 | Batch 19400/48196 ( 40.3%) | loss 1.0264 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 5/6 | Batch 19600/48196 ( 40.7%) | loss 1.0264 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 5/6 | Batch 19800/48196 ( 41.1%) | loss 1.0264 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 5/6 | Batch 20000/48196 ( 41.5%) | loss 1.0264 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 5/6 | Batch 20200/48196 ( 41.9%) | loss 1.0264 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 5/6 | Batch 20400/48196 ( 42.3%) | loss 1.0264 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 5/6 | Batch 20600/48196 ( 42.7%) | loss 1.0263 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 5/6 | Batch 20800/48196 ( 43.2%) | loss 1.0263 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 5/6 | Batch 21000/48196 ( 43.6%) | loss 1.0263 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 5/6 | Batch 21200/48196 ( 44.0%) | loss 1.0263 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 5/6 | Batch 21400/48196 ( 44.4%) | loss 1.0263 | elapsed 4.0m | ETA 5.0m\n",
      "Epoch 5/6 | Batch 21600/48196 ( 44.8%) | loss 1.0263 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 5/6 | Batch 21800/48196 ( 45.2%) | loss 1.0263 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 5/6 | Batch 22000/48196 ( 45.6%) | loss 1.0263 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 5/6 | Batch 22200/48196 ( 46.1%) | loss 1.0263 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 5/6 | Batch 22400/48196 ( 46.5%) | loss 1.0263 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 5/6 | Batch 22600/48196 ( 46.9%) | loss 1.0263 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 5/6 | Batch 22800/48196 ( 47.3%) | loss 1.0263 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 5/6 | Batch 23000/48196 ( 47.7%) | loss 1.0263 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 5/6 | Batch 23200/48196 ( 48.1%) | loss 1.0263 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 5/6 | Batch 23400/48196 ( 48.6%) | loss 1.0263 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 5/6 | Batch 23600/48196 ( 49.0%) | loss 1.0263 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 5/6 | Batch 23800/48196 ( 49.4%) | loss 1.0263 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 5/6 | Batch 24000/48196 ( 49.8%) | loss 1.0263 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 5/6 | Batch 24200/48196 ( 50.2%) | loss 1.0263 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 5/6 | Batch 24400/48196 ( 50.6%) | loss 1.0263 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 5/6 | Batch 24600/48196 ( 51.0%) | loss 1.0263 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 5/6 | Batch 24800/48196 ( 51.5%) | loss 1.0263 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 5/6 | Batch 25000/48196 ( 51.9%) | loss 1.0262 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 5/6 | Batch 25200/48196 ( 52.3%) | loss 1.0263 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 5/6 | Batch 25400/48196 ( 52.7%) | loss 1.0263 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 5/6 | Batch 25600/48196 ( 53.1%) | loss 1.0263 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 5/6 | Batch 25800/48196 ( 53.5%) | loss 1.0263 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 5/6 | Batch 26000/48196 ( 53.9%) | loss 1.0262 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 5/6 | Batch 26200/48196 ( 54.4%) | loss 1.0262 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 5/6 | Batch 26400/48196 ( 54.8%) | loss 1.0262 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 5/6 | Batch 26600/48196 ( 55.2%) | loss 1.0262 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 5/6 | Batch 26800/48196 ( 55.6%) | loss 1.0262 | elapsed 5.0m | ETA 4.0m\n",
      "Epoch 5/6 | Batch 27000/48196 ( 56.0%) | loss 1.0262 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 5/6 | Batch 27200/48196 ( 56.4%) | loss 1.0262 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 5/6 | Batch 27400/48196 ( 56.9%) | loss 1.0262 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 5/6 | Batch 27600/48196 ( 57.3%) | loss 1.0262 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 5/6 | Batch 27800/48196 ( 57.7%) | loss 1.0262 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 5/6 | Batch 28000/48196 ( 58.1%) | loss 1.0262 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 5/6 | Batch 28200/48196 ( 58.5%) | loss 1.0262 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 5/6 | Batch 28400/48196 ( 58.9%) | loss 1.0262 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 5/6 | Batch 28600/48196 ( 59.3%) | loss 1.0262 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 5/6 | Batch 28800/48196 ( 59.8%) | loss 1.0263 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 5/6 | Batch 29000/48196 ( 60.2%) | loss 1.0263 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 5/6 | Batch 29200/48196 ( 60.6%) | loss 1.0263 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 5/6 | Batch 29400/48196 ( 61.0%) | loss 1.0263 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 5/6 | Batch 29600/48196 ( 61.4%) | loss 1.0263 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 5/6 | Batch 29800/48196 ( 61.8%) | loss 1.0263 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 5/6 | Batch 30000/48196 ( 62.2%) | loss 1.0263 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 5/6 | Batch 30200/48196 ( 62.7%) | loss 1.0262 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 5/6 | Batch 30400/48196 ( 63.1%) | loss 1.0262 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 5/6 | Batch 30600/48196 ( 63.5%) | loss 1.0262 | elapsed 5.7m | ETA 3.3m\n",
      "Epoch 5/6 | Batch 30800/48196 ( 63.9%) | loss 1.0262 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 5/6 | Batch 31000/48196 ( 64.3%) | loss 1.0262 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 5/6 | Batch 31200/48196 ( 64.7%) | loss 1.0262 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 5/6 | Batch 31400/48196 ( 65.2%) | loss 1.0262 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 5/6 | Batch 31600/48196 ( 65.6%) | loss 1.0262 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 5/6 | Batch 31800/48196 ( 66.0%) | loss 1.0262 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 5/6 | Batch 32000/48196 ( 66.4%) | loss 1.0262 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 5/6 | Batch 32200/48196 ( 66.8%) | loss 1.0262 | elapsed 6.0m | ETA 3.0m\n",
      "Epoch 5/6 | Batch 32400/48196 ( 67.2%) | loss 1.0262 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 5/6 | Batch 32600/48196 ( 67.6%) | loss 1.0262 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 5/6 | Batch 32800/48196 ( 68.1%) | loss 1.0262 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 5/6 | Batch 33000/48196 ( 68.5%) | loss 1.0262 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 5/6 | Batch 33200/48196 ( 68.9%) | loss 1.0262 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 5/6 | Batch 33400/48196 ( 69.3%) | loss 1.0262 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 5/6 | Batch 33600/48196 ( 69.7%) | loss 1.0262 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 5/6 | Batch 33800/48196 ( 70.1%) | loss 1.0262 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 5/6 | Batch 34000/48196 ( 70.5%) | loss 1.0261 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 5/6 | Batch 34200/48196 ( 71.0%) | loss 1.0261 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 5/6 | Batch 34400/48196 ( 71.4%) | loss 1.0261 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 5/6 | Batch 34600/48196 ( 71.8%) | loss 1.0261 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 5/6 | Batch 34800/48196 ( 72.2%) | loss 1.0261 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 5/6 | Batch 35000/48196 ( 72.6%) | loss 1.0261 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 5/6 | Batch 35200/48196 ( 73.0%) | loss 1.0261 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 5/6 | Batch 35400/48196 ( 73.5%) | loss 1.0261 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 5/6 | Batch 35600/48196 ( 73.9%) | loss 1.0261 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 5/6 | Batch 35800/48196 ( 74.3%) | loss 1.0261 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 5/6 | Batch 36000/48196 ( 74.7%) | loss 1.0261 | elapsed 6.7m | ETA 2.3m\n",
      "Epoch 5/6 | Batch 36200/48196 ( 75.1%) | loss 1.0261 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 5/6 | Batch 36400/48196 ( 75.5%) | loss 1.0261 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 5/6 | Batch 36600/48196 ( 75.9%) | loss 1.0261 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 5/6 | Batch 36800/48196 ( 76.4%) | loss 1.0261 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 5/6 | Batch 37000/48196 ( 76.8%) | loss 1.0261 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 5/6 | Batch 37200/48196 ( 77.2%) | loss 1.0261 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 5/6 | Batch 37400/48196 ( 77.6%) | loss 1.0261 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 5/6 | Batch 37600/48196 ( 78.0%) | loss 1.0261 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 5/6 | Batch 37800/48196 ( 78.4%) | loss 1.0261 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 5/6 | Batch 38000/48196 ( 78.8%) | loss 1.0260 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 5/6 | Batch 38200/48196 ( 79.3%) | loss 1.0260 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 5/6 | Batch 38400/48196 ( 79.7%) | loss 1.0260 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 5/6 | Batch 38600/48196 ( 80.1%) | loss 1.0260 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 5/6 | Batch 38800/48196 ( 80.5%) | loss 1.0260 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 5/6 | Batch 39000/48196 ( 80.9%) | loss 1.0260 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 5/6 | Batch 39200/48196 ( 81.3%) | loss 1.0260 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 5/6 | Batch 39400/48196 ( 81.7%) | loss 1.0260 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 5/6 | Batch 39600/48196 ( 82.2%) | loss 1.0260 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 5/6 | Batch 39800/48196 ( 82.6%) | loss 1.0260 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 5/6 | Batch 40000/48196 ( 83.0%) | loss 1.0260 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 5/6 | Batch 40200/48196 ( 83.4%) | loss 1.0260 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 5/6 | Batch 40400/48196 ( 83.8%) | loss 1.0260 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 5/6 | Batch 40600/48196 ( 84.2%) | loss 1.0260 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 5/6 | Batch 40800/48196 ( 84.7%) | loss 1.0260 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 5/6 | Batch 41000/48196 ( 85.1%) | loss 1.0260 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 5/6 | Batch 41200/48196 ( 85.5%) | loss 1.0260 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 5/6 | Batch 41400/48196 ( 85.9%) | loss 1.0260 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 5/6 | Batch 41600/48196 ( 86.3%) | loss 1.0260 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 5/6 | Batch 41800/48196 ( 86.7%) | loss 1.0260 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 5/6 | Batch 42000/48196 ( 87.1%) | loss 1.0260 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 5/6 | Batch 42200/48196 ( 87.6%) | loss 1.0260 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 5/6 | Batch 42400/48196 ( 88.0%) | loss 1.0260 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 5/6 | Batch 42600/48196 ( 88.4%) | loss 1.0259 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 5/6 | Batch 42800/48196 ( 88.8%) | loss 1.0259 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 5/6 | Batch 43000/48196 ( 89.2%) | loss 1.0259 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 5/6 | Batch 43200/48196 ( 89.6%) | loss 1.0259 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 5/6 | Batch 43400/48196 ( 90.0%) | loss 1.0259 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 5/6 | Batch 43600/48196 ( 90.5%) | loss 1.0259 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 5/6 | Batch 43800/48196 ( 90.9%) | loss 1.0259 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 5/6 | Batch 44000/48196 ( 91.3%) | loss 1.0259 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 5/6 | Batch 44200/48196 ( 91.7%) | loss 1.0259 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 5/6 | Batch 44400/48196 ( 92.1%) | loss 1.0259 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 5/6 | Batch 44600/48196 ( 92.5%) | loss 1.0259 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 5/6 | Batch 44800/48196 ( 93.0%) | loss 1.0259 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 5/6 | Batch 45000/48196 ( 93.4%) | loss 1.0259 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 5/6 | Batch 45200/48196 ( 93.8%) | loss 1.0259 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 5/6 | Batch 45400/48196 ( 94.2%) | loss 1.0259 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 5/6 | Batch 45600/48196 ( 94.6%) | loss 1.0259 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 5/6 | Batch 45800/48196 ( 95.0%) | loss 1.0259 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 5/6 | Batch 46000/48196 ( 95.4%) | loss 1.0259 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 5/6 | Batch 46200/48196 ( 95.9%) | loss 1.0259 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 5/6 | Batch 46400/48196 ( 96.3%) | loss 1.0259 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 5/6 | Batch 46600/48196 ( 96.7%) | loss 1.0259 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 5/6 | Batch 46800/48196 ( 97.1%) | loss 1.0259 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 5/6 | Batch 47000/48196 ( 97.5%) | loss 1.0259 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 5/6 | Batch 47200/48196 ( 97.9%) | loss 1.0259 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 5/6 | Batch 47400/48196 ( 98.3%) | loss 1.0258 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 5/6 | Batch 47600/48196 ( 98.8%) | loss 1.0258 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 5/6 | Batch 47800/48196 ( 99.2%) | loss 1.0258 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 5/6 | Batch 48000/48196 ( 99.6%) | loss 1.0258 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 5/6 | Batch 48196/48196 (100.0%) | loss 1.0258 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 5 DONE | train_loss 1.0242 ppl 2.785 | val_loss 1.3395 ppl 3.817\n",
      "Epoch 6/6 | Batch 200/48196 (  0.4%) | loss 1.0236 | elapsed 0.0m | ETA 10.1m\n",
      "Epoch 6/6 | Batch 400/48196 (  0.8%) | loss 1.0246 | elapsed 0.1m | ETA 9.4m\n",
      "Epoch 6/6 | Batch 600/48196 (  1.2%) | loss 1.0248 | elapsed 0.1m | ETA 9.2m\n",
      "Epoch 6/6 | Batch 800/48196 (  1.7%) | loss 1.0254 | elapsed 0.2m | ETA 9.0m\n",
      "Epoch 6/6 | Batch 1000/48196 (  2.1%) | loss 1.0255 | elapsed 0.2m | ETA 8.9m\n",
      "Epoch 6/6 | Batch 1200/48196 (  2.5%) | loss 1.0255 | elapsed 0.2m | ETA 8.9m\n",
      "Epoch 6/6 | Batch 1400/48196 (  2.9%) | loss 1.0255 | elapsed 0.3m | ETA 8.8m\n",
      "Epoch 6/6 | Batch 1600/48196 (  3.3%) | loss 1.0255 | elapsed 0.3m | ETA 8.7m\n",
      "Epoch 6/6 | Batch 1800/48196 (  3.7%) | loss 1.0254 | elapsed 0.3m | ETA 8.7m\n",
      "Epoch 6/6 | Batch 2000/48196 (  4.1%) | loss 1.0252 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 6/6 | Batch 2200/48196 (  4.6%) | loss 1.0251 | elapsed 0.4m | ETA 8.6m\n",
      "Epoch 6/6 | Batch 2400/48196 (  5.0%) | loss 1.0249 | elapsed 0.4m | ETA 8.5m\n",
      "Epoch 6/6 | Batch 2600/48196 (  5.4%) | loss 1.0248 | elapsed 0.5m | ETA 8.5m\n",
      "Epoch 6/6 | Batch 2800/48196 (  5.8%) | loss 1.0246 | elapsed 0.5m | ETA 8.4m\n",
      "Epoch 6/6 | Batch 3000/48196 (  6.2%) | loss 1.0246 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 6/6 | Batch 3200/48196 (  6.6%) | loss 1.0247 | elapsed 0.6m | ETA 8.4m\n",
      "Epoch 6/6 | Batch 3400/48196 (  7.1%) | loss 1.0247 | elapsed 0.6m | ETA 8.3m\n",
      "Epoch 6/6 | Batch 3600/48196 (  7.5%) | loss 1.0247 | elapsed 0.7m | ETA 8.3m\n",
      "Epoch 6/6 | Batch 3800/48196 (  7.9%) | loss 1.0247 | elapsed 0.7m | ETA 8.2m\n",
      "Epoch 6/6 | Batch 4000/48196 (  8.3%) | loss 1.0248 | elapsed 0.7m | ETA 8.2m\n",
      "Epoch 6/6 | Batch 4200/48196 (  8.7%) | loss 1.0248 | elapsed 0.8m | ETA 8.2m\n",
      "Epoch 6/6 | Batch 4400/48196 (  9.1%) | loss 1.0247 | elapsed 0.8m | ETA 8.1m\n",
      "Epoch 6/6 | Batch 4600/48196 (  9.5%) | loss 1.0247 | elapsed 0.9m | ETA 8.1m\n",
      "Epoch 6/6 | Batch 4800/48196 ( 10.0%) | loss 1.0246 | elapsed 0.9m | ETA 8.0m\n",
      "Epoch 6/6 | Batch 5000/48196 ( 10.4%) | loss 1.0246 | elapsed 0.9m | ETA 8.0m\n",
      "Epoch 6/6 | Batch 5200/48196 ( 10.8%) | loss 1.0246 | elapsed 1.0m | ETA 8.0m\n",
      "Epoch 6/6 | Batch 5400/48196 ( 11.2%) | loss 1.0247 | elapsed 1.0m | ETA 7.9m\n",
      "Epoch 6/6 | Batch 5600/48196 ( 11.6%) | loss 1.0246 | elapsed 1.0m | ETA 7.9m\n",
      "Epoch 6/6 | Batch 5800/48196 ( 12.0%) | loss 1.0245 | elapsed 1.1m | ETA 7.9m\n",
      "Epoch 6/6 | Batch 6000/48196 ( 12.4%) | loss 1.0244 | elapsed 1.1m | ETA 7.8m\n",
      "Epoch 6/6 | Batch 6200/48196 ( 12.9%) | loss 1.0245 | elapsed 1.1m | ETA 7.8m\n",
      "Epoch 6/6 | Batch 6400/48196 ( 13.3%) | loss 1.0245 | elapsed 1.2m | ETA 7.7m\n",
      "Epoch 6/6 | Batch 6600/48196 ( 13.7%) | loss 1.0246 | elapsed 1.2m | ETA 7.7m\n",
      "Epoch 6/6 | Batch 6800/48196 ( 14.1%) | loss 1.0246 | elapsed 1.3m | ETA 7.7m\n",
      "Epoch 6/6 | Batch 7000/48196 ( 14.5%) | loss 1.0245 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 6/6 | Batch 7200/48196 ( 14.9%) | loss 1.0244 | elapsed 1.3m | ETA 7.6m\n",
      "Epoch 6/6 | Batch 7400/48196 ( 15.4%) | loss 1.0244 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 6/6 | Batch 7600/48196 ( 15.8%) | loss 1.0244 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 6/6 | Batch 7800/48196 ( 16.2%) | loss 1.0244 | elapsed 1.4m | ETA 7.5m\n",
      "Epoch 6/6 | Batch 8000/48196 ( 16.6%) | loss 1.0243 | elapsed 1.5m | ETA 7.4m\n",
      "Epoch 6/6 | Batch 8200/48196 ( 17.0%) | loss 1.0243 | elapsed 1.5m | ETA 7.4m\n",
      "Epoch 6/6 | Batch 8400/48196 ( 17.4%) | loss 1.0243 | elapsed 1.6m | ETA 7.4m\n",
      "Epoch 6/6 | Batch 8600/48196 ( 17.8%) | loss 1.0242 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 6/6 | Batch 8800/48196 ( 18.3%) | loss 1.0242 | elapsed 1.6m | ETA 7.3m\n",
      "Epoch 6/6 | Batch 9000/48196 ( 18.7%) | loss 1.0242 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 6/6 | Batch 9200/48196 ( 19.1%) | loss 1.0242 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 6/6 | Batch 9400/48196 ( 19.5%) | loss 1.0242 | elapsed 1.7m | ETA 7.2m\n",
      "Epoch 6/6 | Batch 9600/48196 ( 19.9%) | loss 1.0242 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 6/6 | Batch 9800/48196 ( 20.3%) | loss 1.0242 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 6/6 | Batch 10000/48196 ( 20.7%) | loss 1.0242 | elapsed 1.8m | ETA 7.1m\n",
      "Epoch 6/6 | Batch 10200/48196 ( 21.2%) | loss 1.0242 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 6/6 | Batch 10400/48196 ( 21.6%) | loss 1.0241 | elapsed 1.9m | ETA 7.0m\n",
      "Epoch 6/6 | Batch 10600/48196 ( 22.0%) | loss 1.0242 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 6/6 | Batch 10800/48196 ( 22.4%) | loss 1.0242 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 6/6 | Batch 11000/48196 ( 22.8%) | loss 1.0242 | elapsed 2.0m | ETA 6.9m\n",
      "Epoch 6/6 | Batch 11200/48196 ( 23.2%) | loss 1.0242 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 6/6 | Batch 11400/48196 ( 23.7%) | loss 1.0243 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 6/6 | Batch 11600/48196 ( 24.1%) | loss 1.0243 | elapsed 2.1m | ETA 6.8m\n",
      "Epoch 6/6 | Batch 11800/48196 ( 24.5%) | loss 1.0243 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 6/6 | Batch 12000/48196 ( 24.9%) | loss 1.0243 | elapsed 2.2m | ETA 6.7m\n",
      "Epoch 6/6 | Batch 12200/48196 ( 25.3%) | loss 1.0243 | elapsed 2.3m | ETA 6.7m\n",
      "Epoch 6/6 | Batch 12400/48196 ( 25.7%) | loss 1.0243 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 6/6 | Batch 12600/48196 ( 26.1%) | loss 1.0243 | elapsed 2.3m | ETA 6.6m\n",
      "Epoch 6/6 | Batch 12800/48196 ( 26.6%) | loss 1.0242 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 6/6 | Batch 13000/48196 ( 27.0%) | loss 1.0242 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 6/6 | Batch 13200/48196 ( 27.4%) | loss 1.0243 | elapsed 2.4m | ETA 6.5m\n",
      "Epoch 6/6 | Batch 13400/48196 ( 27.8%) | loss 1.0243 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 6/6 | Batch 13600/48196 ( 28.2%) | loss 1.0243 | elapsed 2.5m | ETA 6.4m\n",
      "Epoch 6/6 | Batch 13800/48196 ( 28.6%) | loss 1.0242 | elapsed 2.6m | ETA 6.4m\n",
      "Epoch 6/6 | Batch 14000/48196 ( 29.0%) | loss 1.0243 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 6/6 | Batch 14200/48196 ( 29.5%) | loss 1.0242 | elapsed 2.6m | ETA 6.3m\n",
      "Epoch 6/6 | Batch 14400/48196 ( 29.9%) | loss 1.0242 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 6/6 | Batch 14600/48196 ( 30.3%) | loss 1.0242 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 6/6 | Batch 14800/48196 ( 30.7%) | loss 1.0242 | elapsed 2.7m | ETA 6.2m\n",
      "Epoch 6/6 | Batch 15000/48196 ( 31.1%) | loss 1.0242 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 6/6 | Batch 15200/48196 ( 31.5%) | loss 1.0242 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 6/6 | Batch 15400/48196 ( 32.0%) | loss 1.0242 | elapsed 2.8m | ETA 6.1m\n",
      "Epoch 6/6 | Batch 15600/48196 ( 32.4%) | loss 1.0242 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 6/6 | Batch 15800/48196 ( 32.8%) | loss 1.0241 | elapsed 2.9m | ETA 6.0m\n",
      "Epoch 6/6 | Batch 16000/48196 ( 33.2%) | loss 1.0241 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 6/6 | Batch 16200/48196 ( 33.6%) | loss 1.0241 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 6/6 | Batch 16400/48196 ( 34.0%) | loss 1.0241 | elapsed 3.0m | ETA 5.9m\n",
      "Epoch 6/6 | Batch 16600/48196 ( 34.4%) | loss 1.0241 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 6/6 | Batch 16800/48196 ( 34.9%) | loss 1.0241 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 6/6 | Batch 17000/48196 ( 35.3%) | loss 1.0242 | elapsed 3.1m | ETA 5.8m\n",
      "Epoch 6/6 | Batch 17200/48196 ( 35.7%) | loss 1.0242 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 6/6 | Batch 17400/48196 ( 36.1%) | loss 1.0242 | elapsed 3.2m | ETA 5.7m\n",
      "Epoch 6/6 | Batch 17600/48196 ( 36.5%) | loss 1.0242 | elapsed 3.3m | ETA 5.7m\n",
      "Epoch 6/6 | Batch 17800/48196 ( 36.9%) | loss 1.0242 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 6/6 | Batch 18000/48196 ( 37.3%) | loss 1.0242 | elapsed 3.3m | ETA 5.6m\n",
      "Epoch 6/6 | Batch 18200/48196 ( 37.8%) | loss 1.0242 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 6/6 | Batch 18400/48196 ( 38.2%) | loss 1.0242 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 6/6 | Batch 18600/48196 ( 38.6%) | loss 1.0242 | elapsed 3.4m | ETA 5.5m\n",
      "Epoch 6/6 | Batch 18800/48196 ( 39.0%) | loss 1.0242 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 6/6 | Batch 19000/48196 ( 39.4%) | loss 1.0241 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 6/6 | Batch 19200/48196 ( 39.8%) | loss 1.0241 | elapsed 3.5m | ETA 5.4m\n",
      "Epoch 6/6 | Batch 19400/48196 ( 40.3%) | loss 1.0241 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 6/6 | Batch 19600/48196 ( 40.7%) | loss 1.0241 | elapsed 3.6m | ETA 5.3m\n",
      "Epoch 6/6 | Batch 19800/48196 ( 41.1%) | loss 1.0241 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 6/6 | Batch 20000/48196 ( 41.5%) | loss 1.0241 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 6/6 | Batch 20200/48196 ( 41.9%) | loss 1.0241 | elapsed 3.7m | ETA 5.2m\n",
      "Epoch 6/6 | Batch 20400/48196 ( 42.3%) | loss 1.0241 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 6/6 | Batch 20600/48196 ( 42.7%) | loss 1.0241 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 6/6 | Batch 20800/48196 ( 43.2%) | loss 1.0241 | elapsed 3.8m | ETA 5.1m\n",
      "Epoch 6/6 | Batch 21000/48196 ( 43.6%) | loss 1.0241 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 6/6 | Batch 21200/48196 ( 44.0%) | loss 1.0241 | elapsed 3.9m | ETA 5.0m\n",
      "Epoch 6/6 | Batch 21400/48196 ( 44.4%) | loss 1.0242 | elapsed 4.0m | ETA 5.0m\n",
      "Epoch 6/6 | Batch 21600/48196 ( 44.8%) | loss 1.0241 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 6/6 | Batch 21800/48196 ( 45.2%) | loss 1.0241 | elapsed 4.0m | ETA 4.9m\n",
      "Epoch 6/6 | Batch 22000/48196 ( 45.6%) | loss 1.0241 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 6/6 | Batch 22200/48196 ( 46.1%) | loss 1.0241 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 6/6 | Batch 22400/48196 ( 46.5%) | loss 1.0241 | elapsed 4.1m | ETA 4.8m\n",
      "Epoch 6/6 | Batch 22600/48196 ( 46.9%) | loss 1.0241 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 6/6 | Batch 22800/48196 ( 47.3%) | loss 1.0242 | elapsed 4.2m | ETA 4.7m\n",
      "Epoch 6/6 | Batch 23000/48196 ( 47.7%) | loss 1.0242 | elapsed 4.3m | ETA 4.7m\n",
      "Epoch 6/6 | Batch 23200/48196 ( 48.1%) | loss 1.0242 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 6/6 | Batch 23400/48196 ( 48.6%) | loss 1.0241 | elapsed 4.3m | ETA 4.6m\n",
      "Epoch 6/6 | Batch 23600/48196 ( 49.0%) | loss 1.0241 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 6/6 | Batch 23800/48196 ( 49.4%) | loss 1.0241 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 6/6 | Batch 24000/48196 ( 49.8%) | loss 1.0241 | elapsed 4.4m | ETA 4.5m\n",
      "Epoch 6/6 | Batch 24200/48196 ( 50.2%) | loss 1.0241 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 6/6 | Batch 24400/48196 ( 50.6%) | loss 1.0241 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 6/6 | Batch 24600/48196 ( 51.0%) | loss 1.0241 | elapsed 4.5m | ETA 4.4m\n",
      "Epoch 6/6 | Batch 24800/48196 ( 51.5%) | loss 1.0241 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 6/6 | Batch 25000/48196 ( 51.9%) | loss 1.0241 | elapsed 4.6m | ETA 4.3m\n",
      "Epoch 6/6 | Batch 25200/48196 ( 52.3%) | loss 1.0241 | elapsed 4.7m | ETA 4.3m\n",
      "Epoch 6/6 | Batch 25400/48196 ( 52.7%) | loss 1.0241 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 6/6 | Batch 25600/48196 ( 53.1%) | loss 1.0241 | elapsed 4.7m | ETA 4.2m\n",
      "Epoch 6/6 | Batch 25800/48196 ( 53.5%) | loss 1.0241 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 6/6 | Batch 26000/48196 ( 53.9%) | loss 1.0241 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 6/6 | Batch 26200/48196 ( 54.4%) | loss 1.0241 | elapsed 4.8m | ETA 4.1m\n",
      "Epoch 6/6 | Batch 26400/48196 ( 54.8%) | loss 1.0241 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 6/6 | Batch 26600/48196 ( 55.2%) | loss 1.0241 | elapsed 4.9m | ETA 4.0m\n",
      "Epoch 6/6 | Batch 26800/48196 ( 55.6%) | loss 1.0241 | elapsed 5.0m | ETA 4.0m\n",
      "Epoch 6/6 | Batch 27000/48196 ( 56.0%) | loss 1.0241 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 6/6 | Batch 27200/48196 ( 56.4%) | loss 1.0241 | elapsed 5.0m | ETA 3.9m\n",
      "Epoch 6/6 | Batch 27400/48196 ( 56.9%) | loss 1.0241 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 6/6 | Batch 27600/48196 ( 57.3%) | loss 1.0241 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 6/6 | Batch 27800/48196 ( 57.7%) | loss 1.0241 | elapsed 5.1m | ETA 3.8m\n",
      "Epoch 6/6 | Batch 28000/48196 ( 58.1%) | loss 1.0241 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 6/6 | Batch 28200/48196 ( 58.5%) | loss 1.0240 | elapsed 5.2m | ETA 3.7m\n",
      "Epoch 6/6 | Batch 28400/48196 ( 58.9%) | loss 1.0241 | elapsed 5.3m | ETA 3.7m\n",
      "Epoch 6/6 | Batch 28600/48196 ( 59.3%) | loss 1.0241 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 6/6 | Batch 28800/48196 ( 59.8%) | loss 1.0241 | elapsed 5.3m | ETA 3.6m\n",
      "Epoch 6/6 | Batch 29000/48196 ( 60.2%) | loss 1.0240 | elapsed 5.4m | ETA 3.6m\n",
      "Epoch 6/6 | Batch 29200/48196 ( 60.6%) | loss 1.0240 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 6/6 | Batch 29400/48196 ( 61.0%) | loss 1.0240 | elapsed 5.4m | ETA 3.5m\n",
      "Epoch 6/6 | Batch 29600/48196 ( 61.4%) | loss 1.0240 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 6/6 | Batch 29800/48196 ( 61.8%) | loss 1.0240 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 6/6 | Batch 30000/48196 ( 62.2%) | loss 1.0240 | elapsed 5.5m | ETA 3.4m\n",
      "Epoch 6/6 | Batch 30200/48196 ( 62.7%) | loss 1.0240 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 6/6 | Batch 30400/48196 ( 63.1%) | loss 1.0240 | elapsed 5.6m | ETA 3.3m\n",
      "Epoch 6/6 | Batch 30600/48196 ( 63.5%) | loss 1.0240 | elapsed 5.7m | ETA 3.3m\n",
      "Epoch 6/6 | Batch 30800/48196 ( 63.9%) | loss 1.0240 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 6/6 | Batch 31000/48196 ( 64.3%) | loss 1.0240 | elapsed 5.7m | ETA 3.2m\n",
      "Epoch 6/6 | Batch 31200/48196 ( 64.7%) | loss 1.0240 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 6/6 | Batch 31400/48196 ( 65.2%) | loss 1.0240 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 6/6 | Batch 31600/48196 ( 65.6%) | loss 1.0240 | elapsed 5.8m | ETA 3.1m\n",
      "Epoch 6/6 | Batch 31800/48196 ( 66.0%) | loss 1.0240 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 6/6 | Batch 32000/48196 ( 66.4%) | loss 1.0240 | elapsed 5.9m | ETA 3.0m\n",
      "Epoch 6/6 | Batch 32200/48196 ( 66.8%) | loss 1.0240 | elapsed 6.0m | ETA 3.0m\n",
      "Epoch 6/6 | Batch 32400/48196 ( 67.2%) | loss 1.0240 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 6/6 | Batch 32600/48196 ( 67.6%) | loss 1.0240 | elapsed 6.0m | ETA 2.9m\n",
      "Epoch 6/6 | Batch 32800/48196 ( 68.1%) | loss 1.0240 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 6/6 | Batch 33000/48196 ( 68.5%) | loss 1.0240 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 6/6 | Batch 33200/48196 ( 68.9%) | loss 1.0240 | elapsed 6.1m | ETA 2.8m\n",
      "Epoch 6/6 | Batch 33400/48196 ( 69.3%) | loss 1.0240 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 6/6 | Batch 33600/48196 ( 69.7%) | loss 1.0240 | elapsed 6.2m | ETA 2.7m\n",
      "Epoch 6/6 | Batch 33800/48196 ( 70.1%) | loss 1.0240 | elapsed 6.3m | ETA 2.7m\n",
      "Epoch 6/6 | Batch 34000/48196 ( 70.5%) | loss 1.0240 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 6/6 | Batch 34200/48196 ( 71.0%) | loss 1.0240 | elapsed 6.3m | ETA 2.6m\n",
      "Epoch 6/6 | Batch 34400/48196 ( 71.4%) | loss 1.0240 | elapsed 6.4m | ETA 2.6m\n",
      "Epoch 6/6 | Batch 34600/48196 ( 71.8%) | loss 1.0240 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 6/6 | Batch 34800/48196 ( 72.2%) | loss 1.0240 | elapsed 6.4m | ETA 2.5m\n",
      "Epoch 6/6 | Batch 35000/48196 ( 72.6%) | loss 1.0240 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 6/6 | Batch 35200/48196 ( 73.0%) | loss 1.0240 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 6/6 | Batch 35400/48196 ( 73.5%) | loss 1.0240 | elapsed 6.5m | ETA 2.4m\n",
      "Epoch 6/6 | Batch 35600/48196 ( 73.9%) | loss 1.0240 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 6/6 | Batch 35800/48196 ( 74.3%) | loss 1.0240 | elapsed 6.6m | ETA 2.3m\n",
      "Epoch 6/6 | Batch 36000/48196 ( 74.7%) | loss 1.0239 | elapsed 6.7m | ETA 2.3m\n",
      "Epoch 6/6 | Batch 36200/48196 ( 75.1%) | loss 1.0239 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 6/6 | Batch 36400/48196 ( 75.5%) | loss 1.0239 | elapsed 6.7m | ETA 2.2m\n",
      "Epoch 6/6 | Batch 36600/48196 ( 75.9%) | loss 1.0239 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 6/6 | Batch 36800/48196 ( 76.4%) | loss 1.0239 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 6/6 | Batch 37000/48196 ( 76.8%) | loss 1.0240 | elapsed 6.8m | ETA 2.1m\n",
      "Epoch 6/6 | Batch 37200/48196 ( 77.2%) | loss 1.0239 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 6/6 | Batch 37400/48196 ( 77.6%) | loss 1.0239 | elapsed 6.9m | ETA 2.0m\n",
      "Epoch 6/6 | Batch 37600/48196 ( 78.0%) | loss 1.0239 | elapsed 7.0m | ETA 2.0m\n",
      "Epoch 6/6 | Batch 37800/48196 ( 78.4%) | loss 1.0239 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 6/6 | Batch 38000/48196 ( 78.8%) | loss 1.0239 | elapsed 7.0m | ETA 1.9m\n",
      "Epoch 6/6 | Batch 38200/48196 ( 79.3%) | loss 1.0239 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 6/6 | Batch 38400/48196 ( 79.7%) | loss 1.0239 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 6/6 | Batch 38600/48196 ( 80.1%) | loss 1.0239 | elapsed 7.1m | ETA 1.8m\n",
      "Epoch 6/6 | Batch 38800/48196 ( 80.5%) | loss 1.0239 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 6/6 | Batch 39000/48196 ( 80.9%) | loss 1.0239 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 6/6 | Batch 39200/48196 ( 81.3%) | loss 1.0239 | elapsed 7.2m | ETA 1.7m\n",
      "Epoch 6/6 | Batch 39400/48196 ( 81.7%) | loss 1.0239 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 6/6 | Batch 39600/48196 ( 82.2%) | loss 1.0239 | elapsed 7.3m | ETA 1.6m\n",
      "Epoch 6/6 | Batch 39800/48196 ( 82.6%) | loss 1.0239 | elapsed 7.4m | ETA 1.6m\n",
      "Epoch 6/6 | Batch 40000/48196 ( 83.0%) | loss 1.0239 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 6/6 | Batch 40200/48196 ( 83.4%) | loss 1.0239 | elapsed 7.4m | ETA 1.5m\n",
      "Epoch 6/6 | Batch 40400/48196 ( 83.8%) | loss 1.0239 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 6/6 | Batch 40600/48196 ( 84.2%) | loss 1.0239 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 6/6 | Batch 40800/48196 ( 84.7%) | loss 1.0239 | elapsed 7.5m | ETA 1.4m\n",
      "Epoch 6/6 | Batch 41000/48196 ( 85.1%) | loss 1.0239 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 6/6 | Batch 41200/48196 ( 85.5%) | loss 1.0239 | elapsed 7.6m | ETA 1.3m\n",
      "Epoch 6/6 | Batch 41400/48196 ( 85.9%) | loss 1.0239 | elapsed 7.7m | ETA 1.3m\n",
      "Epoch 6/6 | Batch 41600/48196 ( 86.3%) | loss 1.0239 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 6/6 | Batch 41800/48196 ( 86.7%) | loss 1.0239 | elapsed 7.7m | ETA 1.2m\n",
      "Epoch 6/6 | Batch 42000/48196 ( 87.1%) | loss 1.0239 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 6/6 | Batch 42200/48196 ( 87.6%) | loss 1.0239 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 6/6 | Batch 42400/48196 ( 88.0%) | loss 1.0239 | elapsed 7.8m | ETA 1.1m\n",
      "Epoch 6/6 | Batch 42600/48196 ( 88.4%) | loss 1.0239 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 6/6 | Batch 42800/48196 ( 88.8%) | loss 1.0239 | elapsed 7.9m | ETA 1.0m\n",
      "Epoch 6/6 | Batch 43000/48196 ( 89.2%) | loss 1.0239 | elapsed 8.0m | ETA 1.0m\n",
      "Epoch 6/6 | Batch 43200/48196 ( 89.6%) | loss 1.0239 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 6/6 | Batch 43400/48196 ( 90.0%) | loss 1.0238 | elapsed 8.0m | ETA 0.9m\n",
      "Epoch 6/6 | Batch 43600/48196 ( 90.5%) | loss 1.0238 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 6/6 | Batch 43800/48196 ( 90.9%) | loss 1.0238 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 6/6 | Batch 44000/48196 ( 91.3%) | loss 1.0238 | elapsed 8.1m | ETA 0.8m\n",
      "Epoch 6/6 | Batch 44200/48196 ( 91.7%) | loss 1.0238 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 6/6 | Batch 44400/48196 ( 92.1%) | loss 1.0238 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 6/6 | Batch 44600/48196 ( 92.5%) | loss 1.0238 | elapsed 8.2m | ETA 0.7m\n",
      "Epoch 6/6 | Batch 44800/48196 ( 93.0%) | loss 1.0238 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 6/6 | Batch 45000/48196 ( 93.4%) | loss 1.0238 | elapsed 8.3m | ETA 0.6m\n",
      "Epoch 6/6 | Batch 45200/48196 ( 93.8%) | loss 1.0238 | elapsed 8.4m | ETA 0.6m\n",
      "Epoch 6/6 | Batch 45400/48196 ( 94.2%) | loss 1.0238 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 6/6 | Batch 45600/48196 ( 94.6%) | loss 1.0238 | elapsed 8.4m | ETA 0.5m\n",
      "Epoch 6/6 | Batch 45800/48196 ( 95.0%) | loss 1.0238 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 6/6 | Batch 46000/48196 ( 95.4%) | loss 1.0238 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 6/6 | Batch 46200/48196 ( 95.9%) | loss 1.0238 | elapsed 8.5m | ETA 0.4m\n",
      "Epoch 6/6 | Batch 46400/48196 ( 96.3%) | loss 1.0238 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 6/6 | Batch 46600/48196 ( 96.7%) | loss 1.0238 | elapsed 8.6m | ETA 0.3m\n",
      "Epoch 6/6 | Batch 46800/48196 ( 97.1%) | loss 1.0238 | elapsed 8.7m | ETA 0.3m\n",
      "Epoch 6/6 | Batch 47000/48196 ( 97.5%) | loss 1.0238 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 6/6 | Batch 47200/48196 ( 97.9%) | loss 1.0238 | elapsed 8.7m | ETA 0.2m\n",
      "Epoch 6/6 | Batch 47400/48196 ( 98.3%) | loss 1.0238 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 6/6 | Batch 47600/48196 ( 98.8%) | loss 1.0238 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 6/6 | Batch 47800/48196 ( 99.2%) | loss 1.0238 | elapsed 8.8m | ETA 0.1m\n",
      "Epoch 6/6 | Batch 48000/48196 ( 99.6%) | loss 1.0238 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 6/6 | Batch 48196/48196 (100.0%) | loss 1.0237 | elapsed 8.9m | ETA 0.0m\n",
      "Epoch 6 DONE | train_loss 1.0221 ppl 2.779 | val_loss 1.3413 ppl 3.824\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6   # enough to show training behavior\n",
    "\n",
    "train_losses, val_losses, train_ppls, val_ppls = train_modules_with_history(\n",
    "    embed,\n",
    "    lstm,\n",
    "    fc,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    save_path=checkpoint_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:01:53.430196Z",
     "iopub.status.busy": "2026-01-30T11:01:53.429898Z",
     "iopub.status.idle": "2026-01-30T11:01:53.677618Z",
     "shell.execute_reply": "2026-01-30T11:01:53.676857Z",
     "shell.execute_reply.started": "2026-01-30T11:01:53.430161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_ppls, label=\"train\")\n",
    "plt.plot(val_ppls, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:01:53.678592Z",
     "iopub.status.busy": "2026-01-30T11:01:53.678394Z",
     "iopub.status.idle": "2026-01-30T11:01:54.149648Z",
     "shell.execute_reply": "2026-01-30T11:01:54.149041Z",
     "shell.execute_reply.started": "2026-01-30T11:01:53.678573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICHAEL: Huh... We've been candy for an artificant.\n",
      "Darryl: And that's what I did, yeah.\n",
      "Michael: Okay, I just came in and give you a picture of myself from you, but sometimes... I... I just want to come into his ST.. You know what? I like a little rating times.\n",
      "Michael: You better be considering my respectful. And you don't think you're a history.\n",
      "Michael: That is so cool.\n",
      "David: What is going on?\n",
      "Michael: I am just taking you in a note, Jim. Ryan.\n",
      "Michael: I am a back these business, getting with a better man. They're mission sexy sentences.\n",
      "Dwight: Watch the table.\n",
      "Michael: Hmmm.\n",
      "Michael: Excuse me, that's not about the break.\n",
      "Dwight: Cookies. Here we go. \n",
      "Michael: Guys. Thanks.\n",
      "Ryan: They are going to be shoops you don't know if you know all of you to flet the first time, and I know you did not\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(generate_script(\"MICHAEL: \", temperature=0.7, num_tokens_to_generate=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:01:54.151244Z",
     "iopub.status.busy": "2026-01-30T11:01:54.150611Z",
     "iopub.status.idle": "2026-01-30T11:01:54.527806Z",
     "shell.execute_reply": "2026-01-30T11:01:54.527029Z",
     "shell.execute_reply.started": "2026-01-30T11:01:54.151221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICHAEL: YOU MADS. Oh, you know what? I'm gonna need to go to the hospital and we were the one thing. \n",
      "Michael:  Okay, now I can't take a little bit of a streamers. And the people who work out there will be so dorky.\n",
      "Michael: Well, I was just watching a business coming to me. I am sorry about that. And I want you to see you and I am so many times.\n",
      "Michael: Well, I don't know. I don't know. I just don't know.\n",
      "Michael: Hey, what's the sale?\n",
      "Michael: I don't know. I don't know. I don't know what you're doing this. The rest of the baby in the bathroom.\n",
      "Jim: Okay.\n",
      "Michael: That was a problem.\n",
      "Pam: I don't know. I don't know what the best manager. The person can have a couple of things who doesn't show you this. I think I'm gonna make a couple of the first time. I was thinking that I want to give you thi\n"
     ]
    }
   ],
   "source": [
    "print(generate_script(\"MICHAEL: \", temperature=0.335, num_tokens_to_generate=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:01:54.529084Z",
     "iopub.status.busy": "2026-01-30T11:01:54.528723Z",
     "iopub.status.idle": "2026-01-30T11:01:54.903575Z",
     "shell.execute_reply": "2026-01-30T11:01:54.903029Z",
     "shell.execute_reply.started": "2026-01-30T11:01:54.529061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICHAEL: No, no, no, no, no. It will.\n",
      "Jan:  Nazili, what 's having baby? Watch oper a year.\n",
      "Pam: GItare Flax. Though. Lets be telling me now of a Michael. After all about this. It's also not a long time, he can take the cat with - since I'm going to come in on you. Okay? Well, idiot. One Sabre plan.\n",
      "Michael: And how does that make a Corner Man?\n",
      "Pam: Oh.\n",
      "Jim: Wow, I know you know what Dwight sitter talking with the news and precises are trying to have her.\n",
      "Dwight: My job best work stickmet? \n",
      "Dwight: Thank you.\n",
      "Michael: You're cool.\n",
      "Michael: In three weird, like, affiry, about Paper Charles...Taper medami. After 25 miles after day how kind of look of sleep back to my life.\n",
      "Michael: Yes it is!\n",
      "Phyllis: I'm sorry  -- somebody's blindfouse man. It's over.\n",
      "Michael:  Pam. Nice to meet...\n",
      "Jim:  Hey, guys. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(generate_script(\"MICHAEL: \", temperature=1, num_tokens_to_generate=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9369375,
     "sourceId": 14665961,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
