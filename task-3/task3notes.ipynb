{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78650b7-06e8-47db-a139-44a9b4dd6c69",
   "metadata": {},
   "source": [
    "# OPTIMIZERS\n",
    "\n",
    "#### SGD (Stochastic Gradient Descent): \n",
    "Updates weights after every single example. Fast but \"jittery.\"\n",
    "\n",
    "### RMSprop: \n",
    "Adjusts the learning rate for each weight. It slows down when gradients are too steep to avoid overshooting.\n",
    "\n",
    "### Adam: The \"Gold Standard.\" \n",
    "It combines the best of all worlds (momentum + adaptive learning rates). Use this if you don't know what else to pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b44f51-9435-426b-9e64-2b826bdf0d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0075f891-b8fb-4d98-bd5f-bf9abe4786f0",
   "metadata": {},
   "source": [
    "# regularization (prevents memorization)\n",
    "Overfitting is when a model memorizes the training data but fails on new data. Underfitting is when itâ€™s too simple to learn anything at all. Regularization forces the model to stay simple.\n",
    "\n",
    "L1 (Lasso): Shrinks some weights to exactly zero. Good for feature selection.\n",
    "\n",
    "L2 (Weight Decay): Shrinks weights to be small but not zero. Prevents any one weight from having too much power.\n",
    "\n",
    "Dropout: Randomly \"turns off\" neurons during training. This forces the network to not rely on any single neuron, making it more robust.\n",
    "\n",
    "Normalization (Batch/Layer): It re-scales the data between layers so the numbers don't get too huge or too tiny. It makes training much faster and more stable.\n",
    "\n",
    "Early Stopping: Stop training the moment the \"Validation Error\" starts going back up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1546855-b44f-4378-9876-87754d029785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb008d1b-81fe-4b12-8994-05326fdec4b6",
   "metadata": {},
   "source": [
    "# The Problem: Exploding vs. Vanishing Gradients\n",
    "Vanishing: If weights are too small, the gradient (signal) gets smaller and smaller as it goes backward until it disappears. The model stops learning.\n",
    "\n",
    "Exploding: If weights are too large, the gradient blows up to infinity, crashing the model.\n",
    "\n",
    "##### The Fixes\n",
    "Weight Initialization:\n",
    "\n",
    "Xavier (Glorot): Best for Sigmoid/Tanh activations.\n",
    "\n",
    "He Initialization: Best for ReLU activations.\n",
    "\n",
    "##### Activation Functions:\n",
    "\n",
    "Sigmoid/Tanh: Old school. Prone to vanishing gradients.\n",
    "\n",
    "ReLU: The default. Fast and solves vanishing gradients but can suffer from Dying ReLU (neurons get stuck at zero and never wake up).\n",
    "\n",
    "Softmax: Used at the very last layer for classification to turn numbers into probabilities.\n",
    "\n",
    "Gradient Clipping: If the gradient gets too big (exploding), we literally \"clip\" it to a maximum value to keep it under control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68cbcc-60a6-4108-b098-090bb33aad85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cff9cf0-58cd-4530-a2f9-64ada33e8133",
   "metadata": {},
   "source": [
    "TopicInterviewer Asks...You Answer...Backprop\"How does a network learn?\"\"It uses the Chain Rule to calculate the gradient of the loss function with respect to every weight, moving backward from output to input.\"Adam\"Why use Adam?\"\"It combines Momentum (to get past local minima) and RMSprop (to scale learning rates for each parameter), making it fast and robust.\"Overfitting\"How do you stop overfitting?\"\"Dropout to prevent co-dependency, L2 Regularization to keep weights small, and Early Stopping.\"Batchnorm\"Why use Batch Normalization?\"\"It reduces Internal Covariate Shift, allows for higher learning rates, and acts as a slight regularizer.\"Vanishing Gradients\"Why is Sigmoid bad for deep nets?\"\"Its derivative is very small (max 0.25). Multiplying many small numbers during backprop causes the gradient to vanish.\"ReLU\"What is the Dying ReLU problem?\"\"If a neuron's input is always negative, it outputs 0. The gradient is 0, so it never updates. Solve it using Leaky ReLU.\"Initialization\"Can we init weights to zero?\"\"No. All neurons would do the exact same thing (symmetry). We need random initialization like He or Xavier.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fea211-e3c9-4510-89cc-6e23a5d33af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
