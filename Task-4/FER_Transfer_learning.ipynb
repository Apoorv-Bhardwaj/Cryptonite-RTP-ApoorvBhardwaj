{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yrOdnqspwWBg",
    "outputId": "2076297d-58d9-4f19-b244-08e697970926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npu4rgN8wch-",
    "outputId": "b61dc772-c8e8-4eb2-f0ab-76818f8ddb37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Extraction done.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# paths\n",
    "ZIP_PATH = \"/content/drive/MyDrive/data_extracted/faces.zip\"\n",
    "EXTRACT_TO = \"/content/drive/MyDrive/data_extracted\"\n",
    "\n",
    "# create clean target folder\n",
    "# !mkdir -p \"$EXTRACT_TO\"\n",
    "\n",
    "# extract\n",
    "# !unzip -q \"$ZIP_PATH\" -d \"$EXTRACT_TO\"\n",
    "\n",
    "print(\"Extraction done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VFr2G7e1GT8",
    "outputId": "d84d12ac-0a66-4665-f61f-4c5cc149451f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR  = \"/content/drive/MyDrive/data_extracted\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# class names (folder names = labels)\n",
    "classes = sorted(os.listdir(TRAIN_DIR))\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "print(\"Classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jirPWNQZ5Uyt"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # faces often grayscale\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjZ5hBho5lCi",
    "outputId": "57c1d094-4a70-4da5-9fd4-48fcfd554394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 28250\n",
      "Test samples : 7178\n"
     ]
    }
   ],
   "source": [
    "def build_file_list(root_dir):\n",
    "    files = []\n",
    "    labels = []\n",
    "    for cls in classes:\n",
    "        cls_dir = os.path.join(root_dir, cls)\n",
    "        for fname in os.listdir(cls_dir):\n",
    "            files.append(os.path.join(cls_dir, fname))\n",
    "            labels.append(class_to_idx[cls])\n",
    "    return files, labels\n",
    "\n",
    "train_files, train_labels = build_file_list(TRAIN_DIR)\n",
    "test_files, test_labels   = build_file_list(TEST_DIR)\n",
    "\n",
    "print(\"Train samples:\", len(train_files))\n",
    "print(\"Test samples :\", len(test_files))\n",
    "\n",
    "\n",
    "def load_image(path, transform):\n",
    "    img = Image.open(path).convert(\"L\")  # grayscale face\n",
    "    return transform(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Q7u2GlD75v9X"
   },
   "outputs": [],
   "source": [
    "# MANUAL BATCH LOADER\n",
    "def get_batch(files, labels, transform, batch_size, start):\n",
    "    imgs, labs = [], []\n",
    "    end = min(start + batch_size, len(files))\n",
    "\n",
    "    for i in range(start, end):\n",
    "        imgs.append(load_image(files[i], transform))\n",
    "        labs.append(torch.tensor(labels[i]))\n",
    "\n",
    "    return (\n",
    "        torch.stack(imgs).to(device),\n",
    "        torch.stack(labs).to(device)\n",
    "    )\n",
    "\n",
    "# MODEL (ResNet18)\n",
    "num_classes = len(classes)\n",
    "\n",
    "model = timm.create_model(\"resnet18\", pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4tYCcby6bT5"
   },
   "outputs": [],
   "source": [
    "# TRAIN & EVAL FUNCTIONS\n",
    "\n",
    "def train_epoch(files, labels, transform, optimizer, batch_size=32):\n",
    "    model.train()\n",
    "    correct = total = 0\n",
    "\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        imgs, labs = get_batch(files, labels, transform, batch_size, i)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = out.argmax(1)\n",
    "        correct += (preds == labs).sum().item()\n",
    "        total += labs.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def evaluate(files, labels, transform, batch_size=32):\n",
    "    model.eval()\n",
    "    preds_all, labels_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(files), batch_size):\n",
    "            imgs, labs = get_batch(files, labels, transform, batch_size, i)\n",
    "            out = model(imgs)\n",
    "            preds_all.append(out.argmax(1).cpu())\n",
    "            labels_all.append(labs.cpu())\n",
    "\n",
    "    return (\n",
    "        torch.cat(labels_all).numpy(),\n",
    "        torch.cat(preds_all).numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "# PARTIAL FINE-TUNING (classifier only)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"\\nPartial Fine-Tuning\")\n",
    "for epoch in range(3):\n",
    "    acc = train_epoch(train_files, train_labels, train_transform, optimizer)\n",
    "    print(f\"Epoch {epoch+1}: Train Acc = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Hk_621mDEir"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "print(\"\\nFull Fine-Tuning\")\n",
    "for epoch in range(5):\n",
    "    acc = train_epoch(train_files, train_labels, train_transform, optimizer)\n",
    "    print(f\"Epoch {epoch+1}: Train Acc = {acc:.4f}\")\n",
    "\n",
    "# FINAL TEST METRICS\n",
    "\n",
    "y_true, y_pred = evaluate(test_files, test_labels, test_transform)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
