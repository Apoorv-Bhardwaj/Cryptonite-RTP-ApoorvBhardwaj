{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Ys1A6Zg0tFNR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6V6MpqQoZDNU",
    "outputId": "5e1239d2-d8ac-4e20-9044-d9110da12dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# unzip (ZIP)\n",
    "# !unzip \"/content/drive/MyDrive/data/archive.zip\" -d \"/content/drive/MyDrive/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "WLPpP87WjWGF",
    "outputId": "7677fbf6-f7f7-4107-ba6f-2ae0f463694d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nZIP_PATH = \"/content/drive/MyDrive/data/archive.zip\"\\nEXTRACT_TO = \"/content/drive/MyDrive/data_extracted\"# clean new folder\\n!mkdir -p \"$EXTRACT_T\\n!unzip -q \"$ZIP_PATH\" -d \"$EXTRACT_TO\"\\nprint(\"Extraction complete\")\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ZIP_PATH = \"/content/drive/MyDrive/data/archive.zip\"\n",
    "EXTRACT_TO = \"/content/drive/MyDrive/data_extracted\"# clean new folder\n",
    "!mkdir -p \"$EXTRACT_T\n",
    "!unzip -q \"$ZIP_PATH\" -d \"$EXTRACT_TO\"\n",
    "print(\"Extraction complete\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcD78cjOnsFC",
    "outputId": "ee51e846-ffb7-4d18-ec95-31d9ed5c46d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level extracted folders/files:\n",
      "['images', 'labels']\n",
      "\n",
      "Contents of images:\n",
      "['20160928-140314-0.jpg', '20160928-140337-0.jpg', '20160928-140731-0.jpg', '20160928-140747-0.jpg', '20160928-141107-0.jpg', '20160928-141135-0.jpg', '20160928-141355-0.jpg', '20160928-141421-0.jpg', '20160928-141437-0.jpg', '20160928-142056-0.jpg']\n",
      "\n",
      "Contents of labels:\n",
      "['labels.csv', 'test_subset0.csv', 'test_subset1.csv', 'test_subset2.csv', 'test_subset3.csv', 'test_subset4.csv', 'train_subset0.csv', 'train_subset1.csv', 'train_subset2.csv', 'train_subset3.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Top-level extracted folders/files:\")\n",
    "print(os.listdir(EXTRACT_TO))\n",
    "\n",
    "# Look one level deeper if needed\n",
    "for item in os.listdir(EXTRACT_TO):\n",
    "    path = os.path.join(EXTRACT_TO, item)\n",
    "    if os.path.isdir(path):\n",
    "        print(f\"\\nContents of {item}:\")\n",
    "        print(os.listdir(path)[:10])  # show only first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJ2y7YeKoral",
    "outputId": "39d0b0f5-9d2c-4305-f915-039f8a07d920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels folder exists: True\n",
      "Images folder exists: True\n",
      "Labels files: ['labels.csv', 'test_subset0.csv', 'test_subset1.csv', 'test_subset2.csv', 'test_subset3.csv', 'test_subset4.csv', 'train_subset0.csv', 'train_subset1.csv', 'train_subset2.csv', 'train_subset3.csv', 'train_subset4.csv', 'val_subset0.csv', 'val_subset1.csv', 'val_subset2.csv', 'val_subset3.csv', 'val_subset4.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main = \"/content/drive/MyDrive/data_extracted\"\n",
    "\n",
    "# Quick check: list the labels folder\n",
    "labels_folder = os.path.join(main, \"labels\")\n",
    "images_folder = os.path.join(main, \"images\")\n",
    "print(\"Labels folder exists:\", os.path.exists(labels_folder))\n",
    "print(\"Images folder exists:\", os.path.exists(images_folder))\n",
    "print(\"Labels files:\", sorted(os.listdir(labels_folder))[:20])  # show first 20 label files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsEeIvjNps52",
    "outputId": "018b832f-6e17-497d-a5a2-304beb3f4215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv path: /content/drive/MyDrive/data_extracted/labels/labels.csv\n",
      "columns: ['Filename', 'Label', 'Species']\n",
      "first 6 rows:\n",
      "                 Filename  Label       Species\n",
      "0  20160928-140314-0.jpg      0  Chinee apple\n",
      "1  20160928-140337-0.jpg      0  Chinee apple\n",
      "2  20160928-140731-0.jpg      0  Chinee apple\n",
      "3  20160928-140747-0.jpg      0  Chinee apple\n",
      "4  20160928-141107-0.jpg      0  Chinee apple\n",
      "5  20160928-141135-0.jpg      0  Chinee apple\n",
      "\n",
      "Test subset example (first 6):\n",
      "                 Filename  Label\n",
      "0  20160928-140747-0.jpg      0\n",
      "1  20160928-141437-0.jpg      0\n",
      "2  20160928-142110-0.jpg      0\n",
      "3  20161207-110730-0.jpg      0\n",
      "4  20161207-110753-0.jpg      0\n",
      "5  20161207-110837-0.jpg      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels_csv = os.path.join(labels_folder, \"labels.csv\")\n",
    "print(\"labels.csv path:\", labels_csv)\n",
    "df_labels = pd.read_csv(labels_csv)\n",
    "print(\"columns:\", df_labels.columns.tolist())\n",
    "print(\"first 6 rows:\\n\", df_labels.head(6))\n",
    "\n",
    "# peek one subset at  (test_subset0.csv)\n",
    "test0 = pd.read_csv(os.path.join(labels_folder, \"test_subset0.csv\"))\n",
    "print(\"\\nTest subset example (first 6):\\n\", test0.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KCf8LPkMp2LI",
    "outputId": "5e1787bf-76be-4ddf-f017-c030869b1ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root exists: True\n",
      "labels dir exists: True\n",
      "images dir exists: True\n",
      "files in labels dir (sample): ['labels.csv', 'test_subset0.csv', 'test_subset1.csv', 'test_subset2.csv', 'test_subset3.csv', 'test_subset4.csv', 'train_subset0.csv', 'train_subset1.csv', 'train_subset2.csv', 'train_subset3.csv', 'train_subset4.csv', 'val_subset0.csv', 'val_subset1.csv', 'val_subset2.csv', 'val_subset3.csv', 'val_subset4.csv']\n"
     ]
    }
   ],
   "source": [
    "main = \"/content/drive/MyDrive/data_extracted\"\n",
    "LABELS_DIR = os.path.join(main, \"labels\")\n",
    "IMAGES_DIR = os.path.join(main, \"images\")\n",
    "\n",
    "# it disappears bro\n",
    "print(\"root exists:\", os.path.exists(main))\n",
    "print(\"labels dir exists:\", os.path.exists(LABELS_DIR))\n",
    "print(\"images dir exists:\", os.path.exists(IMAGES_DIR))\n",
    "print(\"files in labels dir (sample):\", sorted(os.listdir(LABELS_DIR))[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTNHrDeLqS9l",
    "outputId": "0e1e6553-1e68-4a90-c795-bd22babfcc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master CSV: /content/drive/MyDrive/data_extracted/labels/labels.csv\n",
      "master_df columns: ['Filename', 'Label', 'Species']\n",
      "                Filename  Label       Species\n",
      "0  20160928-140314-0.jpg      0  Chinee apple\n",
      "1  20160928-140337-0.jpg      0  Chinee apple\n",
      "2  20160928-140731-0.jpg      0  Chinee apple\n",
      "3  20160928-140747-0.jpg      0  Chinee apple\n",
      "4  20160928-141107-0.jpg      0  Chinee apple\n",
      "5  20160928-141135-0.jpg      0  Chinee apple\n",
      "\n",
      "Subset sample:                 Filename  Label\n",
      "0  20160928-140747-0.jpg      0\n",
      "1  20160928-141437-0.jpg      0\n",
      "2  20160928-142110-0.jpg      0\n",
      "3  20161207-110730-0.jpg      0\n",
      "4  20161207-110753-0.jpg      0\n",
      "5  20161207-110837-0.jpg      0\n"
     ]
    }
   ],
   "source": [
    "master_csv = os.path.join(LABELS_DIR, \"labels.csv\")\n",
    "print(\"Master CSV:\", master_csv)\n",
    "master_df = pd.read_csv(master_csv)   # contains Filename,Label,Species (as you showed)\n",
    "print(\"master_df columns:\", master_df.columns.tolist())\n",
    "print(master_df.head(6))\n",
    "\n",
    "subset0 = pd.read_csv(os.path.join(LABELS_DIR, \"test_subset0.csv\"))\n",
    "print(\"\\nSubset sample:\", subset0.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_WozKKXqfnd",
    "outputId": "e53c7e43-c488-4f8b-a2d5-cba238db7264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val/test sizes: 52525 17511 17509\n",
      "train sample:\n",
      "                 Filename  Label\n",
      "0  20171109-175921-2.jpg      5\n",
      "1  20170714-142019-3.jpg      1\n",
      "2  20170718-101402-2.jpg      0\n",
      "3  20170126-095456-0.jpg      1\n",
      "4  20170913-110647-1.jpg      3\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "def concat_subsets(labels_dir, pattern):\n",
    "    \"\"\"Concatenate CSV files matching pattern in labels_dir into one DataFrame.\"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(labels_dir, pattern)))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No files for pattern {pattern} in {labels_dir}\")\n",
    "    dfs = [pd.read_csv(p) for p in paths]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "train_df = concat_subsets(LABELS_DIR, \"train_subset*.csv\")\n",
    "val_df   = concat_subsets(LABELS_DIR, \"val_subset*.csv\")\n",
    "test_df  = concat_subsets(LABELS_DIR, \"test_subset*.csv\")\n",
    "\n",
    "print(\"train/val/test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "print(\"train sample:\\n\", train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLIhtt8Xqpbz",
    "outputId": "35566b0d-c6a6-49d2-9af3-913516a9dd18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7mBEREuOqzKu"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-6AbBJJ1sf8I"
   },
   "outputs": [],
   "source": [
    "def load_sample(row, image_dir, transform):\n",
    "    \"\"\"\n",
    "    row: one row from train_df / val_df / test_df\n",
    "    returns: image tensor, label tensor\n",
    "    \"\"\"\n",
    "    img_path = os.path.join(image_dir, row[\"Filename\"])\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = transform(image)\n",
    "    label = torch.tensor(int(row[\"Label\"]), dtype=torch.long)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def get_batch(df, image_dir, transform, batch_size, start_idx):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    end_idx = min(start_idx + batch_size, len(df))\n",
    "    for i in range(start_idx, end_idx):\n",
    "        img, lab = load_sample(df.iloc[i], image_dir, transform)\n",
    "        images.append(img)\n",
    "        labels.append(lab)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.stack(labels)\n",
    "    return images.to(device), labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "_Mf76UxYsmfT"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "num_classes = master_df[\"Label\"].nunique()\n",
    "\n",
    "model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(df, transform, optimizer, batch_size=32):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        images, labels = get_batch(df, IMAGES_DIR, transform, batch_size, i)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Wf9AGzfds7ea"
   },
   "outputs": [],
   "source": [
    "def evaluate(df, transform, batch_size=32):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            images, labels = get_batch(df, IMAGES_DIR, transform, batch_size, i)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(1)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    return all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPVx_IBttYOJ",
    "outputId": "e61c583f-5f34-4d84-8934-9667b6cbd3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial FT Epoch 1: Train Acc = 0.6812\n",
      "Partial FT Epoch 2: Train Acc = 0.7261\n",
      "Partial FT Epoch 3: Train Acc = 0.7362\n",
      "Partial FT Epoch 4: Train Acc = 0.7447\n",
      "Partial FT Epoch 5: Train Acc = 0.7474\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(5):\n",
    "    acc = train_epoch(train_df, train_transform, optimizer)\n",
    "    print(f\"Partial FT Epoch {epoch+1}: Train Acc = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaHmtntktbw_",
    "outputId": "3e2f48bc-b841-4098-fd21-cbb962443eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full FT Epoch 1: Train Acc = 0.8484\n",
      "Full FT Epoch 2: Train Acc = 0.9111\n",
      "Full FT Epoch 3: Train Acc = 0.9364\n",
      "Full FT Epoch 4: Train Acc = 0.9487\n",
      "Full FT Epoch 5: Train Acc = 0.9586\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(5):\n",
    "    acc = train_epoch(train_df, train_transform, optimizer)\n",
    "    print(f\"Full FT Epoch {epoch+1}: Train Acc = {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
