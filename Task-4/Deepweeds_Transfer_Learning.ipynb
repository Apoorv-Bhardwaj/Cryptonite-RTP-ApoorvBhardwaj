{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Ys1A6Zg0tFNR"
   },
   "outputs": [],
   "source": [
    "# import the main PyTorch package\n",
    "import torch\n",
    "# import PyTorch neural network module utilities (layers, losses, etc.)\n",
    "import torch.nn as nn\n",
    "# import PyTorch optimizers\n",
    "import torch.optim as optim\n",
    "# import torchvision transforms for common image preprocessing/augmentation\n",
    "from torchvision import transforms\n",
    "# import PIL.Image for opening images\n",
    "from PIL import Image\n",
    "# import os for filesystem path operations\n",
    "import os\n",
    "# import numpy for numeric utilities (not heavily used below but common)\n",
    "import numpy as np\n",
    "# import sklearn metrics for final classification reporting\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6V6MpqQoZDNU",
    "outputId": "5e1239d2-d8ac-4e20-9044-d9110da12dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# import Colab-specific drive mount helper (only works in Google Colab)\n",
    "from google.colab import drive\n",
    "# mount the user's Google Drive at /content/drive (interactive permission step in Colab)\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "WLPpP87WjWGF",
    "outputId": "7677fbf6-f7f7-4107-ba6f-2ae0f463694d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nZIP_PATH = \"/content/drive/MyDrive/data/archive.zip\"\\nEXTRACT_TO = \"/content/drive/MyDrive/data_extracted\"# clean new folder\\n!mkdir -p \"$EXTRACT_T\\n!unzip -q \"$ZIP_PATH\" -d \"$EXTRACT_TO\"\\nprint(\"Extraction complete\")\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ZIP_PATH = \"/content/drive/MyDrive/data/archive.zip\"\n",
    "EXTRACT_TO = \"/content/drive/MyDrive/data_extracted\"# clean new folder\n",
    "!mkdir -p \"$EXTRACT_T\n",
    "!unzip -q \"$ZIP_PATH\" -d \"$EXTRACT_TO\"\n",
    "print(\"Extraction complete\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcD78cjOnsFC",
    "outputId": "ee51e846-ffb7-4d18-ec95-31d9ed5c46d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level extracted folders/files:\n",
      "['images', 'labels']\n",
      "\n",
      "Contents of images:\n",
      "['20160928-140314-0.jpg', '20160928-140337-0.jpg', '20160928-140731-0.jpg', '20160928-140747-0.jpg', '20160928-141107-0.jpg', '20160928-141135-0.jpg', '20160928-141355-0.jpg', '20160928-141421-0.jpg', '20160928-141437-0.jpg', '20160928-142056-0.jpg']\n",
      "\n",
      "Contents of labels:\n",
      "['labels.csv', 'test_subset0.csv', 'test_subset1.csv', 'test_subset2.csv', 'test_subset3.csv', 'test_subset4.csv', 'train_subset0.csv', 'train_subset1.csv', 'train_subset2.csv', 'train_subset3.csv']\n"
     ]
    }
   ],
   "source": [
    "# import os (already imported above but repeated in the notebook)\n",
    "import os\n",
    "\n",
    "# print a short label\n",
    "print(\"Top-level extracted folders/files:\")\n",
    "# list the top-level directory 'EXTRACT_TO' and print the returned list\n",
    "print(os.listdir(EXTRACT_TO))\n",
    "\n",
    "# loop through items at top level and if the item is a directory, print a preview of its contents\n",
    "for item in os.listdir(EXTRACT_TO):\n",
    "    # join path pieces to make a full path to the item\n",
    "    path = os.path.join(EXTRACT_TO, item)\n",
    "    # check if it is a directory\n",
    "    if os.path.isdir(path):\n",
    "        # print which folder we are showing contents for\n",
    "        print(f\"\\nContents of {item}:\")\n",
    "        # print first 10 entries inside that folder to avoid very long output\n",
    "        print(os.listdir(path)[:10])  # show only first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJ2y7YeKoral",
    "outputId": "39d0b0f5-9d2c-4305-f915-039f8a07d920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels folder exists: True\n",
      "Images folder exists: True\n",
      "Labels files: ['labels.csv', 'test_subset0.csv', 'test_subset1.csv', 'test_subset2.csv', 'test_subset3.csv', 'test_subset4.csv', 'train_subset0.csv', 'train_subset1.csv', 'train_subset2.csv', 'train_subset3.csv', 'train_subset4.csv', 'val_subset0.csv', 'val_subset1.csv', 'val_subset2.csv', 'val_subset3.csv', 'val_subset4.csv']\n"
     ]
    }
   ],
   "source": [
    "# set the base path to the extracted dataset\n",
    "main = \"/content/drive/MyDrive/data_extracted\"\n",
    "\n",
    "# path to labels folder under main\n",
    "labels_folder = os.path.join(main, \"labels\")\n",
    "# path to images folder under main\n",
    "images_folder = os.path.join(main, \"images\")\n",
    "# print whether labels folder exists (True/False)\n",
    "print(\"Labels folder exists:\", os.path.exists(labels_folder))\n",
    "# print whether images folder exists (True/False)\n",
    "print(\"Images folder exists:\", os.path.exists(images_folder))\n",
    "# print a sorted slice of files found in the labels folder (first 20)\n",
    "print(\"Labels files:\", sorted(os.listdir(labels_folder))[:20])  # show first 20 label files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsEeIvjNps52",
    "outputId": "018b832f-6e17-497d-a5a2-304beb3f4215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv path: /content/drive/MyDrive/data_extracted/labels/labels.csv\n",
      "columns: ['Filename', 'Label', 'Species']\n",
      "first 6 rows:\n",
      "                 Filename  Label       Species\n",
      "0  20160928-140314-0.jpg      0  Chinee apple\n",
      "1  20160928-140337-0.jpg      0  Chinee apple\n",
      "2  20160928-140731-0.jpg      0  Chinee apple\n",
      "3  20160928-140747-0.jpg      0  Chinee apple\n",
      "4  20160928-141107-0.jpg      0  Chinee apple\n",
      "5  20160928-141135-0.jpg      0  Chinee apple\n",
      "\n",
      "Test subset example (first 6):\n",
      "                 Filename  Label\n",
      "0  20160928-140747-0.jpg      0\n",
      "1  20160928-141437-0.jpg      0\n",
      "2  20160928-142110-0.jpg      0\n",
      "3  20161207-110730-0.jpg      0\n",
      "4  20161207-110753-0.jpg      0\n",
      "5  20161207-110837-0.jpg      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels_csv = os.path.join(labels_folder, \"labels.csv\")\n",
    "print(\"labels.csv path:\", labels_csv)\n",
    "df_labels = pd.read_csv(labels_csv)\n",
    "print(\"columns:\", df_labels.columns.tolist())\n",
    "print(\"first 6 rows:\\n\", df_labels.head(6))\n",
    "\n",
    "# peek one subset at  (test_subset0.csv)\n",
    "test0 = pd.read_csv(os.path.join(labels_folder, \"test_subset0.csv\"))\n",
    "print(\"\\nTest subset example (first 6):\\n\", test0.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KCf8LPkMp2LI",
    "outputId": "5e1787bf-76be-4ddf-f017-c030869b1ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root exists: True\n",
      "labels dir exists: True\n",
      "images dir exists: True\n",
      "files in labels dir (sample): ['labels.csv', 'test_subset0.csv', 'test_subset1.csv', 'test_subset2.csv', 'test_subset3.csv', 'test_subset4.csv', 'train_subset0.csv', 'train_subset1.csv', 'train_subset2.csv', 'train_subset3.csv', 'train_subset4.csv', 'val_subset0.csv', 'val_subset1.csv', 'val_subset2.csv', 'val_subset3.csv', 'val_subset4.csv']\n"
     ]
    }
   ],
   "source": [
    "main = \"/content/drive/MyDrive/data_extracted\"\n",
    "LABELS_DIR = os.path.join(main, \"labels\")\n",
    "IMAGES_DIR = os.path.join(main, \"images\")\n",
    "\n",
    "# it disappears bro\n",
    "print(\"root exists:\", os.path.exists(main))\n",
    "print(\"labels dir exists:\", os.path.exists(LABELS_DIR))\n",
    "print(\"images dir exists:\", os.path.exists(IMAGES_DIR))\n",
    "print(\"files in labels dir (sample):\", sorted(os.listdir(LABELS_DIR))[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTNHrDeLqS9l",
    "outputId": "0e1e6553-1e68-4a90-c795-bd22babfcc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master CSV: /content/drive/MyDrive/data_extracted/labels/labels.csv\n",
      "master_df columns: ['Filename', 'Label', 'Species']\n",
      "                Filename  Label       Species\n",
      "0  20160928-140314-0.jpg      0  Chinee apple\n",
      "1  20160928-140337-0.jpg      0  Chinee apple\n",
      "2  20160928-140731-0.jpg      0  Chinee apple\n",
      "3  20160928-140747-0.jpg      0  Chinee apple\n",
      "4  20160928-141107-0.jpg      0  Chinee apple\n",
      "5  20160928-141135-0.jpg      0  Chinee apple\n",
      "\n",
      "Subset sample:                 Filename  Label\n",
      "0  20160928-140747-0.jpg      0\n",
      "1  20160928-141437-0.jpg      0\n",
      "2  20160928-142110-0.jpg      0\n",
      "3  20161207-110730-0.jpg      0\n",
      "4  20161207-110753-0.jpg      0\n",
      "5  20161207-110837-0.jpg      0\n"
     ]
    }
   ],
   "source": [
    "master_csv = os.path.join(LABELS_DIR, \"labels.csv\")\n",
    "print(\"Master CSV:\", master_csv)\n",
    "master_df = pd.read_csv(master_csv)   # contains Filename,Label,Species (as you showed)\n",
    "print(\"master_df columns:\", master_df.columns.tolist())\n",
    "print(master_df.head(6))\n",
    "\n",
    "subset0 = pd.read_csv(os.path.join(LABELS_DIR, \"test_subset0.csv\"))\n",
    "print(\"\\nSubset sample:\", subset0.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_WozKKXqfnd",
    "outputId": "e53c7e43-c488-4f8b-a2d5-cba238db7264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val/test sizes: 52525 17511 17509\n",
      "train sample:\n",
      "                 Filename  Label\n",
      "0  20171109-175921-2.jpg      5\n",
      "1  20170714-142019-3.jpg      1\n",
      "2  20170718-101402-2.jpg      0\n",
      "3  20170126-095456-0.jpg      1\n",
      "4  20170913-110647-1.jpg      3\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "def concat_subsets(labels_dir, pattern):\n",
    "    \"\"\"Concatenate CSV files matching pattern in labels_dir into one DataFrame.\"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(labels_dir, pattern)))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No files for pattern {pattern} in {labels_dir}\")\n",
    "    dfs = [pd.read_csv(p) for p in paths]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "train_df = concat_subsets(LABELS_DIR, \"train_subset*.csv\")\n",
    "val_df   = concat_subsets(LABELS_DIR, \"val_subset*.csv\")\n",
    "test_df  = concat_subsets(LABELS_DIR, \"test_subset*.csv\")\n",
    "\n",
    "print(\"train/val/test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "print(\"train sample:\\n\", train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLIhtt8Xqpbz",
    "outputId": "35566b0d-c6a6-49d2-9af3-913516a9dd18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7mBEREuOqzKu"
   },
   "outputs": [],
   "source": [
    "# ===== IMAGE TRANSFORMS =====\n",
    "# IMG_SIZE is the square size models like EfficientNet / ResNet expect (commonly 224)\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Training transforms (randomized) — used only when training\n",
    "train_transform = transforms.Compose([\n",
    "    # RandomResizedCrop: pick a random region of the image and scale it to IMG_SIZE.\n",
    "    # This both crops and resizes, which acts as a strong augmentation.\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "\n",
    "    # Random horizontal flip: with probability 0.5 flips image left-right.\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "\n",
    "    # Random small rotation: rotates the image by a random angle in ±15 degrees.\n",
    "    # Helps the model learn rotation-invariant features.\n",
    "    transforms.RandomRotation(15),\n",
    "\n",
    "    # Convert PIL Image -> Tensor and scale from [0,255] ints to [0.0,1.0] floats\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Normalize channels using ImageNet mean/std.\n",
    "    # Pretrained models (ImageNet) expect inputs normalized this way.\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation / Test transforms (deterministic) — used for evaluation\n",
    "test_transform = transforms.Compose([\n",
    "    # Resize the shorter side to 256 pixels (keeps aspect ratio)\n",
    "    transforms.Resize(256),\n",
    "\n",
    "    # CenterCrop to IMG_SIZE to get a deterministic view of the image\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "\n",
    "    # Convert to tensor and normalize with same mean/std\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-6AbBJJ1sf8I"
   },
   "outputs": [],
   "source": [
    "def load_sample(row, image_dir, transform):\n",
    "    \"\"\"\n",
    "    row: a pandas Series containing at least the 'Filename' and 'Label' columns\n",
    "    returns: (image tensor, label tensor) after applying transform\n",
    "    \"\"\"\n",
    "    # build image path from image directory + filename in the CSV row\n",
    "    img_path = os.path.join(image_dir, row[\"Filename\"])\n",
    "    # open the image file and convert to RGB (some images might be grayscale)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    # apply the supplied torchvision transform pipeline\n",
    "    image = transform(image)\n",
    "    # convert numeric label to a torch.long tensor (class index)\n",
    "    label = torch.tensor(int(row[\"Label\"]), dtype=torch.long)\n",
    "    # return the processed image tensor and label tensor\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def get_batch(df, image_dir, transform, batch_size, start_idx):\n",
    "    # create lists to collect tensors\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # compute the end index for this batch (clamped to length of df)\n",
    "    end_idx = min(start_idx + batch_size, len(df))\n",
    "    # iterate rows from start_idx up to end_idx (exclusive)\n",
    "    for i in range(start_idx, end_idx):\n",
    "        # load each sample (image tensor, label tensor)\n",
    "        img, lab = load_sample(df.iloc[i], image_dir, transform)\n",
    "        # append to lists\n",
    "        images.append(img)\n",
    "        labels.append(lab)\n",
    "\n",
    "    # stack image tensors into a single batched tensor of shape (B, C, H, W)\n",
    "    images = torch.stack(images)\n",
    "    # stack label tensors into a single tensor of shape (B,)\n",
    "    labels = torch.stack(labels)\n",
    "    # move tensors to the device (GPU or CPU)\n",
    "    return images.to(device), labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "_Mf76UxYsmfT"
   },
   "outputs": [],
   "source": [
    "# import timm (Torch Image Models) which provides pretrained architectures\n",
    "import timm\n",
    "# compute number of distinct classes from the master labels DataFrame\n",
    "num_classes = master_df[\"Label\"].nunique()\n",
    "\n",
    "# create an EfficientNet-b0 model from timm with pretrained ImageNet weights\n",
    "model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "# replace the classifier (final layer) with a new linear layer sized for our num_classes\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "# send the model to the device (GPU)\n",
    "model = model.to(device)\n",
    "# define the loss function as CrossEntropyLoss (combines softmax + NLLLoss)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(df, transform, optimizer, batch_size=32):\n",
    "    # put the model into training mode (enables dropout, batchnorm running stats updates)\n",
    "    model.train()\n",
    "    # counters for accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # iterate through the dataset in steps of batch_size (manual batching)\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        # get a batch of images and labels starting at index i\n",
    "        images, labels = get_batch(df, IMAGES_DIR, transform, batch_size, i)\n",
    "\n",
    "        # zero gradients for optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute model outputs (logits)\n",
    "        outputs = model(images)\n",
    "        # compute cross-entropy loss between outputs and true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        # optimizer step: apply gradients to update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # get predicted class indices (argmax along class dim)\n",
    "        preds = outputs.argmax(1)\n",
    "        # accumulate correct predictions count\n",
    "        correct += (preds == labels).sum().item()\n",
    "        # accumulate total samples processed\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # return training accuracy for the epoch\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Wf9AGzfds7ea"
   },
   "outputs": [],
   "source": [
    "def evaluate(df, transform, batch_size=32):\n",
    "    # set the model to evaluation mode (disables dropout, uses batchnorm running stats)\n",
    "    model.eval()\n",
    "    # lists to collect predictions and labels from all batches\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # disable gradient computation for inference (saves memory and compute)\n",
    "    with torch.no_grad(): \n",
    "        #Stops gradient tracking → faster + less memory during evaluation\n",
    "\n",
    "\n",
    "        \n",
    "        # iterate over dataset in batch_size steps\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            # load batch to device\n",
    "            images, labels = get_batch(df, IMAGES_DIR, transform, batch_size, i)\n",
    "            # forward pass to get outputs\n",
    "            outputs = model(images)\n",
    "            # get predicted class indices for this batch\n",
    "            preds = outputs.argmax(1)\n",
    "\n",
    "            # append predictions and labels (moved to cpu) to lists\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    # concatenate all batch tensors into single numpy arrays\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    # return arrays (labels, preds) for external metric calculation\n",
    "    return all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPVx_IBttYOJ",
    "outputId": "e61c583f-5f34-4d84-8934-9667b6cbd3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial FT Epoch 1: Train Acc = 0.6812\n",
      "Partial FT Epoch 2: Train Acc = 0.7261\n",
      "Partial FT Epoch 3: Train Acc = 0.7362\n",
      "Partial FT Epoch 4: Train Acc = 0.7447\n",
      "Partial FT Epoch 5: Train Acc = 0.7474\n"
     ]
    }
   ],
   "source": [
    "# freeze all parameters in the model (no gradient updates)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# unfreeze the classifier head parameters only (we just replaced it earlier)\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# create optimizer that will only optimize parameters of the classifier head\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "# run 5 epochs of training on only the classifier head (partial fine-tuning)\n",
    "for epoch in range(5):\n",
    "    acc = train_epoch(train_df, train_transform, optimizer)\n",
    "    print(f\"Partial FT Epoch {epoch+1}: Train Acc = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaHmtntktbw_",
    "outputId": "3e2f48bc-b841-4098-fd21-cbb962443eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full FT Epoch 1: Train Acc = 0.8484\n",
      "Full FT Epoch 2: Train Acc = 0.9111\n",
      "Full FT Epoch 3: Train Acc = 0.9364\n",
      "Full FT Epoch 4: Train Acc = 0.9487\n",
      "Full FT Epoch 5: Train Acc = 0.9586\n"
     ]
    }
   ],
   "source": [
    "# unfreeze all parameters so they can be trained now\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# create optimizer for the whole model parameters but at a lower learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# run 5 epochs of full fine-tuning (now backbone + head will be updated)\n",
    "for epoch in range(5):\n",
    "    acc = train_epoch(train_df, train_transform, optimizer)\n",
    "    print(f\"Full FT Epoch {epoch+1}: Train Acc = {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
