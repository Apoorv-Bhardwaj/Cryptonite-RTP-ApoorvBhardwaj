{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54af154-b9a7-4d42-8d8d-eb15b458c552",
   "metadata": {},
   "source": [
    "# CNN Cheat Sheet\n",
    "\n",
    "This cheat sheet covers the fundamentals of Convolutional Neural Networks (CNNs), key architectures and their evolution, and advanced training techniques. Each section includes brief explanations of the specified topics for quick reference. Use it to grasp basics and spot areas for deeper study.\n",
    "\n",
    "## Fundamentals of Convolutional Neural Networks\n",
    "\n",
    "### Convolution Operation\n",
    "- **Definition**: Core operation in CNNs where a filter (small matrix) slides over the input image, performing element-wise multiplication and summation to detect patterns like edges or textures.\n",
    "- **How it works**: Input (e.g., image pixels) * filter values → output value at each position.\n",
    "- **Purpose**: Extracts local features while reducing parameters compared to fully connected layers.\n",
    "\n",
    "### Filters/Kernels\n",
    "- **Definition**: Small, learnable matrices (e.g., 3x3) that scan the input to detect specific features (e.g., horizontal edges).\n",
    "- **Key points**: Multiple filters per layer create multiple feature maps. Initialized randomly, updated during training via backpropagation.\n",
    "- **Size impact**: Smaller filters capture fine details; larger ones see broader patterns.\n",
    "\n",
    "### Feature Maps\n",
    "- **Definition**: Output grids from applying filters to the input, representing detected features at different spatial locations.\n",
    "- **How formed**: One feature map per filter. Stacked together for the next layer's input.\n",
    "- **Role**: Build hierarchical representations (low-level edges → high-level objects).\n",
    "\n",
    "### Padding (Valid and Same)\n",
    "- **Definition**: Adds extra pixels (usually zeros) around input borders to control output size.\n",
    "- **Valid Padding**: No padding; output shrinks (e.g., 5x5 input with 3x3 filter → 3x3 output).\n",
    "- **Same Padding**: Adds padding to keep output size same as input (e.g., add 1 pixel border for 3x3 filter).\n",
    "- **Why use**: Prevents information loss at edges; \"Same\" maintains spatial dimensions.\n",
    "\n",
    "### Strides\n",
    "- **Definition**: Step size by which the filter slides over the input (e.g., stride=1: every pixel; stride=2: every other).\n",
    "- **Impact**: Larger strides reduce output size and computation (downsampling).\n",
    "- **Formula**: Output size = [(Input size - Filter size + 2*Padding) / Stride] + 1.\n",
    "\n",
    "### Pooling (Max/Average)\n",
    "- **Definition**: Downsampling operation to reduce spatial dimensions and computation while retaining key info.\n",
    "- **Max Pooling**: Takes maximum value in a window (e.g., 2x2) → highlights strongest features.\n",
    "- **Average Pooling**: Takes average value in window → smooths features, less common for classification.\n",
    "- **Common use**: After convolution; e.g., 2x2 pooling with stride=2 halves dimensions.\n",
    "\n",
    "### Convolutions Over Volumes\n",
    "- **Definition**: Applying convolution to multi-channel inputs (e.g., RGB images with 3 channels).\n",
    "- **How it works**: Filters have same depth as input channels (e.g., 3D filter for RGB). Sum across channels for each position.\n",
    "- **Output**: Feature map depth equals number of filters, not input channels.\n",
    "- **Extension**: For videos or 3D data, uses 3D convolutions (height, width, time/depth).\n",
    "\n",
    "## CNN Architectures and Evolution\n",
    "\n",
    "### LeNet-5\n",
    "- **Overview**: Early CNN (1998) for handwritten digit recognition (MNIST dataset).\n",
    "- **Key features**: 7 layers (conv, pool, fully connected); used tanh activation.\n",
    "- **Significance**: Pioneered CNNs for image tasks; simple and efficient for small images.\n",
    "\n",
    "### AlexNet\n",
    "- **Overview**: Breakthrough CNN (2012) that won ImageNet challenge; 8 layers deep.\n",
    "- **Key features**: ReLU activation, dropout, data augmentation; used GPU training.\n",
    "- **Impact on Computer Vision**: Revived interest in deep learning; showed CNNs scale to large datasets (1M+ images); inspired modern architectures.\n",
    "\n",
    "### InceptionNet/GoogLeNet\n",
    "- **Overview**: 2014 model with 22 layers; efficient via Inception modules.\n",
    "- **Inception Modules**: Parallel convolutions (1x1, 3x3, 5x5) + pooling, concatenated for multi-scale feature extraction.\n",
    "- **1x1 Convolutions**: Reduce channel depth (bottleneck) to cut computation without losing info.\n",
    "- **Significance**: Won ImageNet with fewer parameters; focused on efficiency.\n",
    "\n",
    "### ResNet\n",
    "- **Overview**: Deep residual network (2015); up to 152 layers; won ImageNet.\n",
    "- **Skip Connections**: Add input directly to output (shortcut) to ease training deep nets.\n",
    "- **Degradation Problem**: Deeper plain nets perform worse due to vanishing gradients/optimization issues.\n",
    "- **Residual Blocks**: Core unit: conv layers + skip connection (output = F(x) + x); enables very deep models.\n",
    "\n",
    "### MobileNet\n",
    "- **Overview**: Lightweight CNN (2017) for mobile/edge devices; focuses on speed.\n",
    "- **Depth-Wise Separable Convolutions**: Splits standard conv into depth-wise (per channel) + point-wise (1x1 across channels); reduces params/computation by ~8-9x.\n",
    "- **Computational Efficiency**: Fewer FLOPs; tunable via width/depth multipliers for trade-offs.\n",
    "- **Use cases**: Real-time apps like object detection on phones.\n",
    "\n",
    "### EfficientNet\n",
    "- **Overview**: 2019 family of models; scales depth, width, resolution optimally.\n",
    "- **Key features**: Compound scaling (balances all dimensions); based on MobileNetV2 + NAS (neural architecture search).\n",
    "- **Advantages**: State-of-the-art accuracy with fewer params/FLOPs; e.g., EfficientNet-B7 beats larger models.\n",
    "- **Evolution**: Builds on prior nets for better efficiency in resource-constrained settings.\n",
    "\n",
    "## Advanced Training Techniques for CNNs\n",
    "\n",
    "### Data Augmentation\n",
    "- **Definition**: Artificially expands dataset by transforming images to improve generalization.\n",
    "- **Techniques**:\n",
    "  - **Rotation**: Rotate images by angles (e.g., 0-360°) to handle orientations.\n",
    "  - **Flipping**: Horizontal/vertical flips for symmetry invariance.\n",
    "  - **Cropping**: Random crops/zooms to focus on parts and simulate variations.\n",
    "  - **Color Jittering**: Adjust brightness, contrast, saturation, hue for lighting robustness.\n",
    "- **Benefits**: Reduces overfitting; especially useful for small datasets.\n",
    "\n",
    "### Transfer Learning\n",
    "- **Definition**: Use pre-trained model (e.g., on ImageNet) as starting point for new task.\n",
    "- **Why**: Leverages learned features (low-level: edges; high-level: objects); faster training, better performance with less data.\n",
    "- **Steps**: Load pre-trained weights; replace final layers for new classes.\n",
    "\n",
    "### Fine-Tuning Strategies\n",
    "- **Definition**: Adjust pre-trained model for specific task.\n",
    "- **Strategies**:\n",
    "  - Freeze early layers (feature extractors), train later ones.\n",
    "  - Gradually unfreeze and train with lower learning rates.\n",
    "  - Use schedulers (e.g., reduce LR on plateau) to avoid destroying pre-trained weights.\n",
    "- **When to use**: Small datasets → feature extraction; large datasets → full fine-tuning.\n",
    "\n",
    "### Batch Normalization in CNNs\n",
    "- **Definition**: Normalizes activations per mini-batch (mean=0, variance=1) + learnable scale/shift.\n",
    "- **Placement**: After conv/FC layers, before activation.\n",
    "- **Benefits**: Stabilizes training; allows higher LR; reduces internal covariate shift; slight regularization.\n",
    "- **In CNNs**: Speeds up convergence; essential for deep nets like ResNet.\n",
    "\n",
    "### Dropout in CNNs\n",
    "- **Definition**: Randomly drops (sets to zero) neurons during training (e.g., p=0.5 probability).\n",
    "- **Placement**: Typically after fully connected layers; sometimes after conv in CNNs.\n",
    "- **Benefits**: Prevents overfitting by forcing ensemble-like behavior; no dropout at inference.\n",
    "- **In CNNs**: Less common in conv layers due to spatial sharing, but useful in dense parts.\n",
    "\n",
    "### Degradation Problem\n",
    "- **Definition**: In deep plain networks, adding layers worsens performance (training/test error increases).\n",
    "- **Causes**: Vanishing/exploding gradients; optimization difficulties.\n",
    "- **Solutions**: ResNet's residual blocks (skip connections) mitigate by enabling identity mapping.\n",
    "- **Context**: Highlighted in ResNet paper; also addressed by batch norm, better init (e.g., He init)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7512764-7dbb-4754-9977-7548566a7f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
